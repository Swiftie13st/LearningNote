# 操作系统

## 进程线程

### 进程线程的区别

`进程`是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个**独立**单位。  
`线程`是操作操作系统能够进行运算调度的==最小单位==。线程被包含在进程之中，是进程中的实际运作单位，一个进程内可以包含多个线程，线程是资源调度的**最小**单位。
`协程`调度由用户自己控制，本质上有点类似于用户级线程，类比一个进程可以拥有多个线程，一个线程也可以拥有多个协程，因此协程又称为线程的线程。从属同一个内核级线程，无法并行；一个协程阻塞会导致从属同一线程的所有协程无法执行.

`线程`与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304091455014.png)

线程与进程的比较如下：

-   进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
-   进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
-   线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
-   线程能减少并发执行的时间和空间开销；

对于，线程相比进程能减少开销，体现在：

-   线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
-   线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
-   同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
-   由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

所以，不管是时间效率，还是空间效率线程比进程都要高。

**协程**，又称为用户级线程，核心点如下：

（1）与线程存在映射关系，为 M：1；
（2）创建、销毁、调度在用户态完成，对内核透明，所以更轻；
（3）从属同一个内核级线程，无法并行；一个协程阻塞会导致从属同一线程的所有协程无法执行.

-   进程

进程是程序的一次执行过程，是程序在执行过程中的分配和管理资源的基本单位，每个进程都有自己的地址空间,进程是系统进行资源分配和调度的一个独立单位。

每个进程都有自己的独立内存空间，不同进程通过IPC（Inter-Process Communication）进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。

-   线程

线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

-   协程

协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。

协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

### 为什么要有进程，进程解决了什么问题

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个**运行中的程序，就被称为「进程」（Process）**。

### 线程解决了什么问题 

使用多进程，进程间**通信困难**，**维护进程的系统开销较大**，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；

**线程是进程当中的一条执行流程。**

同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。

线程的优点：

-   一个进程中可以同时存在多个线程；
-   各个线程之间可以并发执行；
-   各个线程之间可以共享地址空间和文件等资源；

### 线程资源保存在哪里

线程（非主线程）的栈的大小是固定的，其会在空闲的堆（堆顶附近自顶向下分配）或者是空闲栈（栈底附近自底向上分配），因此线程栈局部函数中分配的变量是存放到各自分配的栈空间，因此可以说是线程私有的，又因为该线程栈的边界是设定好的，因此该线程栈的大小的固定的。

操作系统会专门开辟一块物理内存。这块内存会当必须在物理内存的程序片段和数据。

处理器切换线程时，操作系统专门的线程管理模块，会将寄存器数据全部保存到对应线程数据结构中。这个数据集就在这块物理内存上。
  
线程与线程数据结构一一对应，它不仅保存寄存器数据还保存其他各种与线程相关的数据。

### 上下文

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个**一个进程切换到另一个进程运行，称为进程的上下文切换**。
保存本次执行状态，以便于下次继续执行，这个过程就是一个上下文。

每个进程执行过的、执行时的以及待执行的指令和数据；在[指令寄存器](https://baike.baidu.com/item/%E6%8C%87%E4%BB%A4%E5%AF%84%E5%AD%98%E5%99%A8?fromModule=lemma_inlink)、[堆栈](https://baike.baidu.com/item/%E5%A0%86%E6%A0%88/1682032?fromModule=lemma_inlink)、状态字寄存器等中的内容。此外, 还包括进程打开的[文件描述符](https://baike.baidu.com/item/%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/9809582?fromModule=lemma_inlink)等.

**保存在内核堆栈中**

所谓“**进程上下文**”，就是一个进程在执行的时候，CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。

#### CPU的上下文切换

CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 **CPU 上下文**。

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：**进程上下文切换、线程上下文切换和中断上下文切换**。

#### 进程上下文切换

进程是由内核管理和调度的，所以进程的切换只能发生在内核态。

所以，**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。

#### 线程的上下文切换

这还得看线程是不是属于同一个进程：

-   当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
-   **当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**；

所以，线程的上下文切换相比进程，开销要小很多。

### 进程有哪些组成部分 

**进程是由程序控制块（PCB）、程序段、数据段组成。**

程序段：程序代码存放的位置。  
数据段：程序运行时使用、产生的运算数据。如全局变量、局部变量、宏定义的常量就存放在数据段内。

**PCB**：
操作系统是通过PCB来管理进程，因此PCB中应该包含操作系统对其进行管理所需的各种信息，如进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息。 **PCB是进程存在的唯一标志**

**内容**：
- **进程描述信息：**
	-   进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
	-   用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；
- **进程控制和管理信息：**
	-   进程当前状态，如 new、ready、running、waiting 或 blocked 等；
	-   进程优先级：进程抢占 CPU 时的优先级；
- **资源分配清单：**
	-   有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。
- **CPU 相关信息：**
	-   CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

**每个 PCB 是如何组织的呢**？

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

-   将所有处于就绪状态的进程链在一起，称为**就绪队列**；
-   把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
-   另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

### 进程开辟虚拟空间 有哪些段 都用什么用？栈里面放什么信息？ 

![image.png](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/20230512161107.png)

#### 堆栈段（栈）

1. 为函数内部的局部变量提供存储空间。
2. 进行函数调用时，存储“过程活动记录”。
3. 用作暂时存储区。如计算一个很长的算术表达式时，可以将部分计算结果压入堆栈。

由编译器自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈，是用户存放程序临时创建的局部变量。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。

#### 堆

就像堆栈段能够根据需要自动增长一样，数据段也有一个对象，用于完成这项工作，这就是堆（heap）。堆区域用来动态分配的存储，也就是用 malloc 函数活的的内存。calloc和realloc和malloc类似。前者返回指针的之前把分配好的内存内容都清空为零。后者改变一个指针所指向的内存块的大小，可以扩大和缩小，他经常把内存拷贝到别的地方然后将新地址返回。

由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）

#### 数据段（静态存储区）

包括BSS段的数据段，BSS段存储未初始化的==全局变量、静态变量==。数据段存储经过初始化的全局和静态变量。

BSS段：BSS段（bss segment）通常是指用来存放程序中未初始化的全局变量的一块内存区域。BSS是英文Block Started by Symbol的简称。BSS段属于静态内存分配。

#### 代码段

又称为文本段。存储可执行文件的指令。代码段也被用于存放常量。

### 进程切换

#### 原因

1. 阻塞式系统调用、虚拟地址异常。导致被中断进程进入等待态。
2. 时间片中断、I/O中断后发现更改优先级进程。导致被中断进程进入就绪态。
3. 终止用系统调用、不能继续执行的异常。导致被中断进程进入终止态。

#### 步骤

1. 保存之前运行的进程上下文
2. 调用准备运行的进程的上下文
3. CPU使用权交接

#### 新运行的进程是怎么占到CPU的？ 

在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。

比如，以下状态的变化都会触发操作系统的调度：

-   _从就绪态 -> 运行态_：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；
-   _从运行态 -> 阻塞态_：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行；
-   _从运行态 -> 结束态_：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；

因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。

另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

-   **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
-   **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

### 进程切换为什么比线程切换效率低 

第一，进程切换会涉及到虚拟地址映射的切换，也就是页表。等于说是，这个观点认为页表切换很慢。

因为，每次进程切换时，都会涉及页表的切换，不过切换页表这个操作本身是不太耗时的。但是在切换之后，**TLB（页表缓存/快表）就失效了**，所以在进行地址转化时就需要重新去查找页表，这就造成了程序运行的效率低下。
而同一个进程的线程之间是共用一个页表的，所以线程之间的切换是不需要切换页表的，因此线程切换不存在上述代价大，效率低的问题。

第二，进程切换涉及到上下文(寄存器组)的切换。

**上下文**：每个进程执行过的、执行时的以及待执行的指令和数据；在指令寄存器、堆栈、状态字寄存器等中的内容。此外, 还包括进程打开的文件描述符等.

### 线程分类

#### 用户级线程

==实现在用户空间的线程==称为用户级线程。用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁全由用户空间的库函数完成，不需要内核的参与，因此这种线程的系统资源消耗非常低，且非常的高效。

##### 特点

-   用户线级线程只能参与竞争该进程的处理器资源，不能参与全局处理器资源的竞争。
-   用户级线程切换都在用户空间进行，开销极低。
-   用户级线程调度器在用户空间的线程库实现，内核的调度对象是进程本身，内核并不知道用户线程的存在。

##### 缺点

如果触发了引起阻塞的系统调用的调用，会立即阻塞该线程所属的整个进程。  
系统只看到进程看不到用户线程，所以只有一个处理器内核会被分配给该进程 ，也就不能发挥多久 CPU 的优势
   
#### 内核级线程

内核线程建立和销毁都是由==操作系统负责==、通过系统调用完成，内核维护进程及线程的上下文信息以及线程切换。

##### 特点

-   内核级线级能参与全局的多核处理器资源分配，充分利用多核 CPU 优势。
-   每个内核线程都可被内核调度，因为线程的创建、撤销和切换都是由内核管理的。
-   一个内核线程阻塞与他同属一个进程的线程仍然能继续运行。

##### 缺点

-   内核级线程调度开销较大。调度内核线程的代价可能和调度进程差不多昂贵，代价要比用户级线程大很多。
-   线程表是存放在操作系统固定的表格空间或者堆栈空间里，所以内核级线程的数量是有限的。

### 多线程的三大特性

定义：当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。

-   原子性：提供了互斥访问，同一时刻只能有一个线程来对它进行操作。**即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。**
-   可见性：一个线程对主内存的修改可以及时的被其他线程观察到。**可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值**
-   有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序。**即程序执行的顺序按照代码的先后顺序执行。**

### 线程有哪几种状态

-   **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
-   **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
-   **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
-   **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
-   **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

### 进程间的通信方式

-   **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。**匿名管道是只能用于存在父子关系的进程间单向通信**
-   **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道以**磁盘文件的方式存在**，可以实现本机任意两个进程通信。
-   **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；信号事件的来源主要有硬件来源（如键盘 **Cltr+C** ）和软件来源（如 **kill** 命令）。信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程
-   **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。** **消息队列是保存在内核中的消息链**
-   **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**
-   **共享内存(Shared memory)** ：`最快` 使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。
-   **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。**要与不同主机的进程间通信，那么就需要 Socket 通信了**

#### 进程通信管道实现 

有名管道以**磁盘文件的方式存在**，可以实现本机任意两个进程通信。

1. 父进程调用pipe开辟管道，得到两个文件描述符指向管道的两端。
2. 父进程调用fork创建子进程，那么子进程也有两个文件描述符指向同一管道。
3. 父进程关闭管道读端，子进程关闭管道写端。父进程可以往管道里写，子进程可以从管道里读，管道是用环形队列实现的，数据从写端流入从读端流出，这样就实现了进程间通信。

使用pipe创建的无名管道只能用于具有亲缘关系的进程之间，这就大大限制了管道的使用。

**有名管道**的出现就是为了解决这个限制问题，有名管道可以使互不相关的两个进程实现彼此通信。通信的过程就是通过路径名来指出管道文件，然后在建立了管道联系之后两个进程就可以把它当做一个普通文件一样进行读写操作，但是有名管道是严格遵循FIFO的规则，也就是所谓的先进先出，如果从有名管道中读取数据的话总是从开始出返回数据，显然如果是增加数据的话就是添加到末尾，而且不支持一些定位操作如lseek等。

简单的说就是，打开一个管道之后，如果是非阻塞模式，则不论管道的两边（一边读一边写）有没有正在操作，都会直接返回。但是如果是阻塞模式，则必须要保证管道两边都要有进程同时操作，否则就会阻塞。

```sh
mknod 管道名 p
```

### 线程间的同步方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1.  **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2.  **信号量(Semaphore)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3.  **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作
4. **临界区**：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。保证在某一时刻只有一个线程能访问数据的简便办法。缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。

### 在操作系统杀死一个进程之后，它需要做以下工作：

1.  `终止进程`：操作系统发送一个信号给进程，通知它终止运行。进程在收到信号后会自动终止。
2.  `回收资源`：当进程终止时，它占用的系统资源会被释放，这包括 CPU 时间、内存、打开的文件、网络连接等等。操作系统会回收这些资源，以便其他进程可以使用它们。
3.  `清理进程状态`：操作系统需要清理进程的状态，例如进程所占用的 CPU 寄存器、进程的上下文信息等等。这些状态信息需要被清除，以便其他进程可以使用它们。
4.  `发送信号给相关进程`：如果被终止的进程是某些进程的父进程，那么操作系统会向这些子进程发送信号，通知它们它们的父进程已经终止。这样，子进程就可以做出适当的处理，例如重新连接到另一个进程上。

### 父进程fork一个子进程的时候操作系统会发生哪些变化 

父进程经过fork()以后，父进程和子进程拥有相同内容的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只==复制了自己的PCB块==。而==代码段，数据段和用户堆栈内存空间与子进程共享==。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。

### linux中fork和exec有什么区别

#### fork

调用fork可以创建一个新的进程称为子进程, 调用fork函数的进程称为父进程, 子进程的所有内容都和父进程相同, 除了pcd(进程控制模块), 如果这两个进程都没有对内存做写操作的话, 那么两个进程共享调用fork函数的进程的内存页, 这样表面上看fork创建进程比exec创建进程快. 但只要两个进程其中一个对内存做了修改, 那么在修改之前, 就会把内存页复制一份给子进程用.

#### exec

调用exec创建进程, 实际上不是创建进程, 更准确的说是加载可执行文件, 调用exec后会把exec中指定的可执行文件加载到调用exec的进程的空间内, 并把调用exec的进程的内存更新为exec中指定的可执行文件的内容.

#### 区别

fork主要是Linux用来建立新的进程（线程）而设计的，exec()系列函数则是用来用指定的程序替换当前进程的全部内容。因此exec()系列函数常常在前三个函数使用以后调用，来建立一个全新的程序运行环境。Linux用init进程启动其余进程的过程通常都是这样的

## 内核态和用户态

首先进程在系统上分为：
1.  用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
2.  内核态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

**用户态和内核态**是操作系统的两种运行级别，两者最大的区别就是**特权级**不同。**用户态拥有最低的特权级，内核态拥有较高的特权级。** 运行在用户态的程序不能直接访问操作系统内核数据结构和程序。

-   内核态和用户态之间的转换方式主要包括：**系统调用，异常和中断。**

在进程从用户态转换到内核态时，操作系统会切换进程的上下文，并将处理器的权限级别从用户态提升到内核态。这个过程需要保存用户态下的所有寄存器状态和程序计数器，以便在返回用户态时能够继续执行原来的进程。

### 系统调用

**系统调用（Syscall）** 是一种软中断处理程序，用于让程序从用户态陷入内核态，以执行相应的操作。

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！
也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：
-   设备管理。完成设备的请求或释放，以及设备启动等功能。
-   文件管理。完成文件的读、写、创建及删除等功能。
-   进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
-   进程通信。完成进程之间的消息传递或信号传递等功能。
-   内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能

### 异常

当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。

### 中断

中断（interrupt）是计算机系统中的基本机制之一。即：在计算机运行过程中，当发生某个事件后，CPU 会停止当前程序流，转而去处理该事件，并在处理完毕后继续执行原程序流。**发生中断就意味着需要操作系统介入，开展管理工作。**

由于操作系统的管理工作（**如进程切换、分配IO设备）需要使用特权指令，因此CPU要从用户态转换为核心态**。中断就可以使CPU从用户态转换为核心态，使操作系统获得计算机的控制权。因此，有了中断，才能实现多道程序并发执行。

中断机制的好处是 **化主动为被动，避免 CPU 轮询等待某条件成立**。如果没有中断机制，那么“某个条件成立”就需要 CPU 轮询判断，这样就会增加系统的开销。而使用中断机制，就可以在条件成立之后，向 CPU 发送中断事件，强制中断 CPU 执行程序，转而去执行中断处理程序。

中断可以分为：内中断和外中断。  
  **内中断**：内中断的信号来源于CPU内部、与当前执行的指令有关。如整数除0。  
  **外中断**：外中断的信号来源于CPU外部、与当前执行的指令无关。如用户强制结束一个进程、IO设备完成操作发生的中断信号。

没法延迟处理的必须停下来做的事情硬中断，可以延迟处理是有一定的灵活控制的为软中断

#### 软中断

软中断是执行`中断指令`产生的，为了满足实时系统的要求，中断处理应该是越快越好。linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。系统调用就是软中断

#### 硬中断

由与系统相连的`外设`(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。

### 进程之间是相互隔离的，内核态却同时有A进程和B进程的权限，怎么理解的 

内核态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

这是因为内核态是操作系统的一部分，它是所有进程共享的。在内核态下，操作系统可以访问所有进程的地址空间，因此可以同时拥有A进程和B进程的权限。但是在用户态下，每个进程只能访问自己的地址空间，无法访问其他进程的地址空间。

## 死锁

死锁描述的是这样一种情况：多个进程/线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于进程/线程被无限期地阻塞，因此程序不可能正常终止。

### 死锁的四个必要条件

-   **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
-   **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
-   **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
-   **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

### 解决死锁的方法

解决死锁的方法可以从多个角度去分析，一般的情况下，有**预防，避免，检测和解除四种**。

-   **预防** 是采用某种策略，**限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间上都不满足。
-   **避免**则是系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**
-   **检测**是指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。
-   **解除** 是与检测相配套的一种措施，用于**将进程从死锁状态下解脱出来**。

## 悲观锁，乐观锁

悲观锁做事比较悲观，它认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。

乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

### 什么是CAS机制（compare and swap）

CAS算法的作用：解决多线程条件下使用锁造成性能损耗问题的算法，保证了原子性，这个原子操作是由CPU来完成的
CAS的原理：CAS算法有三个操作数，通过内存中的值（V）、预期原始值（A)、修改后的新值。
1. 如果内存中的值和预期原始值相等， 就将修改后的新值保存到内存中。
2. 如果内存中的值和预期原始值不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作，直到重试成功。

### 自旋锁

**自旋锁**是用于多线程同步的一种锁，线程反复检查锁变量是否可用。由于线程在这一过程中保持执行，因此是一种忙等待。一旦获取了自旋锁，线程会一直保持该锁，直至显式释放自旋锁。

## 内存管理

### 虚拟地址&物理地址

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址

虚拟内存是一个抽象概念，它为每个进程提供一个假象。即每个进程都独占地使用主存，每个进程看到的内存都是一致的。称之为虚拟地址空间。虚拟地址空间分为 内核虚拟内存，用户虚拟内存，他们共同瓜分了操作系统能支配的内存区域。
用户空间虚拟地址的范围从0-TASKSIZE,内存空间占据剩余空间，虚拟内存的最大容量与实际可用的物理内存的大小无关。内核和CPU会负责维护虚拟内存和物理内存直接的映射关系。内核会为每个用户进程分配的是虚拟内存而不是物理内存。每个用户进程分配到的虚拟内存总是在用户空间中，而内核空间则留给内核专用。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

### 为什么要有虚拟地址、内存

- 在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）
- 优化用户体验（进程感知到获得的内存空间是“连续”的）
- “放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成微信这个程序会崩溃。
3. 如果是逻辑内存直接映射到物理内存，当逻辑内存超过物理内存的时候，计算机就会出现内存不足的情况，导致程序崩溃。

通过虚拟地址访问内存有以下优势：
-   程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
	-   程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
-   不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

-   第一，**虚拟内存可以使得进程对运行内存超过物理内存大小**，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
-   第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就**解决了多进程之间地址冲突**的问题。
-   第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

### 虚拟内存映射

**内存地址转换** :

-   把虚拟内存地址，切分成页号和偏移量；
-   根据页号，从页表里面，查询对应的物理页号；
-   直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

### 多级页表相比单级页表的优化？

#### 单级页表：

有空间上的缺陷。在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。

每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。

#### 多级页表：

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。

如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。

我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

### 如何限制虚拟内存大小

限制swap分区大小

当用户提交程序，然后产生进程在机器上运行。机器会判断当前物理内存是否还有空闲允许进程调入内存运行，如果有则直接调入内存进行；如果没有，则会根据优先级选择一个进程挂起，把该进程交换到swap中等待，然后把新的进程调入到内存中运行。根据这种换入和换出，实现了内存的循环利用，让用户感觉不到内存的限制。从这也可以看出swap扮演了一个非常重要的角色，就是暂存被换出的进程。

### 常见的几种内存管理机制

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1.  **块式管理** ： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2.  **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3.  **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理机制** 。段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

简单来说：页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。

#### 内存分段

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

-   第一个就是**内存碎片**的问题。
-   第二个就是**内存交换的效率低**的问题。

##### 内存分段会出现内存碎片吗？

内存碎片主要分为，内部内存碎片和外部内存碎片。

内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以**不会出现内部内存碎片**。

但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。

解决「外部内存碎片」的问题就是**内存交换**。

##### 分段为什么会导致内存交换效率低的问题？

**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

#### 内存分页

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（_Page_）。在 Linux 下，每一页的大小为 `4KB`。

操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作“页”，于物理内存而言叫作“帧”，原因及要点如下：

- 提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）
- 提高内外存交换效率（更细的粒度带来了更高的灵活度）
- 与虚拟内存机制呼应，便于建立虚拟地址->物理地址的映射关系（聚合映射关系的数据结构，称为页表）
- inux 页/帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）

虚拟地址与物理地址之间通过**页表**来映射
页表是存储在内存里的，而CPU芯片中的 内存管理单元 （MMU）就负责将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

页表使用虚拟地址的页号作为索引，以找到实际物理存储器中的页号，即：key = 虚拟地址的页号， val = 实际物理存储器中的页号。

##### TLB（页表缓存/快表）

**计算机中的cpu的处理速度是要远快于内存操作的**，那么每次cpu要读取数据时都需要等待内存就绪才行，这在一定程度上限制了cpu的执行效率。

因此根据**局部性原理**，CPU 芯片中加入了一个专门**存放程序最常访问页表项的 Cache 高速缓存**，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为 **页表缓存**、**转址旁路缓存**、**快表**等，可以极大提高地址转换速度，加速对于页表的访问。

TLB可以看作是一种硬件的哈希表，来快速查找 高速cache 中是否存在特定地址的数据，而其中应用到的内存淘汰策略则是常被提到的**LRU**内存淘汰策略。

-   TLB hit：命中缓存直接访问内存取数据
-   TLB miss：未命中缓存，但是在内存中有对应页 → 【要再去页表中找地址】
-   TLB miss：同时内存中也没有对应页，发生**缺页** → 【要向磁盘要数据，同时更新 TLB 和 页表】

总之，就是先查找 TLB，如果缺失，那么查找页表；还缺就是发生缺页了，需要通过磁盘加载所需数据到物理内存中。如果查找 TLB 命中，那么根据 TLB 获取物理地址，然后查找数据 cache，后续就算普通的 cache 查找了。

##### 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？

内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（_Swap Out_）。一旦需要的时候，再加载进来，称为**换入**（_Swap In_）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

##### 分页机制下，虚拟地址和物理地址是如何映射的？

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址；

总结一下，对于一个**内存地址转换**，其实就是这样三个步骤：
-   把虚拟内存地址，切分成页号和偏移量；
-   根据页号，从页表里面，查询对应的物理页号；
-   直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

#### 段页式内存管理

段页式内存管理实现的方式：
-   先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
-   接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

段页式地址变换中要得到物理地址须经过三次内存访问：
-   第一次访问段表，得到页表起始地址；
-   第二次访问页表，得到物理页号；
-   第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

## 调度算法

### 进程调度算法

- `先来先服务`(_First Come First Severd, FCFS_)：每次从就绪队列选择**最先进入队列的进程**，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。FCFS 对长作业有利，==适用于 CPU 繁忙型作业的系统==，而不适用于 I/O 繁忙型作业的系统。
- `最短作业优先`（_Shortest Job First, SJF_）调度算法同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。
- `高响应比优先`(_Highest Response Ratio Next, HRRN_)调度算法,每次进行进程调度时，先计算「**响应比优先级**」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：$优先级 = \frac{等待时间+要求服务的时间}{要求服务的时间}$
- `时间片轮转`（_Round Robin, RR_）,每个进程被分配一个时间段，称为时间片（_Quantum_），即**允许该进程在该时间段中运行**。如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；
- `最高优先级`（_Highest Priority First，HPF_）从就绪队列中选择**最高优先级**的进程进行运行。
	进程的优先级可以分为，静态优先级或动态优先级：
	-   静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
	-   动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。
	该算法也有两种处理优先级高的方法，非抢占式和抢占式：
	-   非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
	-   抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。
	但是依然有缺点，可能会导致低优先级的进程永远不会运行。
- `多级反馈队列`（_Multilevel Feedback Queue_）「时间片轮转算法」和「最高优先级算法」的综合和发展。
	-   「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
	-   「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

> **缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。
-   **OPT 页面置换算法（最佳页面置换算法）** ：==置换在「未来」最长时间不访问的页面==最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
-   **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
-   **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
-   **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。
- 时钟页面置换算法（_Lock_）该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
	当发生缺页中断时，算法首先检查表针指向的页面：
	-   如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
	-   如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

#### 写LRU算法
[面试题 16.25. LRU 缓存（C++【OPT/FIFO/LRU】操作系统页面置换算法一网打尽） - LRU 缓存 - 力扣（LeetCode）](https://leetcode.cn/problems/lru-cache-lcci/solution/by-nehzil-zt9y/)

```go
type LRUCache struct {
    cap int
    hash map[int]*DNode
    head, tail *DNode
}

type DNode struct {
    key, val int
    pre *DNode
    next *DNode
}


func Constructor(capacity int) LRUCache {
    l, r := &DNode{}, &DNode{}
    l.next = r
    r.pre = l
    return LRUCache {
        cap : capacity,
        hash : map[int]*DNode{},
        head : l,
        tail : r,
    }
}


func (this *LRUCache) Get(key int) int {
    if v, ok := this.hash[key]; ok {
        this.remove(v)
        this.insert(v)
        return v.val
    } 
    return -1;
}


func (this *LRUCache) Put(key int, value int)  {
    if v, ok := this.hash[key]; ok {
        v.val = value
        this.remove(v)
        this.insert(v)
    } else {
        if len(this.hash) == this.cap {
            p := this.tail.pre
            this.remove(p)
            delete(this.hash, p.key)
        }
        p := &DNode{key:key, val:value}
        this.hash[key] = p
        this.insert(p)
    }
}

func (this *LRUCache) remove(v *DNode)  {
    v.pre.next = v.next
    v.next.pre = v.pre
}
 // 插入到最左
func (this *LRUCache) insert(v *DNode)  {
    v.pre = this.head
    v.next = this.head.next
    this.head.next.pre = v
    this.head.next = v
}
/**
 * Your LRUCache object will be instantiated and called as such:
 * obj := Constructor(capacity);
 * param_1 := obj.Get(key);
 * obj.Put(key,value);
 */
```

### 磁盘调度算法

-   `先来先服务`算法
-   `最短寻道时间优先`算法 **产生饥饿的原因是磁头在一小块区域来回移动**。
-   `扫描`算法，`电梯`算法
-   `循环扫描`算法,**磁道只响应一个方向上的请求**。返回时快速返回到最边缘，不处理请求
-   `LOOK` 与 `C-LOOK` 算法，**磁头在移动到「最远的请求」位置，然后立即反向移动。** 
	- LOOK **反向移动的途中会响应请求**。优化扫描算法
	- C-LOOK**反向移动的途中不会响应请求**。优化循环扫描算法

### 有什么标准去评判哪个调度算法的好坏么

## IO

### io操作

I/O 就是指内存与外部设备之间的交互（数据拷贝）
就是将数据写入内存或从内存输出的过程，也指应用程序和外部设备之间的数据传递，常见的外部设备包括文件、管道、网络连接。

### io模型

[解析 Golang 网络 IO 模型之 EPOLL - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/609629545)

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304022015547.png)

### 阻塞与非阻塞

IO操作阻塞非阻塞，是指当你发起一个IO操作后，如果IO没有准备好，你的线程是否要停留在那里等待IO准备好。
阻塞等待：释放cpu资源
非阻塞：忙轮询，占用cpu资源

### 1.BIO-阻塞模式IO

用户进程从发起请求，到最终拿到数据前，一直挂起等待； 
数据会由用户进程完成拷贝

### 2. NIO – 非阻塞模式I/O

用户进程发起请求，如果数据没有准备好，那么立刻告知用户进程未准备好；此时用户进程可选择继续发起请求、或者先去做其他事情，稍后再回来继续发请求，直到被告知数据准备完毕，可以开始接收为止；
数据会由用户进程完成拷贝

### 3. AIO – 异步I/O模型

发起请求立刻得到回复，不用挂起等待；
数据会由内核进程主动完成拷贝

### 4. 信号驱动 IO（signal driven I/O， SIGIO）

首先我们允许套接口进行信号驱动 I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。

### 5. io多路复用

多路复用指的是，由一个执行单元，同时对多个对象提供服务，形成一对多的服务关系.

-   多路：存在多个需要处理 io event 的 fd（linux 中，一切皆文件，所有事务均可抽象为一个文件句柄 file descriptor，简称 fd）
-   复用：复用一个 loop thread 同时为多个 fd 提供处理服务（线程 thread 是内核视角下的最小调度单位；多路复用通常为循环模型 loop model，因此称为 loop thread）
- IO：在操作系统中，数据在内核态和用户态之间的读写操作

io多路复用是一种同步的IO模型，利用IO多路复用模型，可以实现一个线程监视多个文件句柄。一旦某个文件句柄就绪，就能够通知到对应的应用程序进行相应的读写操作；如果没有句柄就绪时，就会阻塞应用程序，从而释放出CPU资源。

网络中：一个或多个线程处理多个TCP连接，无需创建和维护过多的线程

实现IO多路复用的原型有三种，select、poll、epoll

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202303281534380.png)

#### Select

轮询+遍历

-   每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大
-   同时，每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大
-   select支持的文件描述符数量太小，默认最大支持(32位)1024、(64位)2048个
-   主动轮询效率很低

1. fdset 是1024位bitmap
2. fdset不可重用，每次都要重新赋空值
3. 用户态和内核态开销
4. 返回的时候并不知道具体哪个fdset被置位，需要再遍历一次

select 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

**优点**：

1. 跨平台支持性好，几乎所有平台都支持
2. select可设置的监听时间timeout精度更好，可精确到微秒，而poll为毫秒。

**缺点**：

1. 需要用户遍历监控的所有文件描述符，随着FD数量的增多而导致性能下降。
2. 操作系统对单个进程打开的FD数量是有限制的，一般默认1024个
3. select每次调用时都要将文件描述符集合从用户态拷贝到内核态，开销较大

-   一次可以处理多个 fd，体现多路. 但 fd 数量有限，最多 1024 个
-   loop thread 通过 select 将一组 fd 提交到内核做监听
-   当 fd 中无 io event 就绪时，loop thread 会陷入阻塞
-   每当这组 fd 中有 io event 到达时，内核会唤醒 loop thread
-   loop thread 无法精准感知到哪些 fd 就绪，需要遍历一轮 fd 列表，时间复杂度 O(N)
-   托付给内核的 fd 列表只具有一轮交互的时效. 新的轮次中，loop thread 需要重新将监听的 fd 列表再传递给内核一次

#### Poll

轮询+遍历，但是采用结构体数组(链表)方式存储FD，并且可以重用fds

```c
struct poolfd {
	int fd;
	short events;
	short revents;
}
```

**优点**：

1. 没有FD最大数量的限制
2. poll在文件描述符数量较大时速度比select更快；

**缺点**：

1. 需要用户遍历监控的所有文件描述符，随着FD数量的增多而导致性能下降
2. 存储文件描述符的链表不会保存在内核中，poll每次调用时都要将链表从用户空间拷贝到内核空间，开销较大；
3. poll的工作模式为水平触发（LT），不支持边沿触发（ET），效率较低。

#### epoll

内核态和用户态共享epfd（fds），省去了切换开销
每次会将fds重排，并且会返回当前内部有n个fds被置位了，因此只需要遍历前n个就可以，只关心活跃的链接，不需要遍历全部集合

epoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。

**优点**：

1. 将轮询改成了回调，大大提高了CPU的执行效率，也不会随着FD的数量增加而导致效率下降。
2. epoll由一组函数实现，epoll_create创建的红黑树保存在内核中，epoll_ctl只需从红黑树中添加、删除或修改节点，无需重复将已有的文件描述符拷贝到内核态中，开销较小；
3. 没有文件描述符连接数限制，只跟系统内存的大小有关；
4. epoll支持**边沿触发**，可减少epoll_wait调用次数，提高效率；

**缺点**：只能在linux下工作

-   每次处理的 fd 数量无上限
-   loop thread 通过 epoll_create 操作创建一个 epoll 池子
-   loop thread 通过 epoll_ctl 每次将一个待监听的 fd 添加到 epoll 池中
-   每当 fd 列表中有 fd 就绪事件到达时，会唤醒 loop threa. 同时内核会将处于就绪态的 fd 直接告知 loop thread，无需额外遍历

综上所述，select 和 epoll 等多路复用操作利用了内核的能力，能在待监听 fd 中有 io event 到达时，将 loop thread 唤醒，避免无意义的主动轮询操作.

其中，epoll 相比于 select 的核心性能优势在于：

-  loop thread 被唤醒时，能明确知道哪些 fd 需要处理，减少了一次额外遍历的操作，时间复杂度由 O(N) 优化到 O(1)
-  epoll 通过将创建池子和添加 fd两个操作解耦，实现了池中 fd 数据的复用，减少了用户态与内核态间的数据拷贝成本

epoll工作原理：内核利用epoll_create创建一个epfd文件描述符，并利用红黑树数据结构将其存储到根结点上，再用epoll_ctl从红黑树中添加、修改或移除文件描述符，最后内核调用epoll_wait函数开始监听，epoll处于阻塞状态，当有事件发生或设置的等待时间timeout到了就会返回，返回时传出有事件发生文件描述符的结构体数组。与select、poll不一样的是，epoll直接传出有事件发生的文件描述符数组，不用遍历查询。

##### epoll_create

在内核开辟空间，创建一个 epoll 池子用于批量存储管理 fd，后续可以通过 epoll_ctl 往池子中增删改 fd.

```c
/** 
 * @param size 告诉内核监听的数目 
 * 
 * @returns 返回一个epoll句柄（即一个文件描述符） 
 */
int epoll_create(int size);
```

在内核创建一颗红黑树的根节点。，保证了所有增、删、改操作的平均时间复杂度维持在 O(logN) 的对数级水平.

就绪队列：
针对于 fd 的就绪 io event，由于通常数量有限，且每个事件都需要逐一处理，没有优先级之分，因此采用简单的双向链表实现即可.

##### epoll_ctl

在某个 epoll 池子中进行一个 fd 的增删改操作.
正是由于 epoll 中将 epoll_ctl 与 epoll_create 操作进行了解耦，才实现了对 epoll_create 时传递的 fd 数据的复用，减少了用户态和内核台之间对 fd 数据的重复传递
此外，在 epoll_ctl 实现时，也需要通过 epollevent 设置好回调事件，当 fd 有指定事件到达时，会被添加到就绪队列中，最终将 loop thread 唤醒.

```c
/**
* @param epfd 用epoll_create所创建的epoll句柄
* @param op 表示对epoll监控描述符控制的动作
*           EPOLL_CTL_ADD(注册新的fd到epfd)
*           EPOLL_CTL_MOD(修改已经注册的fd的监听事件)
*           EPOLL_CTL_DEL(epfd删除一个fd)
* @param fd 需要监听的文件描述符
* @param event 告诉内核需要监听的事件
*
* @returns 成功返回0，失败返回-1, errno查看错误信息
*/
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);


struct epoll_event {
	__uint32_t events; /* epoll 事件 */
	epoll_data_t data; /* 用户传递的数据 */
}

/*
 * events : {EPOLLIN, EPOLLOUT, EPOLLPRI, EPOLLHUP, EPOLLET, EPOLLONESHOT}
 */
typedef union epoll_data {
	void *ptr;
	int fd;
	uint32_t u32;
	uint64_t u64;
} epoll_data_t;
```

##### epoll_wait

从对应 epoll 池子中获取就绪的 epollevent，从中可以关联到对应的 fd 和 loop thread 信息.

```c
/**
*
* @param epfd 用epoll_create所创建的epoll句柄
* @param event 从内核得到的事件集合
* @param maxevents 告知内核这个events有多大,
* 注意: 值 不能大于创建epoll_create()时的size.
* @param timeout 超时时间
* -1: 永久阻塞
* 0: 立即返回，非阻塞
* >0: 指定微秒
*
* @returns 成功: 有多少文件描述符就绪,时间到时返回0
* 失败: -1, errno 查看错误
*/
int epoll_wait(int epfd, struct epoll_event *event, int maxevents, int timeout);
```

##### epoll编程架构

```c
int epfd = epoll_crete(1000);

//将 listen_fd 添加进 epoll 中
epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd,&listen_event);

while (1) {
	//阻塞等待 epoll 中 的fd 触发
	int active_cnt = epoll_wait(epfd, events, 1000, -1);

	for (i = 0 ; i < active_cnt; i++) {
		if (evnets[i].data.fd == listen_fd) {
			//accept. 并且将新accept 的fd 加进epoll中.
		}
		else if (events[i].events & EPOLLIN) {
			//对此fd 进行读操作
		}
		else if (events[i].events & EPOLLOUT) {
			//对此fd 进行写操作
		}
	}
}
```

##### 触发模式

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202303281559326.png)

epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：

LT模式：**当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。**

ET模式：**当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。**

**ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。**

##### 如果epoll服务器监听端口是80，现有1024个客户端连接，内部的红黑树发生什么变化？

当epoll服务器监听端口是80时，每个客户端连接都会生成一个epoll_event结构体，该结构体包含有该连接的文件描述符、事件类型和回调函数等信息，并添加到内部的红黑树上。
当有1024个客户端连接时，会有1024个epoll_event结构体被添加到内部的红黑树上，这会导致红黑树的大小增加到1024个节点，同时由于红黑树的自平衡性质，可能会引起一些节点的旋转和重新着色，以维持红黑树的平衡.

#### 总结

select，poll，epoll都是I/O多路复用机制，即能监视多个fd，一旦某fd就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质都是**同步I/O**，因为他们都需在读写事件就绪后，自己负责进行读写，即该读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O实现会负责把数据从内核拷贝到用户空间。

select，poll需自己主动不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但它是设备就绪时，调用回调函数，把就绪fd放入就绪链表，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但select和poll在“醒着”时要遍历整个fd集合，而epoll在“醒着”的时候只需判断就绪链表是否为空，节省大量CPU时间，这就是回调机制带来的性能提升。

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，且把current往等待队列上挂也只挂一次（在epoll_wait开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少开销。

#### epoll为什么不支持磁盘，为什么kqueue支持磁盘

epoll的作用是在同时监听多个io是否可读可写（是否Ready），磁盘文件始终是Ready的状态，而实际读取的时候如果文件数据不在内存缓存中的话，read本身还是会”阻塞”住等待数据从磁盘读出来。

epoll是POSIX的，而kqueue是FreeBSD的
kqueue抽象出了高级的event事件，相比于epoll只能等io是否ready，kqueue可以直接监听类似“文件数据已经加载到内存”这样的事件，这看上去就比epoll有意义多了。所以kqueue可以支持磁盘io。它相当于托管了整个磁盘IO操作，做到让磁盘io看上去是“非阻塞”的。

### 新建一个文件，描述符从多少开始，不同文件描述符是否可以重复 

在进程中，**当我们每打开一个文件时，操作系统都会创建相应的数据结构描述目标文件**，于是就产生了我们**描述文件的file结构体**（**每打开一个文件都会创建一个描述该文件的结构体**），表示一个已经打开的文件对象。而进程执行open系统调用，所以必须让进程和文件关联起来。**每个进程都有一个指针\*files, 指向一张表files_struct,** 该表最重要的部分就是**包涵一个指针数组，每个元素都是一个指向打开文件的指针！**

**在files_struct的指针数组中，找到当前没有被使用的最小的一个下标，就作为新的文件描述符。**

因为文件描述符0,1,2对应的是系统调用的标准输入，标准输出，标准错误。所以如果我打开一个a文件，此时a文件描述符就是3，再打开一个b文件那么这个b文件的文件描述符就是4。以此类推。

## io多路复用了解吗？

先答io多路复用是什么，再答select、poll、epoll

io多路复用是一种同步的IO模型，利用IO多路复用模型，可以实现一个线程监视多个文件句柄。一旦某个文件句柄就绪，就能够通知到对应的应用程序进行相应的读写操作；如果没有句柄就绪时，就会阻塞应用程序，从而释放出CPU资源。
实现IO多路复用的原型有三种，select、poll、epoll

### 提升了什么

IO多路复用主要提升了CPU的效率，具体来说，它可以==减少CPU的空闲等待时间，避免了频繁的上下文切换和进程间的数据复制==，从而提高CPU的利用率和吞吐量。这是因为，在传统的同步阻塞I/O模型中，当一个进程在等待I/O操作完成时，CPU会进入空闲等待状态，浪费了宝贵的CPU资源。而采用IO多路复用技术，可以将多个I/O操作的等待集中在一个地方，并且在数据准备好时通知进程，进程再通过非阻塞I/O将数据读取出来，避免了CPU空闲等待的情况，提高了CPU的利用率。此外，IO多路复用还可以避免频繁的上下文切换和进程间的数据复制，减少了CPU的负担，从而进一步提高了CPU的性能。

## CPU密集型 和 I/O密集型

-   I/O密集型：`当线程等待时间所占比例越高，需要越多线程`，启用其他线程继续使用CPU，以此提高CPU的利用率；
-   CPU密集型：`当线程CPU时间所占比例越高，需要越少的线程`。任务越多，花在进程、线程切换的时间就越多，通常线程数和CPU核数一致即可，这一类型在开发中主要出现在一些计算业务频繁的逻辑中。

I/O密集型任务的特点是CPU消耗很少，任务的大部分时间都在等待I/O操作完成（磁盘I/O远低于内存、CPU速度）。`涉及到网络、磁盘I/O的任务多是I/O密集型任务`。I/O密集型任务，线程数越多，CPU效率越高，但也有相对限度

## 临界区是什么意思 

每个进程中访问临界资源（比如全局变量等公用资源）的那段程序（代码）称为临界区（临界资源是一次仅允许一个进程使用的共享资源，如全局变量等），也称为临界段。

由于该部分代码访问了共享资源，因此多个线程或进程在同时执行时可能会产生竞争条件（Race Condition），从而导致程序出现不可预期的结果。

为了避免临界区中的竞争条件，需要通过同步机制来控制多个线程或进程的访问。常见的同步机制包括`互斥锁`（Mutex）、`信号量`（Semaphore）等。在临界区中，通过获取锁或信号量来保证只有一个线程或进程能够访问共享资源，从而避免了竞争条件的发生。

需要注意的是，临界区的大小应该尽量小，避免出现过多的竞争条件，从而提高程序的并发性能。同时，在进行临界区的代码开发时，也需要注意避免死锁（Deadlock）等问题。

## 程序调用read过程中有那些数据拷贝 

[原来 8 张图，就可以搞懂「零拷贝」了 - 小林coding - 博客园 (cnblogs.com)](https://www.cnblogs.com/xiaolincoding/p/13719610.html)

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304111653046.png)

-   用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；
-   操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；
-   DMA 进一步将 I/O 请求发送给磁盘；
-   磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
-   **DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务**；
-   当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；
-   CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；

### 传输文件

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304111655584.png)

1. 从磁盘复制数据到内核态内存
2. 从内核态内存复制到用户态内存
3. 从用户态内存复制到网络驱动的内核态内存
4. 网络驱动的内核态内存复制到网卡中进行传输

### 什么是零拷贝 

零复制（英语：Zero-copy；也译零拷贝）技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽

零拷贝（Zero-Copy）是一种 I/O 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。 其在 FTP 或者 HTTP 等协议中可以显著地提升性能。 但是需要注意的是，并不是所有的操作系统都支持这一特性，**目前只有在使用 NIO 和 Epoll 传输时才可使用该特性**

零拷贝技术实现的方式通常有 2 种：

-   mmap + write
-   sendfile

#### mmap

`mmap()` 系统调用函数会直接把内核缓冲区里的数据「**映射**」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304111657165.png)

-   应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
-   应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
-   最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

#### sendfile

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304111658574.png)

首先，它可以替代前面的 `read()` 和 `write()` 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。

其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。

但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（_The Scatter-Gather Direct Memory Access_）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。

对于支持网卡支持 SG-DMA 技术的情况下， `sendfile()` 系统调用的过程发生了点变化，具体过程如下：

-   第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
-   第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；

所以，这个过程之中，只进行了 2 次数据拷贝，如下图：

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202304111811235.png)

这就是所谓的**零拷贝（_Zero-copy_）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。**。

零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**

所以，总体来看，**零拷贝技术可以把文件传输的性能提高至少一倍以上**。

### PageCache有什么用

回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是**磁盘高速缓存（_PageCache_）**。

由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。

读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。

但是，内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。

那问题来了，选择哪些磁盘数据拷贝到内存呢？

我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 **PageCache 来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。

所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。

还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，**PageCache 使用了「预读功能」**。

比如，假设 read 方法每次只会读 `32 KB` 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。

所以，PageCache 的优点主要是两个：

-   缓存最近被访问的数据；
-   预读功能；

这两个做法，将大大提高读写磁盘的性能。

**但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能**

这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。

另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：

-   PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；
-   PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；

所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。

## pv原语 

PV原语通过操作信号量来处理进程间的同步与互斥的问题。其核心就是一段不可分割不可中断的程序。

`P原语`：P是荷兰语Proberen（测试）的首字母。为**阻塞原语**，负责把当前进程由运行状态转换为阻塞状态，直到另外一个进程唤醒它。操作为：==申请一个空闲资源==（把信号量减1），若成功，则退出；若失败，则该进程被阻塞；

`V原语`：V是荷兰语Verhogen（增加）的首字母。为**唤醒原语**，负责把一个被阻塞的进程唤醒，它有一个参数表，存放着等待被唤醒的进程信息。操作为：==释放一个被占用的资源==（把信号量加1），如果发现有被阻塞的进程，则选择一个唤醒之。

## 时间片轮转具体过程 

该算法中，将一个较小时间单元定义为时间量或时间片。时间片的大小通常为 10~100ms。就绪队列作为循环队列。CPU 调度程序循环整个就绪队列，为每个进程分配不超过一个时间片的 CPU。  
  
为了实现 RR 调度，我们再次将就绪队列视为进程的 FIFO 队列。新进程添加到就绪队列的尾部。CPU 调度程序从就绪队列中选择第一个进程，将定时器设置在一个时间片后中断，最后分派这个进程。

## CPU L123缓存 

CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。

-   对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；
-   对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；

### 什么时机才把 Cache 中的数据写回到内存

-   写直达（_Write Through_）
-   写回（_Write Back_）

#### 写直达

保持内存与 Cache 一致性最简单的方式是，**把数据同时写入内存和 Cache 中**，这种方法称为**写直达（_Write Through_）**。

在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：

-   如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
-   如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

写直达法很直观，也很简单，但是问题明显，无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响。

#### 写回

既然写直达由于每次写操作都会把数据写回到内存，而导致影响性能，于是为了要减少数据写回内存的频率，就出现了**写回（_Write Back_）的方法**。

在写回机制中，**当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中**，减少了数据写回内存的频率，这样便可以提高系统的性能。

可以发现写回这个方法，在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。

这样的好处是，如果我们大量的操作都能够命中缓存，那么大部分时间里 CPU 都不需要读写内存，自然性能相比写直达会高很多。

## 写时复制 

**写时复制**（**Copy-on-write**，简称**COW**）是一种计算机程序设计(领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。