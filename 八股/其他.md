## 限流

漏桶和令牌桶都是常用的限流算法，用于控制系统的流量，防止系统被过度访问而崩溃。总的来说，漏桶算法适用于需要稳定处理请求的场景，而令牌桶算法适用于需要应对瞬时流量激增的场景。

### 固定窗口算法

劣势：临界时间点产生突发流量，统计数量不准确。

设每分钟请求数量为 60 个，每秒可以处理 1 个请求，用户在 00:59 发送 60 个请求，在 01:00 发送 60 个请求 此时 2 秒钟有 120 个请求(每秒 60 个请求)，远远大于了每秒钟处理数量的阈值。

### 滑动窗口算法 

滑动窗口算法弥补了计数器算法的不足。滑动窗口算法把间隔时间划分成更小的粒度，当更小粒度的时间间隔过去后，把过去的间隔请求数减掉，再补充一个空的时间间隔。

**当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。**

滑动窗口设置得越精细，限流的效果越好，但滑动窗口的时间间隔（小格子）多了，存储的空间也会增加。

### 漏桶

漏桶算法是一种固定容量的算法，类似于水桶，它可以以恒定的速率流出请求，无论输入速率有多快，最终输出速率都不会超过指定的限制。

漏桶算法的实现方式是，在服务端维护一个`固定容量`的队列（即漏桶），并以恒定速率处理请求。如果请求速率过快，请求将被加入到漏桶中，等待服务端处理。==当漏桶已满时，新的请求将被丢弃，从而控制了流量。==

漏桶算法的优点是实现简单，适用于需要**稳定处理请求**的场景，但是如果出现瞬时流量激增的情况，漏桶算法无法应对。

### 令牌桶

令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。
对于从桶里取不到令牌的场景，我们可以选择等待也可以直接拒绝并返回。

令牌桶算法的优点是可以应对**瞬时流量激增**的情况，因为它可以通过调整发放令牌的速率来控制请求的处理速度，但是实现相对漏桶算法更复杂一些。

limiter 并不是每隔一段时间更新当前桶的数量，而是记录了上次访问时和当前桶中令牌的数量，当再次访问时，通过上次访问时间计算出当前令牌的数量，决定是否可以发放。

```go
// The methods AllowN, ReserveN, and WaitN consume n tokens. 
type Limiter struct {
	mu sync.Mutex 
	limit Limit 
	burst int 
	tokens float64 // last is the last time the limiter's tokens field was updated 
	last time.Time // lastEvent is the latest time of a rate-limited event (past or future) 
	lastEvent time.Time 
}
```

后期使用Redis实现令牌桶算法：
使用lua脚本保证原子性
使用两个kv存储，一个存储当前数量，一个存储更新时间
记录当前key的值以及上次更新的时间，
定义返回值，是个数组，包含：是否触发限流（1限流 0通过）、当前桶中的令牌数

1. 首先判断当前令牌桶是否存在，可能是过期或刚启动
2. 如果不存在就创建桶
3. 存在就通过时间计算差计算当前剩余值减一放回，更新时间。
4. 如果桶中剩余数量小于零，返回限流

-   将获取令牌的操作封装在Lua脚本中。由于Lua脚本在redis中天然的原子性，可以实现我们的需求；
-   若太过依赖redis的话，我们可以每次请求redis时，预支一些令牌放在本地，通过本地的进程锁来分配这些令牌，消耗完毕在此请求redis。

Redis允许在Lua脚本中调用redis.call()或者redis.pcall()来执行Redis命令，如果Lua脚本对Redis的数据做了更改，那么除了执行脚本本身以外还需要两个额外的操作：

1.  把这段Lua脚本持久化到AOF文件中，保证Redis重启时可以回放执行过的Lua脚本。
2.  把这段Lua脚本复制给备库执行，保证主备库的数据一致性。

由于上述两步，现在就很容易理解为什么Redis要求Lua脚本必须是纯函数的形式了，想象一下给定一段Lua脚本和输入参数却得到了不同的结果，这就会造成重启前后和主备库之间的数据不一致，Redis不允许对数据一致性的破坏。

```lua
-- 定义返回值res[1]是否触发限流（1限流 0通过）res[2]当前桶中的令牌数
local res={}
res[1]=0
--local curtime=redis.call('time')
local inteval_time=tonumber(ARGV[1]) -- 放入令牌桶的间隔时间
local current_time=tonumber(ARGV[2]) -- 当前时间

local amount=10 -- 一次取几个
local key_expire_time=1000*3600 -- 过期时间
local inflow__per_unit=100 -- 每次放多少
local capacity=1000
local st_key='last_update'
local bucket_amount = 0

-- 上次向桶中投放令牌的时间
local last_time=redis.call('get',st_key)
-- 当前令牌数
local current_value = redis.call('get',KEYS[1])

if(last_time == false or current_value == false) -- 令牌桶也不存在或过期，重新生成令牌桶
then
    bucket_amount = capacity - amount;
    -- 生成令牌桶
    redis.call('set',KEYS[1],bucket_amount,'PX',key_expire_time)
    -- 设置投放时间
    redis.call('set',st_key,current_time,'PX',key_expire_time)
    res[2]=bucket_amount
    return res
end

current_value = tonumber(current_value)
last_time=tonumber(last_time)
local past_time=current_time-last_time --当前时间-上次投放的时间
if(past_time<inteval_time)
then
    -- 不到放入令牌时间，直接从令牌桶中取走令牌
    bucket_amount=current_value-amount
else
    -- 需要放入令牌
    local cur_times = past_time/inteval_time -- 放几次

    cur_times=math.floor(cur_times)

    bucket_amount=current_value+cur_times*inflow__per_unit
    if (bucket_amount > capacity)
    then
        bucket_amount = capacity-amount
    end
    -- 有新投放，更新投放时间
    redis.call('set',st_key,current_time,'PX',key_expire_time)
end

res[2]=bucket_amount

-- 触发限流
if(bucket_amount<0)
then
    res[1]=1
    return res
end

-- 更新令牌桶KV
redis.call('set',KEYS[1],bucket_amount,'PX',key_expire_time)
return res
```

## 鉴权JWT

JWT( JSON-WEB-TOKEN ) 是比较新的一种登录方式，他利用时间换空间的方式，服务端将用户的信息相关信息进行加密并返回到客户端，即签发了 一个"令牌"，在令牌的有效期内，客户端可以通过传递令牌的方式与服务端通信。JWT 登录整体流程如下：

- 用户输入用户名密码进行登录
- 服务端验证用户名密码，成功后，将用户的相关信息（通常是 user_id）及一些附加信息通过 JWT 方式进行加密，并返回给客户端。
- 客户端可以用任意方式储存服务器返回的 JWT ，之后只需在每次请求时，将 JWT 通过某种方式传递给后端。JWT默认的传递方式为:
```json
"headers": {
 'Authorization': 'Bearer ' + token // JWT 规定的的表示形式
}
```
- 服务器收到请求后，获取并验证 JWT，从而获取用户的信息（通常是 user_id 及一些附加信息），即服务器不需要储存每个用户的状态（即 session）， 只需要在每次请求时获取并解析 JWT，即可完成用户身份校验和用户基本信息的获取。

### 各部分信息

-   Header（头部）：alg：签名的算法；typ：token的类型，"JWT"
-   Payload（负载）
-   Signature（签名）：对前两部分的签名，防止数据篡改。

### 特点

1. JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。不加密的情况下，不要将秘密数据写入 JWT。
2. JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。
3. JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。
4. JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。
5. 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。
6. 后端每次接口请求都需要进行 JWT 的加解密，计算压力增大。

### 为什么要用两个，而不用一个token, refresh token的作用 

refreshToken就是用来在accessToken过期以后来重新获取accessToken的

-   用户在访问网站时，`accessToken`被盗取了，此时攻击者就可以拿这个`accessToke`访问权限以内的功能了。如果`accessToken`设置一个短暂的有效期2小时，攻击者能使用被盗取的`accessToken`的时间最多也就2个小时，除非再通过`refreshToken`刷新`accessToken`才能正常访问。
    
-   设置`accessToken`有效期是永久的，用户在更改密码之后，之前的`accessToken`也是有效的

### 为什么不用Cookie+Session方式？

`Session`是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；
`Cookie`是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

cookie + session 是最传统的登录方式，利用浏览器默认行为，每次请求将登录后设置好的 cookie 发送给服务端， 服务端通过 cookie 中的信息（ session_id），获取用户的登录信息。整体流程如下：

- 用户输入用户名密码进行登录
- 服务端验证用户名密码，成功后，生成唯一的 session_id 储存起来（可以是内存、数据库等，通常使用 redis ）。
- 通过设置 set-cookie，将 session_id 返回给前端并储存在浏览器 cookie 中。
- cookie 过期前，对该系统的每次请求都将会带上 cookie（浏览器默认行为），后端通过 cookie 中的信息，获取用户的 session_id 信息。 并在后端（ redis ）查询出对应用户的信息。

优点 ：原理简单、实现方便

**缺点**:

- **服务器端需维护大量 session_id**，有一定负担。（目前通常将 session_id 放在 redis中，也解决了服务器集群下 session_id 同步问题）
- 无法阻止[跨站请求伪造**CSRF**](https://zh.m.wikipedia.org/zh/跨站请求伪造) 攻击。
- 这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。

## 异步写库

实现异步写库可以帮助减轻数据库的压力，提高系统的吞吐量和响应速度。在每次写入数据库操作时，不直接写入到MySQL数据库中，防止在高并发情况下数据库瓶颈出现。为了解决这个问题，我把所有的更新、插入数据库的需求，放入一个独立的goroutine中，使用channel进行数据的异步传递，也避免了多个goroutine之间的竞争和锁的使用，使代码更加简洁易于维护。

### 异步写库会带来一些数据一致性的问题，如何保证数据的一致性？

采用**先更新数据库再删除缓存**的方案
缺点：假如缓存删除失败或者更新数据库时，其他线程读到缓存的旧数据。但是仅是出现读取到一次旧值，并不会对主要数据产生影响。

### 保证数据一致性回写redis要注意什么？

先更新数据库再删除缓存，使用**双检加锁机制**锁住mysql，只让一个线程回写redis，完成数据一致性。

### 双检加锁

多个线程同时查询数据库的一条数据时，在第一个查询数据的请求上使用一个互斥锁来锁住它，其他线程走到这一步拿不到锁，就等到第一个线程查询到数据后，然后做缓存。其他线程发现有缓存后就不会去读取mysql。

双检加锁就是在加锁后再次查询reids缓存，二次查询无数据才去查询mysql

### 如果存在更新频繁的热点key怎么办

同一热点key保留2份，A有过期时间，B无

先查询A的，查询不到，则：
1.  后端查询DB更新缓存
2.  查询带后缀返回给调用方

### 延迟双删用过吗？会有哪些问题

延迟双删用于先删除redis缓存再更新mysql的策略中：

延迟双删：==先删除缓存在写数据库再延迟一段时间再次删除缓存==

#### why？

假设A删除完redis缓存，然后更新mysql，
此时B读取数据，redis找不到，读mysql然后回写到redis中
A再次回写redis出现问题

因此在A第一次删除缓存时，延迟一段时间再次删除

#### 延迟时间

1. 估算一次读取数据然后写入缓存中的时间，在此基础上加几百毫秒，确保读请求结束，写请求可以删除读请求造成的缓存脏数据
2. 启动一个后台监控程序，比如WatchDog

### 删除缓存失败怎么办？

1. 可以把要删除的缓存值或者要更新的数据库值暂存到消息队列中（Kafka，RabbitMQ等）
2. 当程序没有删除缓存或者更新数据库时，可以从消息队列中读取这些值，然后再次进行删除或更新。
3. 如果成功删除或更新，就从消息队列中弹出这些值，防止重复操作。此时如果还是失败就再次重试
4. 如果重试一定次数还没成功，就要发送报错信息，通知运维

流程：
1. 更新数据库
2. 数据库写入binlog
3. 订阅程序从binlog中提取出信息
4. 另起一段非业务代码，获取该信息
5. 尝试删除缓存，发现删除失败
6. 将这些信息发送到消息队列
7. 从消息队列中获取该数据，执行重试操作


如果缓存删除失败，就会出现缓存与数据库数据不一致的情况。不过删除行为是幂等的，可以通过重试机制来保证缓存中的数据终将被删除。

### 如何保证最终一致性？

给缓存设置过期时间，定期清理并回写。
以mysql的数据库写入库为准，对缓存操作尽最大努力即可。

#### 如果业务层必须保证读取一致性？

在更新数据库时先暂停Redis缓存并发读请，等操作完删除缓存后再读取数据。

#### 如果想要mysql有改动，立即同步redis如何做？

使用阿里巴巴canal，会读取mysql的binlog

MySQL binlog增量订阅消费+消息队列+增量数据更新到redis读Redis

热数据基本都在Redis写MySQL:增删改都是操作MySQL更新Redis数据：MySQ的数据操作binlog，来更新到Redis：

1)数据操作主要分为两大块：一个是全量(将全部数据一次写入到redis)一个是增量(实时更新)。

这里说的是增量,指的是mysql的update、insert、delate变更数据。

2)读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。
这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。
当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。

