## go基础

### 数据类型占用空间 

| 类型    | 空间                          |
| ------- | ----------------------------- |
| int8    | 1                             |
| int16   | 2                             |
| int32   | 4                             |
| int64   | 8                             |
| int     | 4(32位)/8(64位)               |
| float32 | 4                             |
| float64 | 8                             |
| string  | 1(英文)/2~4(中文取决于字符集) |
| bool    | 1                             |
| byte    | 1                             | 

### func 

`Go`语言中，函数被认为是一等公民（`First-class citizens`），这意味着函数在语言中具有与其他类型（如整数、字符串等）相同的权利和地位。以下是函数在`Go`语言中被视为一等公民的原因：

1. **函数可以作为值进行传递**：在`Go`语言中，函数可以像其他类型的值一样被传递给其他函数或赋值给变量。这意味着可以将函数作为参数传递给其他函数，也可以将函数作为返回值返回。
2. **函数可以赋值给变量**：在`Go`语言中，可以将函数赋值给变量，然后通过变量来调用函数。这种能力使得函数可以像其他数据类型一样被操作和处理。
3. **函数可以匿名定义**：`Go`语言支持匿名函数的定义，也称为闭包。这意味着可以在不给函数命名的情况下直接定义和使用函数，更加灵活和便捷。
4. **函数可以作为数据结构的成员**：在`Go`语言中，函数可以作为结构体的成员，从而使得函数与其他数据一起存储在结构体中。这种特性使得函数能够更好地与数据相关联，实现更复杂的功能。

### Init()函数

golang程序初始化先于main函数执行，由runtime进行初始化，初始化顺序如下：

1.  初始化导入的包（包的初始化顺序并不是按导入顺序（“从上到下”）执行的，runtime需要解析包依赖关系，==没有依赖的包最先初始化==，与变量初始化依赖关系类似）
2.  初始化包作用域的变量（该作用域的变量的初始化也并非按照“从上到下、从左到右”的顺序，runtime解析变量依赖关系，没有依赖的变量最先初始化）
3.  执行包的init函数；

-   init函数先于main函数自动执行，不能被其他函数调用；
-   init函数没有输入参数、返回值；
-   每个包可以有多个init函数；
-   **包的每个源文件也可以有多个init函数**，这点比较特殊；
-   同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。
-   不同包的init函数按照包导入的依赖关系决定执行顺序。

- `init` 函数没有输入参数、返回值，也未声明，所以无法被显示的调用，不能被引用（赋值给函数变量），否则会出现编译错误
- 一个`go`文件可以拥有多个`init`函数，执行顺序按定义顺序执行
- 初始化常量/变量优于 `init` 函数执行，`init`函数先于`main`函数自动执行。执行顺序先后为： `const`常量 > `var` 变量 > `init`函数 > `main`函数

#### 只想调用包的init函数，不需要其他方法

```go
import _ "net/http/pprof"
```

**golang对没有使用的导入包会编译报错，但是有时我们只想调用该包的init函数，不使用包导出的变量或者方法，这时就采用上面的导入方案。**

### 结构体

Go 语言中没有类的概念，因此在 Go 中结构体有着更为重要的地位。结构体是复合类型(composite types)，当需要定义一个类型，它由一系列属性组成，每个属性都有自己的类型和值的时候，就应该使用结构体，它把数据聚集在一起。然后可以访问这些数据，就好像它是一个独立实体的一部分。结构体也是值类型，因此可以通过 new 函数来创建。

#### 初始化

因为Go语言结构体是一个值类型，也就是说当你声明了一个结构体类型的变量时，实际上是在内存中分配了一块连续的内存空间的，这个空间里面包含这个结构体中定义的所有字段。字段均为默认零值

#### go的结构体能不能比较

golang中 `Slice`，`Map`，`Func` 这三种数据类型是不可以直接比较的。

同一个struct的两个实例可比较也不可比较，当结构不包含不可直接比较成员变量时可直接比较，否则不可直接比较

#### 对struct{}{}的理解 

结构体常用于抽象表示一类事物，可以拥有行为或者状态。

struct{ } ：表示struct类型  
struct{}{}是一种普通数据类型，一个无元素的结构体类型，通常在没有信息存储时使用。  
==优点是大小为0，不需要内存来存储struct {}类型的值==。

**空结构体是一种特殊的结构体，没有任何字段，不会进行内存对齐，也不占用内存，但是有固定的地址 zerobase。**

struct {} {}：表示struct类型的值，该值也是空。  
struct {} {}是一个复合字面量，它构造了一个struct {}类型的值，该值也是空。

##### 应用场景 

1. struct{}类型的chan，用于传递信号，用于流转各类状态或是控制并发情况。
2. map\[type]struct{}，实现set
3. 实现方法接收者，不占空间，也便于未来针对该类型进行公共字段等的增加

**实现方法接收者**：

在业务场景下，我们需要将方法组合起来，代表其是一个 ”分组“ 的，便于后续拓展和维护。
但是如果我们使用：

```go
type T string
func (s *T) Call()
```

又似乎有点不大友好，因为作为一个字符串类型，其本身会占据定的空间。
这种时候我们会采用空结构体的方式，这样==也便于未来针对该类型进行公共字段等的增加==。如下：

```go
type T struct{}

func (s *T) Call() {
}

func main() {
 var s T
 s.Call()
}
```

在该场景下，使用空结构体从多维度来考量是最合适的，易拓展，省空间，最结构化。

### 调用函数传入结构时应该传值还是传指针（函数传值都是**值传递**）

go都是值传递只是传的参数是值类型还是引用类型
**golang中所有函数参数传递都是传值，slice、map和chan看上去像引用只是因为他们内部有指针或本身就是指针而已**。由于它们本身就是引用类型，因此使用引用传递可以避免复制数据和额外的内存开销。

**string在底层实现上是引用类型，但是因为string不允许修改，只能生成新的对象，在逻辑上和值类型无差别。**

值传递或者指针传递都有可能发生逃逸，关键是有没有外部引用！！！，不是传指针就一定会逃逸！！！

当结构体很小且拷贝成本很低时，例如结构体中只包含几个基本类型的字段，可以直接传递结构体的值，这样可以避免创建指针的额外开销，而且较小的结构体会在栈上分配内存更加高效，减少GC压力。

当结构体很大时或者需要修改结构体中的字段时，传递指向结构体的指针会更加高效。因为在 Go 中，函数传递结构体时会进行一次值拷贝，如果结构体很大，则拷贝的成本也很高。而如果传递结构体的指针，函数就可以直接操作原始数据，避免了值拷贝的开销。

所以得出结论，当我们需要**修改结构体的变量内容的时候，方法传入的结构体变量参数需要使用指针**，**也就是结构体的地址。**

**需要修改map中的架构体的变量的时候也需要使用结构体地址作为map的value。**
**如果仅仅是读取结构体变量，可以不使用指针，直接传递引用即可。**
**\*type 这里的type这个变量存放的东西是地址，这点需要明确，需要使用&type获取到地址。**

#### 引用类型 

`引用类型` 变量存储的是一个地址，这个地址存储最终的值。内存通常在堆上分配。通过 GC 回收。

包括 **指针、slice 切片、管道 channel、接口 interface、map、函数**等。

==struct是值类型==

值类型 直接存放值，内存通常在栈中分配

应用类型变量存储的地址（也就是通过指针访问类型里面的数据），通常真正的值在堆上分配。当么有变量引用这个地址的时候，该值会被gc回收。

### make和new和var的区别？

`引用类型` 变量存储的是一个地址，这个地址存储最终的值。内存通常在堆上分配。通过 GC 回收。包括 指针、slice 切片、管道 channel、接口 interface、map、函数等。
`值类型`是 基本数据类型，int,float,bool,string, 以及数组和 struct 特点：变量直接存储值，内存通常在栈中分配，栈在函数调用后会被释放
对于`引用类型`的变量，我们不光要声明它，还要为它分配内容空间
对于`值类型`的则不需要显示分配内存空间，是因为go会默认帮我们分配好

简单的说，new只分配内存，make用于slice，map，和channel的初始化。
-   make和new都是golang用来分配内存的內建函数，且在堆上分配内存，==make 即分配内存，也初始化内存。new只是将内存清零(赋零值)，并没有初始化内存。==
-   make返回的还是==引用类型本身==；而new返回的是==指向类型的指针==。
-   make只能用来分配及初始化类型为==slice，map，channel==的数据；==new可以分配任意类型的数据==。

-   使用make()，来初始化slice，map 和channel 。
-   大多数场合，类型明确的场合下，使用短变量声明方式:=。
-   当使用文字方式初始化一个变量，并且需要指明类型时，使用var变量声明方式。
-   避免使用new()，除非你需要一个指针变量。
- 对于值类型的变量，**var 声明(包括结构体)**，系统会**默认为他分配内存空间**，并赋该类型的零值。

1.  new 和 make都是Go语言的两个内建函数，用于分配内存
2.  new 一般用来返回指针类型（一般不用），make返回引用类型（map, slice,chan 这三个引用)
3.  var 声明的 基本类型和struct这种已经分配了内存，并且赋零值了。

#### make的参数

```go
make(Type, len, cap)
```

`Type`：数据类型，必要参数，Type 的值只能是 slice、 map、 channel 这三种数据类型。
`len`：数据类型实际占用的内存空间长度，map、 channel 是可选参数，slice 是必要参数。
`cap`：为数据类型提前预留的内存空间长度，可选参数。所谓的提前预留是当前为数据类型申请内存空间的时候，提前申请好额外的内存空间，这样可以避免二次分配内存带来的开销，大大提高程序的性能。

### 深拷贝和浅拷贝

1.  **深拷贝**: 拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值。 实现深拷贝的方式:
	-   `copy(slice2, slice1)`；
	-   遍历slice进行append赋值
2. **浅拷贝∶**拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化。 实现浅拷贝的方式：引用类型的变量,默认赋值操作就是浅拷贝
	-   如`slice2 := slice1`

### go中的uint无符号整型是否可以相减（uint类型溢出 ）

不可以，如果相减会进行类型的自动推导c为uint32位，所以系统会把负数的1的正负位当做最高进制来算，造成数值很大

涉及到原码补码反码，计算机存储，减去一个数，相当于加上这个数的相反数的补码，负数的补码是符号位不变，其他位取反，相加变成一个很大的数，因为是无符号位，首位也会再变。

### string 的底层 

[go底层系列-string底层实现原理与使用 - 掘金 (juejin.cn)](https://juejin.cn/post/7111953294469267493)

string我们看起来是一个整体，但是本质上是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组，相比于切片仅仅少了一个Cap属性。

1. 相比于切片少了一个容量的cap字段，就意味着string是不能发生地址空间扩容；
2. 可以把string当成一个只读的byte切片类型；
3. string本身的切片是只读的，所以不会直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上的写入操作都是通过拷贝实现的。

```go
type stringStruct struct {
	str unsafe.Pointer //字符串首地址，指向底层字节数组的指针 
	len int //字符串长度 
}
// 实例化
func gostringnocopy(str *byte) string {
	ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)} 
	s := *(*string)(unsafe.Pointer(&ss)) 
	return s 
}
```

string的元素不能取地址，`s[i]` 代表第i个元素，但是`&s[i]`是违法的。

#### 如果一个string很大1G，值传递的时候也是复制一遍吗？可以修改吗？

传递指针的复制，不可以修改

string在底层实现上是引用类型，但是因为string不允许修改，只能生成新的对象，在逻辑上和值类型无差别。

#### string vs \[\]byte

既然`string`就是一系列字节，而`[]byte`也可以表达一系列字节，那么实际运用中应当如何取舍？

-   `string`可以直接比较，而`[]byte`不可以，所以`[]byte`不可以当map的key值。
-   因为无法修改`string`中的某个字符，需要粒度小到操作一个字符时，用`[]byte`。
-   `string`值不可为`nil`，所以如果你想要通过返回nil表达额外的含义，就用`[]byte`。
-   `[]byte`切片这么灵活，想要用切片的特性就用`[]byte`。
-   需要大量字符串处理的时候用`[]byte`，性能好很多。

#### string转成byte数组会发生内存拷贝吗？

会
字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝。那么问题来了。  
频繁的内存拷贝操作听起来对性能不大友好。**有没有什么办法可以在字符串转成切片的时候不用发生拷贝呢？**

```go
a :="aaa"  
addr := *(*reflect.StringHeader)(unsafe.Pointer(&a))  
b := *(*[]byte)(unsafe.Pointer(&addr))
```

那么如果想要在底层转换二者，只需要把 `StringHeader` 的地址强转成 `SliceHeader` 就行。那么go有个很强的包叫 `unsafe` 。

1. `unsafe.Pointer(&a)`方法可以得到变量`a`的地址。
2. `(*reflect.StringHeader)(unsafe.Pointer(&a))` 可以把字符串a转成底层结构的形式。
3. `(*[]byte)(unsafe.Pointer(&ssh))` 可以把ssh底层结构体转成byte的切片的指针。
4. 再通过 `*`转为指针指向的实际内容。

#### 两个string合并，用“+”，fmt，strings，哪个效率高 

[Go 字符串拼接6种，最快的方式 -- strings.builder - 技术颜良 - 博客园 (cnblogs.com)](https://www.cnblogs.com/cheyunhua/p/15769717.html)

通过两次`benchmark`对比，我们可以看到

- 当进行少量字符串拼接时，直接使用`+`操作符进行拼接字符串，效率还是挺高的，但是当要拼接的字符串数量上来时，`+`操作符的性能就比较低了；
- 函数`fmt.Sprintf`还是不适合进行字符串拼接，无论拼接字符串数量多少，性能损耗都很大，还是老老实实做他的字符串格式化就好了；
- `strings.Builder`无论是少量字符串的拼接还是大量的字符串拼接，性能一直都能稳定，这也是为什么`Go`语言官方推荐使用`strings.builder`进行字符串拼接的原因，在使用`strings.builder`时最好使用`Grow`方法进行初步的容量分配，观察`strings.join`方法的benchmark就可以发现，因为使用了`grow`方法，提前分配好内存，在字符串拼接的过程中，不需要进行字符串的拷贝，也不需要分配新的内存，这样使用`strings.builder`性能最好，且内存消耗最小。
- `bytes.Buffer`方法性能是低于`strings.builder`的，`bytes.Buffer` 转化为字符串时重新申请了一块空间，存放生成的字符串变量，不像`strings.buidler`这样直接将底层的 `[]byte` 转换成了字符串类型返回，这就占用了更多的空间。

同步最后分析的结论：

无论什么情况下使用`strings.builder`进行字符串拼接都是最高效的，不过要主要使用方法，记得调用`grow`进行容量分配，才会高效。`strings.join`的性能约等于`strings.builder`，在已经字符串slice的时候可以使用，未知时不建议使用，构造切片也是有性能损耗的；如果进行少量的字符串拼接时，直接使用`+`操作符是最方便也是性能最高的，可以放弃`strings.builder`的使用。

综合对比性能排序：

```go
strings.join` ≈ `strings.builder` > `bytes.buffer` > `[]byte`转换`string` > "+" > `fmt.sprintf
```

`strings.builder`避免内存拷贝的问题，使用了**强制转换来避免内存拷贝**

```go
func (b *Builder) String() string {
	return *(*string)(unsafe.Pointer(&b.buf)) 
}
```

`strings.join`也是基于`strings.builder`来实现的，唯一不同在于在`join`方法内调用了`b.Grow(n)`方法，这个是进行初步的容量分配，而前面计算的n的长度就是我们要拼接的slice的长度，因为我们传入切片长度固定，所以提前进行容量分配可以减少内存分配，很高效。

### rune 和 byte

#### rune

rune是`int32的别名`，代表字符的Unicode编码，采用4个字节存储，将string转成rune就意味着任何一个字符都用4个字节来存储其unicode值，这样每次遍历的时候返回的就是unicode值，而不再是字节了，这样就可以解决乱码问题了。
==中文、特殊字符==

#### byte

bytes操作的对象也是字节切片，与string的不可变不同，byte是可变的，因此string按增量方式构建字符串会导致多次内存分配和复制，使用bytes就不会，因而更高效一点

区别：`byte` 表示一个字节，`rune` 表示四个字节
```go
first := "社区" 
fmt.Println([]rune(first)) // 输出[31038 21306]
fmt.Println([]byte(first)) // [231 164 190 229 140 186]
```

### Slice切片

切片（Slice）是一个动态数组，它不需要指定长度，可以动态增长。切片是对底层数组的一层封装，支持对底层数组进行动态增删改操作。切片的定义方式为 `var s []int`，其中 s 为切片名，int 为元素类型。切片可以使用 append() 函数对其进行动态增长，例如 s = append(s, 1)。切片在内存中不是连续的存储空间，而是由一个指向底层数组的指针、长度和容量组成。

1.19源码：**切片一定会分配在堆上** [go/complit.go at master · golang/go · GitHub](https://github.com/golang/go/blob/master/src/cmd/compile/internal/walk/complit.go)
截取规则**左闭右开**

```go
type slice struct {
	array unsafe.Pointer
	len   int
	cap   int
}
```

使用var声名的切片其实是一个**nil切片**，它与nil比较返回true  
而使用语法糖或者make声名的切片是一个空切片，他们与ni比较返回false

#### arr\[low:high:max\]

len = high-low
cap = max-low

max不指定时max=high

max不允许超过cap
```sh
panic: runtime error: slice bounds out of range [::6] with capacity 5
```

切片cap的值在被切时会改变

#### slice和数组的区别

**数组**（Array）是一种固定长度的数据结构，元素的类型都是相同的。数组的长度在创建时就已经确定，并且不可更改。数组的定义方式为 `var a [5]int`，其中 a 为数组名，5 为数组的长度，int 为元素类型。数组可以使用下标进行访问和修改，例如 a\[0] = 1。数组在内存中是连续的存储空间。
在Golang中数组是一个长度固定的数据类型，数组的长度是类型的一部分，也就是说\[5\]int和\[10\]int是两个不同的类型。

1.  长度不同：数组的长度是固定的，而切片的长度可以动态增长。
2.  内存分配方式不同：数组在定义时就已经分配好了内存空间，而切片需要使用 make() 函数进行初始化分配内存。
3.  数据类型不同：数组中的元素类型必须相同，而切片可以是不同类型的元素的序列。
4.  传递方式不同：数组是值类型，传递时会复制一份，而切片是引用类型，传递时会传递指向底层数组的指针，多个切片可能会共享底层数组。
5.  访问方式不同：数组使用下标访问元素，而切片支持切片操作和下标访问元素。

#### 为什么append()需要在传入一个切片后还需要再赋值 

因为append之后可能会生成新的slice对象，赋值操作是用来接受可能会产生的新对象，确保期望使用的silce对象始终符合预期
append这种写法看起来有点奇怪而且重复，为什么需要将append函数返回的值再赋值给传入的值，而不是直接append(x,value)呢？这涉及到go语言的设计哲学，即参数传递是值拷贝。传入到函数中的参数x会建立一个新的副本。因此需要将添加元素后返回的新副本赋值给原始的变量。

#### nil slice

切片的零值是nil，所以只声明变量时，其缺省值为零值nil，这时也就是我们所说的`nil slice`。  
nil切片不能直接访问元素值，但可通过`append()`追加元素。

`append` 内部append 会初始化 nil slice，与此类似的函数还有 `copy` 。这两个函数内部都进行 make 初始化。每次对 slice 的操作内部是会产生一个新的数组，然后返回

#### 拷贝大切片一定比小切片代价大吗？

并不是，所有切片的大小相同；**三个字段**（一个 uintptr，两个int）。切片中的第一个字是指向切片底层数组的指针，这是切片的存储空间，第二个字段是切片的长度，第三个字段是容量。将一个 slice 变量分配给另一个变量只会复制三个机器字。所以 **拷贝大切片跟小切片的代价应该是一样的**。

#### 函数传参修改会影响原值吗？

如果没有扩容则会影响，如果扩容此时函数的哪个就会变成独立的一个切片

**注意**：
```go
func main() {
    x := []int{1, 2, 3}
    y := x[:2]
    y = append(y, 50)
    y = append(y, 60)
    fmt.Println(x) // [1 2 50]
    y[0] = 10
    fmt.Println(x) // [1 2 50]
    fmt.Println(y) // [10 2 50 60]
}
```
x的大小为3，当y扩容后其大小超过3此时xy就变成了两个独立的切片

#### Slice扩容规则

**1.18 前**
当原 slice 容量小于 `1024` 的时候，新 slice 容量变成原来的 `2` 倍；原 slice 容量超过 `1024`，新 slice 容量变成原来的`1.25`倍。

**1.18 后**
如果新切片的容量大于原切片的两倍，则直接将切片扩容到新切片的容量
当原slice容量(oldcap)小于`256`的时候，新slice(newcap)容量为原来的`2`倍；原slice容量超过256，新slice容量$newcap = oldcap+(oldcap+3*256)/4$

原来 `newcap`只是一个我们的预期容量，实际的容量需要根据切片中的元素大小**对齐内存**
最后，会根据切片元素的大小和新容量计算内存，将超出切片长度的内存清空，并拷贝旧切片的内存数据到新申请的内存中,最后返回

## defer 

在 Go 中，`defer` 语句用于注册一个函数，这个函数会在当前函数返回前执行，即使函数发生错误或者 panic。

`defer` 语句的实现原理是，Go 编译器会把 `defer` 语句转换为一个栈。在函数调用时，每遇到一个 `defer` 语句，就将其函数推入栈中。在函数返回时，栈中的函数会按照`后进先出`（LIFO）的顺序执行。这意味着最后注册的函数会最先执行。

**return之后的语句先执行，defer后的语句后执行**，return 不是原子级操作的，执行过程是: 保存返回值—>执行 defer —>执行 ret

#### 底层

defer 语句后面是要跟一个函数的，所以 defer 的数据结构跟一般的函数类似，不同之处是 defer 结构含有一个指针，用于指向另一个 defer ，每个 goroutine 数据结构中实际上也有一个 defer 指针指向一个 defer 的单链表，每次声明一个 defer 时就将 defer 插入单链表的表头，每次执行 defer 时就从单链表的表头取出一个 defer 执行。保证 defer 是按 LIFO 方式执行的。

```go
type _defer struct {
	started bool
	heap    bool

	openDefer bool
	sp        uintptr // sp at time of defer
	pc        uintptr // pc at time of defer
	fn        func()  // can be nil for open-coded defers
	_panic    *_panic // panic that is running defer
	link      *_defer // next defer on G; can point to either heap or stack!
	fd   unsafe.Pointer // funcdata for the function associated with the frame
	varp uintptr        // value of varp for the stack frame

	framepc uintptr
}
```

在Go语言的运行时环境中，\_defer 结构体的实现可以通过一个链表来维护多个 defer 语句的执行顺序。具体来说，每个\_defer 结构体都有指向下一个\_defer 结构体的指针，从而可以形成一个链表。

当一个函数执行结束时，runtime 会自动遍历这个链表，按照 defer 语句的执行顺序依次执行这些被延迟的函数。同时，runtime 也会对这些 \_defer 结构体进行释放，回收内存。

#### defer遇到panic时

遇到panic时，遍历本协程的defer链表，并执行defer。在执行defer过程中:遇到recover则停止panic，返回recover处继续往下执行。如果没有遇到recover，遍历完本协程的defer链表后，向stderr抛出panic信息。

**panic仅有最后一个可以被revover捕获**。

## 介绍 panic 和 recover 

Panic ：在 Go 语言中，出现 Panic 是代表一个严重问题，意味着程序结束并退出。在 Go 中 Panic 关键字用于抛出异常的。类似 Java 中的 throw。

recover：在 Go 语言中，用于将程序状态出现严重错误恢复到正常状态。当 发生 Panic 后，你需要使用recover 捕获，不捕获程序会退出。类似 Java 的 try catch 捕获异常。

-   `panic` 能够改变程序的控制流，调用 `panic` 后会立刻停止执行当前函数的剩余代码，并在**当前** Goroutine 中递归执行调用方的 `defer`；
-   `recover` 可以中止 `panic` 造成的程序崩溃。它是一个只能在 `defer` 中发挥作用的函数，在其他作用域中调用不会发挥作用；

### 如果有若干个goroutine，其中有一个panic，会发生什么

有一个panic，那么剩余goroutine也会退出，程序退出。如果不想程序退出，那么必须通过调用 recover() 方法来捕获 panic 并恢复将要崩掉的程序。

### defer可以捕获到其goroutine中的子goroutine的panic吗？

不能,它们处于不同的调度器P中。对于子goroutine，必须通过 **recover() 机制来进行恢复**，然后结合日志进行打印（或者通过channel传递error），下面是一个例子

```go
func main() {
    defer func() {
        defer func() {
            if err := recover(); err != nil {
                panic("3")
            }
        }()
        if err := recover(); err != nil {
            panic("2")
        }
    }()
    panic("1")
}

// 结果
panic: 1 [recovered]
        panic: 2 [recovered]
        panic: 3
```

## 内存管理

### go 怎么管理内存的

Go语言的内存分配器的核心设计思想是：多级内存分配模块，减少内存分配时锁的使用与系统调用；多尺度内存单元，减少内存分配产生碎片。

Golang在实现的时候还做了很多优化，感兴趣的还通过源码来看一下Golang的内存管理实现。

Golang的内存管理实现主要涉及以下几个方面：

1. 内存分配器(malloc)和释放器(free):Golang使用tcmalloc作为其默认的内存分配器，它是一个高效的内存分配器，可以减少内存碎片。在Go语言中，可以使用内置函数malloc和free来分配和释放内存。
2. 垃圾回收机制：Golang使用并发标记清除算法(Concurrent Mark Sweep,CMS)作为其默认的垃圾回收机制。CMS是一种高效的垃圾回收算法，可以在不阻塞用户线程的情况下进行垃圾回收。
3. 内存池技术：Golang使用内存池技术来提高内存分配和释放的效率。内存池是一种预先分配一定数量内存的技术，可以避免频繁地调用系统函数分配和释放内存，从而提高程序的性能。
4. 大对象支持：Golang支持大对象，即超过1MB的对象。为了支持大对象，Golang使用了一种称为“可变大小数组”的数据结构，它可以在运行时动态调整数组的大小。

### 内存模型

- **以空间换时间，一次缓存，多次复用**
	由于每次向操作系统申请内存的操作很重，那么不妨一次多申请一些，以备后用.
- **多级缓存，实现无/细锁化**
	Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型
	- mheap：全局的内存起源，访问要加全局锁
	- mcentral：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内
	- mcache：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁
- **多级规格，提高利用率**
	- Golang 借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page，但大小为 8 KB。
	- 最小的管理单元：mspan 大小为 page 的整数倍，且从 8B 到 80 KB 被划分为 67 种不同的规格，分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间。

1）page：最小的存储单元.

Golang 借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page，但大小为 8 KB

（2）mspan：最小的管理单元.

mspan 大小为 page 的整数倍，且根据空间大小和面向分配对象的大小，从 8B 到 80 KB 被划分为 67 种不同的规格（实际上还有一种隐藏的 0 级，用于处理更大的对象，上不封顶），分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间.

1. 根据规格大小，产生了等级的制度
2. 消除了外部碎片，但不可避免会有内部碎片
3. 宏观上能提高整体空间利用率
4. 正是因为有了规格等级的概念，才支持 mcentral 实现细锁化

堆是 Go 运行时中最大的临界共享资源，这意味着每次存取都要加锁，在性能层面是一件很可怕的事情.

在解决这个问题，Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型，下面对三者作个梳理：

- `mheap`：全局的内存起源，访问要加全局锁
- `mcentral`：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内
- `mcache`：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁
	- mcache 是每个 P 独有的缓存，因此交互无锁
	- mcache 将每种 spanClass 等级的 mspan 各缓存了一个，总数为 2（nocan 维度） * 68（大小维度）= 136
	- mcache 中还有一个为对象分配器 tiny allocator，用于处理小于 16B 对象的内存分配.

对于微对象的分配流程：

（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）
（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）
（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）
（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）
（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.

对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；
对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步.

-   object size > 32K，则使用 mheap 直接分配。
-   object size < 16 byte，不包含指针使用 mcache 的小对象分配器 tiny 直接分配；包含指针分配策略与\[16 B, 32 K]类似。
-   object size >= 16 byte && size <=32K byte 时，先使用 mcache 中对应的 size class 分配。
-   如果 mcache 对应的 size class 的 span 已经没有可用的块，则向 mcentral 请求。
-   如果 mcentral 也没有可用的块，则向 mheap 申请，并切分。
-   如果 mheap 也没有合适的 span，则向操作系统申请。

#### 为什么分微对象，小对象，大对象 

16B以上是小对象，32KB以上是大对象，16B一下是微对象

因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。

### 堆&栈

可以简单的认为 Golang 程序在启动时，会向操作系统申请一定区域的内存，分为栈（Stack）和堆（Heap）。栈内存会随着函数的调用分配和回收；堆内存由程序申请分配，由垃圾回收器（Garbage Collector）负责回收。性能上，栈内存的使用和回收更迅速一些；尽管Golang 的 GC 很高效，但也不可避免的会带来一些性能损耗。因此，Go ==优先使用栈内存进行内存分配==。在不得不将对象分配到堆上时，才将特定的对象放到堆中。

`栈`是一种特殊的数据结构，它按照后进先出（LIFO）的顺序存储数据。当程序调用一个函数时，该函数的参数、局部变量以及返回地址都会被存储到栈中，当函数返回时，这些数据也会被从栈中移除。由于栈是一种线性结构，因此它的分配和释放内存的方式是非常高效的。栈中的内存空间是按照一定的规则自动管理的，由编译器自动进行分配和释放，无需手动释放。它会随着函数的创建而分配，随着函数的退出而销毁。**一个栈通常又包含了许多栈帧（stack frame），它描述的是函数之间的调用关系**
go中栈区往往存储着函数参数、局部变量和调用函数帧。每个 goroutine 都维护着一个自己的栈区，这个栈区只能自己使用不能被其他 goroutine 使用。

`堆`是另一种内存空间，它是程序在运行时动态分配的一块内存区域。堆的分配和释放是由程序员手动控制的。在堆中分配内存时，程序需要通过 `malloc` 或 `new` 等函数手动申请内存空间，并在不需要使用这些内存时手动释放它们，否则就会导致内存泄漏。由于堆中的内存分配是动态的，因此其分配和释放的效率比栈要低得多。
go中堆区的内存一般由编译器和开发者共同管理分配，交给runtime GC来释放。

- **栈**：
	- 在内存中，从上往下增长
	- 分配大小空间有限
	- 连续的空间
	- 系统自动分配，效率高
- **堆**：
	- 在内存中，从下往上增长
	- 分配大小受到虚拟内存大小限制
	- 非连续的空间
	- new分配的内存，比较满，容易产生碎片
	- 忘记回收会导致内存泄露

### 内存分配（何时分配在堆/栈上）

go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做**逃逸分析(escape analysis)**，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。

go中变量的内存分配不仅仅取决于变量的大小，还受到编译器的优化影响。例如，如果一个较大的结构体变量被分配在栈上可能会导致栈溢出的问题，而编译器可能会自动将其分配在堆上，以避免这种情况的发生。

**逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则在栈上分配。否则，就是所谓的逃逸，必须在堆上进行分配。**

当分配到栈上可能引起非法内存访问等问题后，会使用堆，主要场景有：
1.  当一个值可能在函数被调用后访问，这个值极有可能被分配到堆上。
2.  当编译器检测到某个值过大，这个值会被分配到堆上。
3.  当编译时，编译器不知道这个值的大小（slice、map...）这个值会被分配到堆上。

不同于JAVA JVM的运行时逃逸分析，Go的逃逸分析是在`编译期`完成的：编译期无法确定的参数类型**必定**放到堆中；

- **如果函数外部没有引用，则优先放到栈中**
- **如果函数外部存在引用，则必定放到堆中**
- **变量过大时，可能会被放到堆中**
- **编译期间不知道值的大小时，会被放到堆中**

### 内存逃逸 

go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做**逃逸分析(escape analysis)**，**当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆**。

所谓逃逸，就是指变量的生命周期不仅限于函数栈帧，而是超出了函数的范围，需要在堆上分配内存。如果变量x没有发生逃逸，那么它会被分配在函数栈帧中，随着函数的返回而被自动销毁。

一般我们给一个引用类对象中的引用类成员进行赋值，可能出现逃逸现象。可以理解为访问一个引用对象实际上底层就是通过一个指针来间接的访问了，但如果再访问里面的引用成员就会有第二次间接访问，这样操作这部分对象的话，极大可能会出现逃逸的现象。

-   **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
-   **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
-   **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。

我们得出了指针**必然发生逃逸**的三种情况：

- 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）；
- 被已经逃逸的变量引用的指针，一定发生逃逸；
- 被指针类型的slice、map和chan引用的指针，一定发生逃逸；

同时我们也得出一些**必然不会逃逸**的情况：

- 指针被未发生逃逸的变量引用；
- 仅仅在函数内对变量做取址操作，而未将指针传出；

#### 逃逸分析好处

通过逃逸分析，那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了不但同时减少 GC 的压力，还减轻了内存分配的开销。

`go build -gcflags=-m main.go`

#### 如何避免内存逃逸

- 尽量减少外部指针引用，必要的时候可以使用值传递；
- 对于自己定义的数据大小，有一个基本的预判，尽量不要出现栈空间溢出的情况；
- Golang中的接口类型的方法调用是动态调度，如果对于性能要求比较高且访问频次比较高的函数调用，应该尽量避免使用接口类型；
- 尽量不要写闭包函数，可读性差且发生逃逸。
- 当指针类型作为返回时，会发生内存逃逸

### 内存泄露 

- 临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是 string、slice 底层 buffer 的错误共享，导致无用数据对象无法及时释放，或者 defer 函数导致的资源没有及时释放。
- 永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如 goroutine 内部预期之外的`for-loop`或者`chan select-case`导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。

1. **Goroutine泄漏**：实际开发中更多的还是Goroutine引起的内存泄漏，因为Goroutine的创建非常简单，通过关键字go即可创建，由于开发的进度大部分程序猿只会关心代码的功能是否实现，很少会关心Goroutine何时退出。如果Goroutine在执行时被阻塞而无法退出，就会导致Goroutine的内存泄漏，一个Goroutine的最低栈大小为2KB，在高并发的场景下，对内存的消耗也是非常恐怖的！
2. **互斥锁未释放**：协程拿到锁未释放，其他协程获取锁会阻塞
3. **死锁**
4. **chan阻塞**
5. **定时器使用** `time.Ticker`是每隔指定的时间就会向通道内写数据。作为循环触发器，必须调用stop方法才会停止，从而被GC掉，否则会一直占用内存空间。

#### 排查

1. pprof
2. hook 库函数

1. 代码审查：仔细检查代码，特别关注goroutine的创建和终止逻辑，确保没有未释放的资源，没有未关闭的通道，以及没有无限循环。
2. 调试工具：使用Go语言提供的调试工具，如goroutine分析器（`go tool pprof`）和内存分析器（`go tool pprof -alloc_space`），来检查运行时的goroutine数量和内存使用情况。这些工具可以帮助定位泄露的goroutine以及相关的资源。
3. 监控和日志：在应用程序中添加监控和日志记录，以便及时发现异常的goroutine数量和行为。记录重要的事件和错误信息，以便追踪和分析泄露的原因。
4. 单元测试和性能测试：编写单元测试来验证goroutine的创建和终止逻辑，并进行性能测试以模拟高并发和负载情况，以确定是否存在泄露问题。

## golang垃圾回收机制

[Go语言GC实现原理及源码分析 - luozhiyun - 博客园 (cnblogs.com)](https://www.cnblogs.com/luozhiyun/p/14564903.html)

垃圾回收就是对程序中不再使用的内存资源进行自动回收的操作。

GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。
GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通
GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。

### 三色标记法
-   初始化状态下所有对象都是白色的。
-   从根节点开始遍历所有对象，把遍历到的对象变成灰色对象
-   遍历灰色对象，将灰色对象引用的对象也变成灰色对象，然后将遍历过的灰色对象变成黑色对象
-   循环步骤3，知道灰色对象全部变黑色。
-   通过写屏障检测对象有变化。重复以上操作
-   收集所有的白色对象（垃圾）

### 根节点

根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：
1.  全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。
2.  执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。
3.  寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。

### 什么是stop the world？为什么有这个时期？ 

为了防止在GC处理过程中对象依赖树被篡改，比如一个黑节点指向一个白节点，会导致白节点错误的被清理，所以需要在整个GC过程停止用户的代码执行，即STW(stop the word), 早期的go就是这样做的，带来的后果也是非常严重的，STW时间长达数百毫秒，对时延敏感的程序造成巨大的影响。

a.第一次是Mark阶段的开始, 这个时候主要是一些准备工作，比如enable write barrier；第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC(mutator assist). 

b.第二次是Mark Termination阶段. re-scan过程，如果这个时候没有stw，那么mark将无休止，第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC(mutator assist). 需要注意的是, 不是所有根对象的扫描都需要STW, 例如扫描栈上的对象只需要停止拥有该栈的G. 从go 1.9开始, 写屏障的实现使用了Hybrid Write Barrier, 大幅减少了第二次STW的时间.

这里的写屏障(write barrier)是因为在GC的时候用户代码可以同时运行，这样在扫描的时候，对象的依赖树可能被改变了，为了避免这个问题，Golang在GC中标记阶段会启用写屏障。

### 写屏障:

当标记和程序是并发执行的，这就会造成一个问题. 在标记过程中，有新的引用产生，可能会导致误清扫.

清扫开始前，标记为黑色的对象引用了一个新申请的对象，它肯定是白色的，而黑色对象不会被再次扫描，那么这个白色对象无法被扫描变成灰色、黑色，它就会最终被清扫，而实际它不应该被清扫.

这就需要用到屏障技术，golang采用了写屏障，其作用就是为了避免这类误清扫问题. 写屏障即在==内存写操作前，维护一个约束，从而确保清扫开始前，黑色的对象不能引用白色对象==.

插入写屏障：当一个对象指向另一个对象时，被指向的对象被置灰，所以黑节点指向灰节点，不会错误清理对象。
删除写屏障：当删除一个对象对另一个对象的引用时，旧的被指向者被置灰。

#### 强三色不变性

不存在黑色对象引用到白色对象的指针。

#### 弱三色不变性

所有被黑色对象引用的白色对象都处于灰色保护状态.

**黑色对象可以引用白色对象，当前仅当白色对象存在其他灰色对象引用，或者可达它的链路上游存在黑色对象**
**强制性不允许黑色对象引用白色对象**

### 插入写屏障

`具体操作`: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)满足**强三色不变性**

我们知道,黑色对象的内存槽有两种位置, `栈`和`堆`. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在**栈空间的对象操作中不使用**. 而仅仅使用在堆空间对象的操作中.

==为了防止栈空间内黑色对象引用白色对象，此时会在准备清扫白色对象时，进行STW再次扫描一遍栈空间。==

**缺点**：结束时需要STW重新扫描栈，10~100ms

### 删除写屏障

`具体操作`: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。满足**弱三色不变性**

**缺点**：回收精度低，一个对象即时被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一次GC中才被清理。GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。

### 混合写屏障

1. GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，
2. GC期间，任何在栈上创建的新对象，均为黑色。
3. 被删除的对象标记为灰色。
4. 被添加的对象标记为灰色。

`满足`: 变形的**弱三色不变式**（结合了插入、删除写屏障的优点）.
只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。

###  GC触发时机  

1.  **主动触发**，通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。
2.  **被动触发**，分为两种方式：
    -   使用系统监控，当超过`两分钟`没有产生任何 GC 时，强制触发 GC。
    -   当程序分配了一定数量的内存后，GC 也会被触发。
      当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发。
      使用步调（Pacing）算法，其核心思想是控制内存增长的比例。
      第一次触发 GC 时强制设置触发第一次 GC 为 4MB
    - 当系统内存空间不足时，GC 会被触发来释放内存

### 缺点

stop the world是gc的最大性能问题，对于gc而言，需要停止所有的内存变化，即停止所有的goroutine，等待gc结束之后才恢复。

从1.8以后的golang将第一步的stop the world 也取消了，这又是一次优化； 1.9开始, 写屏障的实现使用了Hybrid Write Barrier, 大幅减少了第二次STW的时间.
## 并发

### 并行和并发有什么区别？

-   并发（concurrency）：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务`并不会同时运行`。
-   并行（parallelism）：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务`一定是同时运行`。

-   goroutine 可能发生并行执行；
-   但 coroutine(协程) 始终顺序执行。

### 并发的三大特性: 

有序性 ,原子性,可见性

`有序性`：即程序执行的顺序按照代码的先后顺序执行。
`原子性`：一个或多个操作,要么全部执行且在执行过程中不被任何因素打断,要么全部不执行。
`可见性`：当一个线程修改了共享变量的值，其他线程能够看到修改的值。

### Go并发编程及常用并发控制手段

Go是一门天生支持并发编程的语言，提供了丰富的原生并发控制手段，以下是其中的几个常用的并发控制手段：

1.  **goroutine**：goroutine是Go中的轻量级线程，可以通过关键字`go`快速启动一个goroutine，使其在后台执行任务。在一个程序中可以同时运行数千甚至数百万个goroutine，有效地提高了程序的并发性和性能。
2.  **channel**：channel是Go语言中的一种通信机制，用于在goroutine之间传递数据。通过使用channel，可以在不使用锁的情况下实现不同goroutine之间的同步和协调。
3.  **sync.Mutex**：互斥锁是最常用的同步原语之一，用于保护临界区。在Go语言中，通过`sync`包提供的`Mutex`类型可以实现互斥锁。
4.  **sync.WaitGroup**：`sync`包还提供了`WaitGroup`类型，用于等待一组goroutine的完成。通过在`WaitGroup`中添加计数器，可以在主goroutine中等待所有goroutine完成后再继续执行。
5.  **sync.Cond**：条件变量是一种高级的同步原语，用于在不同的goroutine之间传递信号。通过使用`sync.Cond`，可以实现复杂的同步和协调操作。
6.  **atomic**：`atomic`包提供了原子操作，用于在不加锁的情况下进行并发访问。例如，通过原子操作可以实现无锁的计数器。
7.  **context**：`context`包提供了一种机制，用于在goroutine之间传递上下文信息。通过使用`context`，可以实现在不同goroutine之间安全地取消操作、超时控制等。

这些并发控制手段在不同的场景下有着不同的应用，程序员需要根据实际情况选择合适的手段来实现并发控制，以提高程序的性能和可靠性。

### 如何确保高并发场景下一些事情只执行一次

加载文件，关闭管道等
使用`sync.Once`，或双检锁

如：单例模式
```go
type Singleton struct {}
var singleton *Singleton
var singletonOnce sync.Once
func GetSingletonInstance() *Singleton {
	singletonOnce.Do(func(){
		singleton = &Singleton{}
	})
	return singleton
}
```

once.Do 源码

```go
func (o *Once) Do(f func()) {//判断是否执行过该方法，如果执行过则不执行
    if atomic.LoadUint32(&o.done) == 1 {
        return
    }
    // Slow-path.
    o.m.Lock()
    defer o.m.Unlock()　　
    if o.done == 0 {
        defer atomic.StoreUint32(&o.done, 1)
        f()
    }
}
```

### 容器的并发安全性

数组，slice，struct允许并发修改（可能会脏写），并发修改map有时会发生panic

如果需要并发修改map，使用`sync.Map`

n++ 可能会出现脏写，n = a, a = a + 1, n = a
解决：把n++封装成原子操作，解除资源竞争，避免脏写
```go
func atomic.AddInt32(addr *int32, delta int32) (new int32)

func atomic.LoadInt32(addr *int32) (val int32)
```

### 读写锁

```go
var lock sync.RWMutex // 声明读写锁，无需初始化
// 写锁
lock.Lock()
lock.Unlock()
// 读锁
lock.Rlock()
lock.RUnlock()
```

任意时刻只能加一把写锁，且不能加读锁
每加写锁时，可以同时加多把读锁，读锁加上后不能加写锁

### 临界区

如果一部分程序会被并发访问或修改，那么，为了避免并发访问导致的意向不到的结果，这部分程序需要被保护起来，这部分程序就是临界区。

如果多个线程同时访问或操作临界区，会造成访问错误，可以使用互斥锁，限定临界区同一时间只能有1个线程持有。

1.  当临界区由一个线程持有的时候，其它线程如果想进入这个临界区，就会返回失败，或者是等待。
2.  直到持有的线程退出临界区，这些等待线程中的某一个才有机会接着持有这个临界区。

## Goroutine

### 介绍一下goroutine

Goroutine，经 Golang 优化后的特殊协程，协程是一种更细粒度的调度，可以满足多个不同处理逻辑的协程共享一个线程资源，它的创建销毁和调度的成本都非常的小。它与线程存在映射关系，为 M：N，可以利用多个线程实现并行，并且go实现了GMP调度模型，可以通过调度器的调度来实现线程间的动态绑定和灵活调度。
GMP：M 是操作系统线程的抽象，P 则是用于管理 G的调度器。P 结构负责管理 G的调度，包括创建、销毁、挂起和唤醒等，而 M 结构则负责将 G 绑定到操作系统线程上并执行它们。调度流程：M如果想要运行G就需要与P绑定，调度时先找p.runnext然后p的本地队列，再找全局队列，最后找准备就绪的网络协程，这样的好处是取本地队列时可以接近于无锁化减少锁的竞争。其中每61次调度会直接从全局队列中取G执行，并且把一个G放入本地队列，避免全局队列的G被饿死。如果都没有的话就会触发work stealing机制，会尝试从其他P的本地队列中偷取一半的G来执行。当M执行G时遇到了系统调用或其他阻塞行为，M会阻塞，此时runtime会通过handoff机制将M与P解绑，P与空闲的M或新建一个M绑定执行后续的G。当M结束阻塞后，G会尝试获取一个空闲的P，如果获取不到则这个M会变成休眠状态

p.runnext 优先取P本地队列，其次取全局队列，最后取net wait队列

（1）M 是线程的抽象；G 是 goroutine；P 是承上启下的调度器；
（2）M调度G前，需要和P绑定；
（3）全局有多个M和多个P，但同时并行的G的最大数量等于P的数量；
（4）G的存放队列有三类：P的本地队列；全局队列；和wait队列（图中未展示，为io阻塞就绪态goroutine队列）；
（5）M调度G时，优先取P本地队列，其次取全局队列，最后取wait队列；这样的好处是，取本地队列时，可以接近于无锁化，减少全局锁竞争；
（6）为防止不同P的闲忙差异过大，设立work-stealing机制，本地队列为空的P可以尝试从其他P本地队列偷取一半的G补充到自身队列.

（1）与线程存在映射关系，为 M：N；
（2）创建、销毁、调度在用户态完成，对内核透明，足够轻便；
（3）可利用多个线程，实现并行；
（4）通过调度器的斡旋，实现和线程间的动态绑定和灵活调度；
（5）栈空间大小可动态扩缩，因地制宜.

调度假设当前正在执行G1，G1阻塞（如系统调用），此时P与G1，M1解绑，P被挂载到M2上继续执行G队列中其他任务。G1解除阻塞后，如果有空闲的P就加入到P队列中，如果没有就放到全局可运行队列runqueue中。P会周期性扫描全局（61次）可运行队列，执行里面的G；如果全局runqueue为空，就会从其他的P的执行队列中取一半G来执行。

在 GPM 模型，有一个全局队列（Global Queue）：存放等待运行的 G，还有一个 P 的本地队列：也是存放等待运行的 G，但数量有限，不超过 256 个。

GPM 的**调度流程**从 go func()开始创建一个 goroutine，新建的 goroutine 优先保存在 P 的本地队列中，如果 P 的本地队列已经满了，则会保存到全局队列中。

M 会从 P 的队列中取一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会从其他的 MP 组合偷取一个可执行的 G 来执行，

当 M 执行某一个 G 时候发生系统调用或者阻塞，M 阻塞，

如果这个时候 G 在执行，runtime 会把这个线程 M 从 P 中摘除，然后创建一个新的操作系统线程来服务于这个 P，当 M 系统调用结束时，这个 G 会尝试获取一个空闲的 P 来执行，并放入到这个 P 的本地队列，如果这个线程 M 变成休眠状态，加入到空闲线程中，然后整个 G 就会被放入到全局队列中。

**work stealing（工作量窃取） 机制**：会优先从全局队列里进行窃取，之后会从其它的P队列里窃取一半的G，放入到本地P队列里。
**hand off （移交）机制**：当前线程的G进行阻塞调用时，例如睡眠，则当前线程就会释放P，然后把P转交给其它空闲的线程执行，如果没有闲置的线程，则创建新的线程

### go中线程VS协程：

-  创建销毁：
   - 协程goroutine由Go runtime负责管理，创建和销毁的销毁都非常小，是用户级
   - 线程创建和销毁开销巨大，因为是内核级的，通常的解决方法是线程池
- 创建数量：
  - 协程：轻松创建上百万个
  - 线程：通常最多不超过1w个
- 内存占用：
	- 协程：2kb，初始分配4k堆栈，随着程序的执行自动增长删除
	- 线程：1M，创建线程是必须指定堆栈且固定，通常M为单位
- 切换成本：
	- 协程：协程切换只需保存3个寄存器，耗时约200纳秒
	- 线程：线程切换需要保存几十个寄存器，耗时约1000纳秒
- 调度方式：
	- 协程：非抢占式，由GO runtime主动交出控制权
	- 线程：在时间片用完后，由CPU中断任务强行将其调度走，此时需要保存很多信息

### gorountine的优势

1. Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU，最大限度的使用cpu的性能
2. 开启一个goroutine消耗是非常小的（大概是2kb），所以可以轻松的创建数以百计的goroutine。
3. 速度快，还可以用channel进行通信

### 协程什么时候会发生切换？ 

协程可以主动让渡自己的执行权利（用户调用强制让渡），
也可以在发生锁或者通道堵塞时被动让渡自己的执行权利。
除此之外，为了让每个协程都有执行的机会，并且最大化利用CPU 资源，在Go 语言初 始化时会启动一个特殊的线程来执行系统监控服务。系统监控会判断协程是否需要执行垃圾回 收或者当前协程是否运行时间过长或处于系统调用阶段，在这些情况下，调度器将借助操作系 统信号机制或者抢占逻辑处理器实现抢占调度。

## GMP

`GMP`：M 是操作系统线程的抽象，P 则是用于管理 G的调度器。P 结构负责管理 G的调度，包括创建、销毁、挂起和唤醒等，而 M 结构则负责将 G 绑定到操作系统线程上并执行它们。**调度流程**：M如果想要运行G就需要与P绑定，调度时先找p.runnext然后p的本地队列，再找全局队列，最后找网络轮询器 Net Poller 上有一个陷入异步网络调用的准备就绪的G，这样的好处是取本地队列时可以接近于无锁化减少锁的竞争。其中每61次调度会直接从全局队列中取1个G执行，避免全局队列的G被饿死。如果都没有的话就会触发`work stealing`机制，会尝试从其他P的本地队列中偷取一半的G来执行。当M执行G时遇到了系统调用或其他阻塞行为，M会阻塞，此时runtime会通过`handoff`机制将M与P解绑，P与空闲的M或新建一个M绑定执行后续的G。当M结束阻塞后，G会尝试优先绑定oldP，失败后从全局P队列中获取一个P，如果获取不到则这个M会变成休眠状态G放入全局队列。**抢占**如果有G一直占用资源，go在运行时有sysmon进行监控，如果G独占P超过10ms就会被抢占。`Why P`: 1.每个P有本地队列可以近乎无锁化执行，减少全局队列的锁竞争。2.当本地队列为空时，通过workstealing机制减少空转，提高资源利用率。3.当M阻塞时会绑定到其他M上执行，提高并发性能，如果将队列实现在M上会使得阻塞时队列等待。`G0`负责调度与创建g，分配defer，stw，扫描栈，栈分配

[Golang并发调度的GMP模型 - 掘金 (juejin.cn)](https://juejin.cn/post/6886321367604527112)
[GO GMP协程调度实现原理 5w字长文史上最全 - 掘金 (juejin.cn)](https://juejin.cn/post/7105971301151408141)

- G(Goroutine)，表示一个 goroutine，即我需要分担出去的任务；
- M(Machine)，对应一个内核线程，用于将一个 G 搬到线程上执行；
- P(Processor)，一个装满 G 的队列，用于维护一些任务；

-   G：Groutine协程，拥有运行函数的指针、栈、上下文（指的是sp、bp、pc等寄存器上下文以及垃圾回收的标记上下文），在整个程序运行过程中可以有无数个，代表一个用户级代码执行流（用户轻量级线程）；
-   P：Processor，调度逻辑处理器，同样也是Go中代表资源的分配主体（内存资源、协程队列等），默认为机器核数，可以通过GOMAXPROCS环境变量调整
-   M：Machine，代表实际工作的执行者，对应到操作系统级别的线程；M的数量会比P多，但不会太多，最大为1w个。

Golang 中的 GMP 模型是指 Goroutine、M（Machine）、P（Processor）三个组件组成的并发模型，其中 Goroutine 是 Go 语言中的轻量级线程，M 是操作系统线程的抽象，P 则是用于管理 Goroutine 的调度器。P 结构负责管理 Goroutine 的调度，包括 Goroutine 的创建、销毁、挂起和唤醒等，而 M 结构则负责将 Goroutine 绑定到操作系统线程上并执行它们。

- `G`: 表示 Goroutine，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。
- `P`: Processor，表示逻辑处理器， 对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等，P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 >= P 的数量），P 的数量由用户设置的 GOMAXPROCS 决定，但是不论 GOMAXPROCS 设置为多大，P 的数量最大为 256。
- `M`: Machine，OS 线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础，M 的数量是不定的，由 Go Runtime 调整，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。

### 为什么要有P？

加了 P 之后会带来什么改变呢？

- 每个 P 有自己的本地队列，大幅度的减轻了对全局队列的直接依赖，所带来的效果就是锁竞争的减少。而 GM 模型的性能开销大头就是锁竞争。
- 每个 P 相对的平衡上，在 GMP 模型中也实现了 Work Stealing （工作量窃取机制）算法，如果 P 的本地队列为空，则会从全局队列或其他 P 的本地队列中窃取可运行的 G 来运行，减少空转，提高了资源利用率。

如果在M上实现P类似的组件：

- 一般来讲，M 的数量都会多于 P。像在 Go 中，M 的数量默认是 10000，P 的默认数量的 CPU 核数。另外由于 M 的属性，也就是如果存在系统阻塞调用，阻塞了 M，又不够用的情况下，M 会不断增加。
- M 不断增加的话，如果本地队列挂载在 M 上，那就意味着本地队列也会随之增加。这显然是不合理的，因为本地队列的管理会变得复杂，且 Work Stealing 性能会大幅度下降。

在 Golang 中，为了提高并发性能，一个 M 可以绑定多个 P，并且一个 P 也可以被多个 M 共享。这种设计可以在多核 CPU 上更好地利用硬件资源，从而提高并发性能。

如果直接将 P 结构实现在 M 上，会使得一个 M 管理的 Goroutine 的数量非常大，导致调度器的复杂度增加，可能会影响到并发性能。而将 P 结构单独实现，并允许多个 P 绑定到同一个 M 上，可以有效降低调度器的复杂度，提高并发性能。

另外，将 P 结构单独实现还可以方便地进行负载均衡和资源调度。因为不同的 Goroutine 可能会对系统资源产生不同的需求，单独实现 P 结构可以让调度器更加灵活地进行资源调度，从而提高系统的并发性能。

### goroutine什么时候会发生阻塞？

1. 由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine；
2. 由于网络请求和 IO 操作导致 Goroutine 阻塞。
3. 当调用一些系统方法的时候（如文件 I/O），如果系统方法调用的时候发生阻塞，
4. 如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了

### 每个线程/协程占用多少内存？

创建一个协程需要2kb, 栈空间不够会自动扩容， 创建一个线程需要1M空间。

### 在GPM调度模型，goroutine 有哪几种状态？线程呢？

#### G

**有9种状态**

-   **\_Gidle**：刚刚被分配并且还没有被初始化
-   **\_Grunnable**：没有执行代码，没有栈的所有权，存储在运行队列中
-   **\_Grunning**：可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P
-   **\_Gsyscall**：正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 M 但是不在运行队列上
-   **\_Gwaiting**：由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在于 Channel 的等待队列上
-   **\_Gdead**：没有被使用，没有执行代码，可能有分配的栈
-   **\_Gcopystack**：栈正在被拷贝，没有执行代码，不在运行队列上
-   **\_Gpreempted**：由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒
-   **\_Gscan**：GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在


### 如果goroutine一直占用资源怎么办，PMG模型怎么解决这个问题

如果有一个goroutine一直占用资源的话，GMP模型会从正常模式转为饥饿模式，通过信号协作强制处理在最前的 goroutine 去分配使用

#### 基于信号的抢占式调度

golang在之前的版本中已经实现了抢占调度，不管是陷入到大量计算还是系统调用，大多可被sysmon扫描到并进行抢占。但有些场景是无法抢占成功的。比如轮询计算 for { i++ } 等，这类操作无法进行newstack、morestack、syscall，所以无法检测stackguard0 = stackpreempt。

go team已经意识到抢占是个问题，所以在1.14中加入了**基于信号的协程调度抢占**。原理是这样的，首先注册绑定 SIGURG 信号及处理方法runtime.doSigPreempt，sysmon会间隔性检测超时的p，然后发送信号，m收到信号后休眠执行的goroutine并且进行重新调度。

sysmon启动后会间隔性的进行监控，最长间隔10ms，最短间隔20us。如果某协程独占P超过`10ms`，那么就会被抢占！

### 如果若干个线程中有一个发生OOM会发生什么？如果goroutine发生呢？

当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行

go中的内存泄漏一般都是goroutine泄露，就是goroutine没有被关闭，或者没有添加超时控制，让goroutine一只处于阻塞状态，不能被GC。

当一个线程发生OOM（内存溢出）时，通常会导致整个进程崩溃，因为线程共享进程的地址空间。然而，当一个Goroutine发生OOM时，情况可能会有所不同。由于Goroutine的堆栈是动态扩展的，当一个Goroutine的堆栈无法扩展时，Go运行时会尝试回收其他Goroutine的内存，以便为当前Goroutine分配更多的内存。如果回收失败，Go运行时会抛出一个运行时错误（如`runtime: out of memory`），但不会导致整个进程崩溃。

### 什么是协程泄露

协程泄露指的是在 Go 语言程序中，由于某种原因而导致协程无法正常结束，从而造成内存泄露的情况。这种情况通常发生在使用协程时处理异步任务时，如果没有正确地处理协程的终止条件，它们将一直保持活动状态，不断占用内存，最终导致内存泄露。为了避免协程泄露，应该确保在程序结束时关闭所有协程，并释放其占用的内存。

- 可以通过`leaktest`库来检测
- 使用 golang 自带的`pprof`监控工具，可以发现内存上涨情况

1. channel缺少消费者，导致发送阻塞；没有生产者，读取阻塞
2. 死锁
	1.  同一个goroutine中，使用同一个chnnel读写；
	2.  2个 以上的goroutine中， 使用同一个 channel 通信。 读写channel 先于 go程创建；
	3. channel 和 读写锁、互斥锁混用；
3. select 所有的case都阻塞
4. 无限死循环
	I/O 操作上的堵塞也可能造成泄露，例如发送请求到 API 服务器，而没有使用超时；或者程序单纯地陷入死循环中。

### 如果有若干个goroutine，其中有一个panic，会发生什么

有一个panic，那么剩余goroutine也会退出，程序退出。如果不想程序退出，那么必须通过调用 recover() 方法来捕获 panic 并恢复将要崩掉的程序。

### defer可以捕获到其goroutine中的子goroutine的panic吗？

不能,它们处于不同的调度器P中。对于子goroutine，必须通过 **recover() 机制来进行恢复**，然后结合日志进行打印（或者通过channel传递error），下面是一个例子

### 主协程如何等待所有协程都完成

1. `sync.WaitGroup`
   - Add：WaitGroup 类型有一个计数器，默认值是 0，通常通过个方法来标记需要等待的子协程数量
   - Done：当某个子协程执行完毕后，可以通过 Done 方法标记已完成，常用 defer 语句来调用
   - Wait 阻塞当前协程，直到对应 WaitGroup 类型实例的计数器值归零
2. 使用channel
   - 声明一个和子协程数量一致的通道数组，然后为每个子协程分配一个通道元素，在子协程执行完毕时向对应的通道发送数据；然后在主协程中，依次读取这些通道接收子协程发送的数据，只有所有通道都接收到数据才会退出主协程。
3. 使用context
   - 使用 `context.WithCancel`在子协程退出:

### 起多个协程，怎么控制他们的退出 

channel通知，select监控，ctx中Done退出，waitGroup等待

1. 调用 `runtime.Goexit()` 来手动终止协程
2. 使用select监控：监控chan或ctx.Done
3. waitGroup等待


### 请描述避免多线程竞争时有哪些手段？ 

Go语言提供了传统的同步 goroutine 的机制，就是对共享资源加锁。atomic 和 sync 包里的一些函数就可以对共享的资源进行加锁操作。

#### 原子函数

原子函数能够以很底层的加锁机制来同步访问整型变量和指针。

n++ 可能会出现脏写，n = a, a = a + 1, n = a
解决：把n++封装成原子操作，解除资源竞争，避免脏写
```go
func atomic.AddInt32(addr *int32, delta int32) (new int32)

func atomic.LoadInt32(addr *int32) (val int32)
```

```go
var isInit uint32
if atomic.LoadUint32(&isInit) == 1 {
	return
}
atomic.StoreUint32(&isInit, 1)
```

#### 互斥锁

另一种同步访问共享资源的方式是使用互斥锁，互斥锁这个名字来自互斥的概念。  
互斥锁用于在代码上创建一个临界区，保证同一时间只有一个 goroutine 可以执行这个临界代码。

### 特殊的goroutine  G0

在 Go 中创建的所有 Goroutine 都会被一个内部的调度器所管理。Go 调度器尝试为所有的 Goroutine 分配运行时间，并且在当前的 Goroutine 阻塞或者终止的时候，Go 调度器会通过运行 Goroutine 的方式使所有 CPU 保持忙碌状态。这个调度器实际上是作为一个特殊的 Goroutine 运行的。

**M0**

`M0`是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0==负责执行初始化操作和启动第一个G==， 在之后M0就和其他的M一样了。

**G0**

`G0`是每次启动一个M都会第一个创建的gourtine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。

职责：
1. Goroutine 创建与调度
2. defer 函数分配。
3. 垃圾收集操作，比如 STW（ stopping the world ），扫描 Goroutine 的栈，以及一些标记清理操作。
4. 栈增长。当需要的时候，Go 会增加 Goroutine 的大小。这个操作是由 `g0` 的 prolog 函数完成的。

m 通过 p 调度执行的 goroutine 永远在普通 g 和 g0 之间进行切换，当 g0 找到可执行的 g 时，会调用 gogo 方法，调度 g 执行用户定义的任务；当 g 需要主动让渡或被动调度时，会触发 mcall 方法，将执行权重新交还给 g0.

## Channel

### channel用过吗，实现机制，有什么注意的地方

channel 是Go语言在语言级别提供的 ==goroutine 间的通信方式==。我们可以使用 channel 在两个或多个 goroutine 之间传递消息。

### 为什么要有channel，CSP

与主流语言通过共享内存来进行并发控制方式不同，Go 语言采用了 CSP 模式。**不要通过共享内存来通信，而要通过通信来实现内存共享**。这是一种用于描述两个独立的并发实体通过共享的通讯 Channel（管道）进行通信的并发模型。https://www.zhihu.com/question/58004055

不同的线程不共享内存不用锁，线程之间通讯用channel同步也用channel。用这种范式的主要优点是逻辑简单清楚，系统有高正确性。你的程序能保证每个线程里事件都是sequential consistent的，不会有竞争出现。

-   **避免数据竞争**：通过将数据封装在消息中发送，每个线程只关心自己的消息队列，避免了对共享内存的直接访问，从而避免了数据竞争和一致性问题。
- **隔离性和模块化**：通过通过消息传递的方式进行通信，不同模块之间的数据交互更加清晰和独立，每个模块只需关注自己的消息处理逻辑，提高了代码的隔离性和模块化程度。
- **灵活性和可扩展性**：通过消息传递方式，可以方便地扩展和添加新的线程或进程，只需定义适当的消息格式和处理逻辑即可。
- **可靠性**：通过使用消息队列或者事件驱动机制，可以提供可靠的消息传递保证，确保消息的有序性和可靠性。

### 使用场景

1.  `任务分发和处理`：可以通过Channel将任务分发给多个goroutine进行处理，并将处理结果发送回主goroutine进行汇总和处理。
2.  `并发控制`：可以通过Channel来进行信号量控制，限制并发的数量，避免资源竞争和死锁等问题。
3.  `数据流处理`：可以通过Channel实现数据流的处理，将数据按照一定的规则传递给不同的goroutine进行处理，提高并发处理效率。
4.  `事件通知和处理`：可以通过Channel来实现事件的通知和处理，将事件发送到Channel中，让订阅了该Channel的goroutine进行相应的处理。
5.  `异步处理`：可以通过Channel实现异步的处理，将任务交给其他goroutine处理，自己继续执行其他任务，等待处理结果时再从Channel中获取。

#### 有缓冲

- 有缓冲通道是指具有固定大小的存储空间的通道。在发送操作时，如果通道缓冲区未满，则发送操作是非阻塞的，发送者可以继续执行。只有当通道缓冲区已满时，发送操作才会阻塞。
- 有缓冲通道适用于解耦发送和接收操作的场景，允许发送者和接收者在处理速度上有一定的差异。常用于**异步传递数据**的场景，==例如生产者-消费者模型，其中生产者可以快速发送数据，而消费者以自己的速度处理数据。==

#### 无缓冲

- 无缓冲通道是指没有预先分配存储空间的通道。发送操作（`channel <- value`）会阻塞，直到有接收操作（`value := <-channel`）准备好接收数据。
- 无缓冲通道适用于要求发送和接收操作同步进行的场景，即发送者和接收者必须同时准备好，实现了数据的**同步传递**。==常用于控制并发的场景，例如使用通道来进行任务的同步和协调==。

### channel 是否线程安全？锁用在什么地方？

1. Golang的Channel,发送一个数据到Channel 和 从Channel接收一个数据都是`原子性`的，都会加锁，保证同一时间只有一个goroutine可以操作。
2. 而且Go的设计思想就是:不要通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。
3. 也就是说，设计Channel的主要目的就是在多任务间传递数据的，这当然是安全的

当多个goroutine通过Channel进行通信时，Channel会保证每个操作的原子性和顺序性，避免了多个goroutine同时访问共享变量导致的数据竞争问题。Channel的阻塞特性也保证了在发送和接收操作发生时，它们会被添加到等待队列中，直到满足条件后才会被唤醒，从而避免了死锁问题。

### Channel 有缓存和没缓存的区别是什么？

无缓冲的与有缓冲 channel 有着重大差别，那就是一个是同步的 一个是非同步的。 比如：

```go
c1:=make(chan int)        //无缓冲
c2:=make(chan int,1)      //有缓冲
c1<-1
```

**无缓冲**： 不仅仅是向 c1 通道放 1，而是一直要等有别的携程 <-c1 接手了这个参数，那么 c1<-1 才会继续下去，要不然就一直阻塞着。 **有缓冲**： c2<-1 则不会阻塞，因为缓冲大小是 1 （其实是缓冲大小为 0 )，只有当放第二个值的时候，第一个还没被人拿走，这时候才会阻塞。

管道没有缓冲区时，从管道中读取数据会阻塞，直到有协程向管道中写入数据。同样，向管道中写入数据也会阻塞，直到有协程从管道中读取数据。
管道中有缓冲区没有数据时，读数据也会阻塞，直到有协程写入数据。向管道中写数据，如果缓冲区已满，那么也会阻塞，直到有协程从缓冲区读数据。
管道表达式最多给两个变量赋值`x, ok := <-ch`

### channel 读写情况

nil、关闭的 channel、有数据的 channel，再进行读、写、关闭会怎么样？（各类变种题型，重要）

- 给一个 nil channel 发送数据，造成永远阻塞
- 从一个 nil channel 接收数据，造成永远阻塞
- 给一个已经关闭的 channel 发送数据，引起 panic
- 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值
- 无缓冲的channel是同步的，而有缓冲的channel是非同步的

以上5个特性是死东西，也可以通过口诀来记忆：“**空读写阻塞，写关闭异常，读关闭空零**”。

-   channel的零值可以为nil 。对这样的channel发送或接收会永远阻塞。
-   在select语句中操作nil的channel永远都不会被select到,我们可以用这个特性来激活或者禁用case

==panic 出现的场景有：==

-   关闭值为 nil 的 channel
-   关闭已经关闭的 channel
-   向已经关闭的 channel 中写数据

### Channel 可能会引发 goroutine 泄漏。

泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。同时，垃圾回收器也不会回收此类资源，进而导致 gouroutine 会一直处于等待队列中，不见天日。
另外，程序运行过程中，对于一个 channel，如果没有任何 goroutine 引用了，gc 会对其进行回收操作，不会引起内存泄漏。

### channel的死锁问题

1. channel满了就阻塞写，空了就阻塞读
2. 阻塞之后交出cpu，去执行其他协程，希望其他协程能解除自己的阻塞
3. 如果阻塞发生在main进程中，并且没有其他子进程可以执行，那么可以确定会永远阻塞，此时会报fatal error:deadlock
4. 如果阻塞发生在子协程中，就不会发生死锁，因为会一直等待main进程

### 退出程序时如何防止channel没消费完？

**不要在消费端关闭channel**，不要在有多个并行的生产者时对channel执行关闭操作，应只在唯一或最后唯一剩下的生产者协程中关闭channel，来通知消费者已经无值可读。
**退出程序的时候,将生产者关闭,不会产生多余的数据给消费者消费**

### Channel为什么需要两个队列实现

一个Channel可以被看作是一个通信通道，用于在不同的进程之间传递数据。在具体的实现中，一个Channel通常需要使用两个队列来实现。这两个队列是发送队列和接收队列。

使用两个队列实现Channel的主要原因是为了实现异步通信。发送进程可以在发送数据之后立即继续执行其他任务，而不需要等待接收进程确认收到数据。同样，接收进程也可以在等待数据到达的同时执行其他任务。这种异步通信的实现方式可以提高系统的吞吐量和响应速度

### channel协程通知的功能怎么实现的 

channel是通过注册相关goroutine id实现消息通知的

从阻塞度协程队列中取出一个 goroutine 的封装对象 sudog。
在 send 方法中，会基于 memmove 方法，直接将元素拷贝交给 sudog 对应的 goroutine；

### 那等待的goroutine是什么时候开始运行呢？它会立即唤醒它吗？ 

它是先拷贝完再唤醒
等待接收的goroutine被拷贝数据过去后，会调用goready，放到P的runnext，本地队列，全局队列（一半）。

runqput：如果不是竞争状态，放到p.runnext将原来的runnext放到本地队列中
如果本地队列满了，就将原来的和一半g放到全局队列中。

### Channel底层是使用锁控制并发的，为什么不直接使用锁

-   **CSP** 模型中，基于**管道** 通信，相对于 **对共享内存加锁** 属于一种程序设计上的抽象与封装
-   基于**管道** 通信，类比于生产者-消费者模型，属于一种逻辑上的解耦，相似的还有**Java中线程池**结构

-   本身 `Channel` 能够实现锁的功能。
-   `channel` 的可扩展性非常高，除了共享内存，还能满足协程之间数据通信场景，控制共享内存仅仅是`channel`的一个功能

首先，Channel比锁更加高级和抽象。Channel可以实现多个goroutine之间的同步和数据传递，不需要程序员显式地使用锁来进行线程间的协调。Channel可以避免常见的同步问题，比如死锁、饥饿等问题。

其次，Channel在语言层面提供了一种更高效的并发模型。在使用锁进行并发控制时，需要程序员自己手动管理锁的获取和释放，这增加了代码复杂度和错误的风险。而使用Channel时，可以通过goroutine的调度和Channel的阻塞机制来实现更加高效和简单的并发控制。

此外，Channel还可以避免一些由锁导致的性能问题，如锁竞争、锁粒度过大或过小等问题。Channel提供了一种更加精细的控制机制，能够更好地平衡不同goroutine之间的并发性能。

### 读写流程

**向 channel 写数据**：

若等待接收队列 recvq 不为空，则缓冲区中无数据或无缓冲区，将直接从 recvq 取出 G ，并把数据写入，最后把该 G 唤醒，结束发送过程。

若缓冲区中有空余位置，则将数据写入缓冲区，结束发送过程。

若缓冲区中没有空余位置，则将发送数据写入 G，将当前 G 加入 sendq ，进入睡眠，等待被读 goroutine 唤醒。

**从 channel 读数据**：

若等待发送队列 sendq 不为空，且没有缓冲区，直接从 sendq 中取出 G ，把 G 中数据读出，最后把 G 唤醒，结束读取过程。

如果等待发送队列 sendq 不为空，说明缓冲区已满，从缓冲区中首部读出数据，把 G 中数据写入缓冲区尾部，把 G 唤醒，结束读取过程。

如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程。

将当前 goroutine 加入 recvq ，进入睡眠，等待被写 goroutine 唤醒。

**关闭 channel**：

关闭 channel 时会将 recvq 中的 G 全部唤醒，本该写入 G 的数据位置为 nil。将 sendq 中的 G 全部唤醒，但是这些 G 会 panic。

panic 出现的场景还有：

-   关闭值为 nil 的 channel
-   关闭已经关闭的 channel
-   向已经关闭的 channel 中写数据

### channel底层实现

[Golang | 从源码分析Channel - 掘金 (juejin.cn)](https://juejin.cn/post/7097617352740569102)
底层是用数组实现的环形队列，还加了锁

**Channel是通过一个有缓存的队列来实现的，底层数据结构是一个双向链表。** 是一个叫做hchan的结构体，每个Channel都有一个send队列和一个receive队列，用于存放发送和接收操作的goroutine。当发送操作和接收操作发生时，它们会被添加到对应的队列中，等待对方的操作来满足条件。
明白channel是通过注册相关goroutine id实现消息通知的

```go
type hchan struct {
	qcount   uint // chan 里元素数量
	dataqsiz uint // channel循环队列的长度 ,make channel中的len属性 ，即缓冲区大小
	buf      unsafe.Pointer // channel缓冲区数据指针,指向底层循环数组的指针
	elemsize uint16 // channel元素的大小,是 elem元数据类型的大小
	closed   uint32 // chan 是否被关闭的标志
	elemtype *_type // element type chan 中元素类型
	// channel的send操作处理到的位置；
	sendx    uint   // send index已发送元素在循环数组中的索引
	// channel的recv操作处理到的位置；
	recvx    uint   // receive index已接收元素在循环数组中的索引
	// 等待队列(即 <- channel )
	recvq    waitq  // list of recv waiters等待接收的 goroutine 队列
	// 等待队列(即 channel <- )
	sendq    waitq  // list of send waiters等待发送的 goroutine 队列

	// 保护 hchan 中所有字段
	lock mutex
}

// 等待队列是一个`sudog`结构的双向链表
type waitq struct { 
	first *sudog 
	last *sudog 
}
// `sudog`结构其实就是一个goroutine ，同时持有前后`sudog`的地址，是一个双向链表
type sudog struct { 
	g *g // 指向goroutine结构体
	next *sudog // 前sudog 
	prev *sudog // 后sudog 
	elem unsafe.Pointer //数据元素（可以指向堆栈）
	isSelect bool // 当前g是否在select中，此时不会真正的阻塞
	c *hchan // 标识与当前 sudog 交互的 chan.
	success bool // 当前g被唤醒是因为从c中取到数据true或false表示c被关闭


	acquiretime int64
	releasetime int64
	ticket      uint32

	parent   *sudog // semaRoot binary tree与当前sudog相关的父sudog。
	waitlink *sudog // g.waiting list or semaRoot等待链表中的前置节点（等待链表用于多个goroutine争抢共享资源时的等待和唤醒）。
	waittail *sudog // semaRoot
} 
```

![j5co0](attachments/j5co0.webp)

- `buf` 指向底层循环数组，只有缓冲型的 channel 才有。
- `sendx`，`recvx` 均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）。
- `sendq`，`recvq` 分别表示被阻塞的 goroutine，这些 goroutine 由于尝试读取 channel 或向 channel 发送数据而被阻塞。
- `waitq` 是 `sudog` 的一个双向链表，而 `sudog` 实际上是对 goroutine 的一个封装
- `lock` 用来保证每个读 channel 或写 channel 的操作都是原子的。

### 源码解读

#### gopark和goready

源码当中有两个系统函数出现的次数较频繁，这里简单介绍一下他们的作用

`gopark`的作用

1.  解除当前goroutine的m的绑定关系，将当前goroutine状态机切换为**waiting** 状态
2.  调用一次schedule()函数，在局部调度器P发起一轮新的调度。
3.  这个时候的 **G** 没有进入调度队列

`goready`的作用

1.  当前goroutine的状态机切换到 **runnable** 状态
2.  **M** 重新进入调度循环
3.  goroutine进入local queue ，等待 **P** 调度

#### 创建chan

使用make方法创建channel，最终会调用`runtime.makechan` ，方法很简单，只做了两件事：**参数校验**和**分配hchan和buf内存**

1.  如果channel元素类型不包含指针类型，会在堆上分配一段连续的内存，同时sudog会引用该hchan，该hchan不会被gc回收
2.  如果channel元素类型不包含指针类型，会为buf和hchan分配内存
3.  channel的内存分配涉及到内存对齐的计算

- 判断申请内存空间大小是否越界，mem 大小为 element 类型大小与 element 个数相乘后得到，仅当无缓冲型 channel 时，因个数为 0 导致大小为 0；
- 根据类型，初始 channel，分为 `无缓冲型`、`有缓冲元素为 struct 型`、`有缓冲元素为 pointer 型` channel;
- 倘若为无缓冲型，则仅申请一个大小为默认值 96 的空间；
- 如若有缓冲的 struct 型，则一次性分配好 96 + mem 大小的空间，并且调整 chan 的 buf 指向 mem 的起始位置；
- 倘若为有缓冲的 pointer 型，则分别申请 chan 和 buf 的空间，两者无需连续；
- 对 channel 的其余字段进行初始化，包括元素类型大小、元素类型、容量以及锁的初始化.

#### 发送数据 ch <- data

使用`ch <- data` 往channel里推数据，最终会调用`runtinme.chansend`方法  
源码很长，主要做了三个事情:

1. 当chan为nil(没有用make声明)，直接调用gopark挂起，并报**死锁**
2. 当chan已经关闭，会panic
3. 加锁
4. 当recvq存在等待者时，直接进入`send`方法。解锁
5.  当缓冲区存在空余空间时，将发送的数据写入channel的缓冲区。解锁
6.  当不存在缓冲区或者缓冲区已满时，等待其他goroutine从channel 接收数据。将写的goroutine调用`gopark`阻塞。解锁
7. 阻塞的g如果是因为chan关闭而被唤醒，panic

`send`方法：

1.  调用 `runtime.sendDirect`将发送的数据直接拷贝到 `x = <-c` 表达式中变量 `x` 所在的内存地址上；
2.  调用 `runtime.goready` 将等待接收数据的goroutine标记成可运行状态`grunnable`并把该 goroutine放到发送方所在的处理器的 `runnext` 上等待执行，该处理器在下一次调度时会立刻唤醒数据的接收方；

#### 接收数据 data <- ch

使用`data <- channel` 从channel里接收数据，会被转换成`runtime.chanrecv1`和`runtime.chanrecv2`。 他们最终会调用`runtinme.chanrecv`方法，主要流程如下:

1.  如果channel为空nil，那么会直接调用 `gopark` 挂起当前goroutine，并报**死锁**
2. 加锁
3.  如果channel已经关闭并且缓冲区没有任何数据，直接解锁返回返回零值
4.  如果channel的 `sendq` 队列中存在挂起的 goroutin（说明此时缓冲区已满），会将 `recvx` 索引所在的数据拷贝到接收变量所在的内存空间上并将 `sendq` 队列中 goroutine 的数据拷贝到缓冲区，移动指针，解锁，然后将首部的g执行`goready`
5.  如果channel的缓冲区中包含数据，那么直接读取 `recvx`索引对应的数据，移动指针，解锁
6. 无数据时，gopark挂起当前的goroutine，同时将`sudog`结构推入`recvq`队列并进入休眠状态，解锁，等待发送者向channel发送数据，从而唤醒当前goroutine。

`recv`方法：

1.  当缓冲区存在数据时，从 channel 的缓冲区中接收数据；
2.  当缓冲区中不存在数据时，等待其他 goroutine 向 channel 发送数据
3.  最后使用`goready`,在调度器下一次调度时将阻塞的发送方唤醒

#### 非阻塞模式

默认模式下chan都是阻塞模式，只有在select语句中组成的多路复用分支中，需要同时监听多个chan，与chan的交互会变成非阻塞模式

非阻塞模式下，读写chan方法通过一个bool型响应参数，用以标识是否读写成功

- 所有需要使得当前 goroutine 被挂起的操作，在非阻塞模式下都会返回 false;
- 所有是的当前 goroutine 会进入死锁的操作，在非阻塞模式下都会返回 false;
- 所有能立即完成读取/写入操作的条件下，非阻塞模式下会返回 true.

#### 关闭chan

1. 如果channel为空nil，panic
2. 加锁
3. 如果chan已经被关闭了，panic
4. 所有的阻塞的读或写goroutine都会加入glist，读g放入零值
5. 解锁

## select

select 是 Go 中的一个控制结构，类似于 switch 语句。
select 语句只能用于通道操作，每个 case 必须是一个通道操作，要么是发送要么是接收。
select 语句会监听所有指定的通道上的操作，一旦其中一个通道准备好就会执行相应的代码块。
==如果多个通道都准备好，那么 select 语句会随机选择一个通道执行。如果所有通道都没有准备好，那么执行 default 块中的代码。==

```go
for {  
	select {  
    case msg1 := <-ch1:  
      fmt.Println(msg1)  
    case msg2 := <-ch2:  
      fmt.Println(msg2)  
    default:  
      // 如果两个通道都没有可用的数据，则执行这里的语句  
      fmt.Println("no message received")  
    }
}
```

我们可以通过监听一个 `退出通道` 来做到超时控制。  
`退出通道`可以用`time.After()` 也可以用`context.Done()`，或者是一个程序级别的`closeChannel`

#### 底层

`select`在底层不存在单独的结构体，我们使用`runtime.scase`表示`select` 中的 `case`。
可以看到，每个`case块`持有一个`chan指针`， `default`是一个特殊的`scase` ，用`retc`表示

```go
type scase struct { 
	c *hchan // chan elem 
	unsafe.Pointer // data element 
}
```

**准备阶段**：
在准备阶段，有三种情况时，编译器会优化:

1.  没有case和default情况下，直接调用gopark()使当前协程永远阻塞 。
2.  如果只有一个case，那么select会被优化成一个if语句.
3.  只有一个case和default.
    -   如果这个case是发送操作，会直接调用channel.chansend()进行一次非阻塞的发送
    -   如果是接收操作，会直接调用chan.chanrecv()进行一次非阻塞的接收操作

**执行过程**：
`select` 执行过程位于 `runtime.selectgo` 方法中。我们来看一下

方法运行过程主要分为4个阶段

1.  按照规则生成遍历顺序 pollorder && lockorder（pollorder随机）
2.  按pollorder顺序尝试channel是否ready
3.  如果 (2)都不满足  
    3.1 如果有default语句 ，执行default语句后返回  
    3.2 如果没有default语句 ，阻塞当前协程，将当前协程压入所有channel的等待队列&&接收队列中，等待唤醒
4.  被唤醒后，按lockorder顺序解锁scases，从其他channel中将本sudog出队，返回 caseIndex

## 锁

### go的锁机制了解过吗？

Golang 中的有两种锁，为 `sync.Mutex` 和 `sync.RWMutex`

-   `sync.Mutex` 的锁只有一种锁：`Lock()`，它是绝对锁，同一时间只能有一个锁。悲观锁，读写互斥。
-   `sync.RWMutex` 叫读写锁，它有两种锁： `RLock()` 和 `Lock()`：
    -   `RLock()` 叫读锁。它不是绝对锁，可以有多个读者同时获取此锁（调用 `mu.RLock`）。
    -   `Lock()` 叫写锁，它是个绝对锁，就是说，如果一旦某人拿到了这个锁，别人就不能再获取此锁了。
-   **当写锁阻塞时，新的读锁是无法申请的**。

即在 `sync.RWMutex` 的使用中，一个线程请求了他的写锁（`mx.Lock()`）后，即便它还没有取到该锁（可能由于资源已被其他人锁定），后面所有的读锁的申请，都将被阻塞，只有取写锁的请求得到了锁且用完释放后，读锁才能去取。

### 自旋锁

**自旋锁**是用于多线程同步的一种锁，线程反复检查锁变量是否可用。由于线程在这一过程中保持执行，因此是一种忙等待。一旦获取了自旋锁，线程会一直保持该锁，直至显式释放自旋锁。自旋锁避免了进程上下文的调度开销，因此对于线程只会阻塞很短时间的场合是有效的。

**缺点**：

-   某个协程持有锁时间长，等待的协程一直在循环等待，消耗CPU资源。
-   不公平，有可能存在有的协程等待时间过程，出现线程饥饿（这里就是协程饥饿）

#### 过程

-   加锁时，如果当前 Locked 位为 1，则说明该锁当前是由其他协程持有，尝试加锁的协程并不会马上转入阻塞，而是**会持续的探测 Locked 位是否变为 0**，这个过程即为自旋过程。
-   自旋的时间很短，但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。
-   自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。

#### 条件

自旋必须满足以下所有条件：

-   自旋的次数要足够小，通常为4，即「**自旋最多为4次**」
-   CPU 核数要大于1，否则自旋是没有意义的，因为此时不可能有其他协程释放锁
-   协程调度机制中的 Process 数量要大于 1，比如使用 GOMAXPROCS() 将处理器设置为 1 就不能启用自旋
-   **协程调度机制中的可运行队列必须为空**，否则会延迟协程调度

### Mutex的锁有哪几种模式，分别介绍一下？

Go实现的互斥锁有两种模式，分别是 **正常模式** 和 **饥饿模式**。

#### 正常模式 （互斥锁）

正常情况下，Golang使用 **Barging**方式 移交锁的所有权，在并发抢占锁的过程中，抢不到锁的Goroutine会进入`waiter队列`（按照先进先出（**FIFO**）的方式获取锁）。但是一个刚被唤醒的`waiter`与新到达的`goroutine`竞争锁时，大概率是干不过的。这是为什么呢？

因为新来的`goroutine`有一个优势：它已经在CPU上运行，并且有可能不止一个`新来的goroutine`，因此`waiter`极有可能还是拿不到锁，灰溜溜的继续在`waiter队列`中排队。

#### 饥饿模式

如果自旋过程中获得锁，那么之前被阻塞的协程将无法获得锁，如果加锁的协程特别多，每次都通过自旋获得锁，那么之前被阻塞的进程将很难获得锁，从而进入「饥饿状态」。

为了避免`waiter`长时间抢不到锁，当`waiter`超过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式。
在饥饿模式下，Golang使用 **Handoff方式** 来移交锁的所有权直接从解锁的`goroutine`转移到等待队列中的队头`waiter`。新来的`goroutine`不会尝试去获取锁，也不会自旋。它们将在`waiter队列`的队尾排队。

在饥饿模式中，互斥锁会直接交给等待队列最前面的goroutine。新的goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待。

#### 何时退出饥饿模式

如果某`waiter`获取到了锁，并且满足以下两个条件之一，它就会将锁从饥饿模式切换回正常模式。

-   它是`waiter队列`中最后一个Goroutine
-   它等待获取锁的时间 < 1ms

### 什么是CAS机制（compare and swap）

CAS算法的作用：解决多线程条件下使用锁造成性能损耗问题的算法，保证了原子性，这个原子操作是由CPU来完成的
CAS的原理：CAS算法有三个操作数，通过内存中的值（V）、预期原始值（A)、修改后的新值。
1. 如果内存中的值和预期原始值相等， 就将修改后的新值保存到内存中。
2. 如果内存中的值和预期原始值不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作，直到重试成功。

### Mutex锁底层如何实现？

[Golang |深入理解互斥锁Mutex - 掘金 (juejin.cn)](https://juejin.cn/post/7095334586019741704)

`Mutex` 是一个结构体，对外提供 `Lock()`和`Unlock()`两个方法，分别用来加锁和解锁。一个mutex对象仅占用8个字节
```go
// A Locker represents an object that can be locked and unlocked. 
type Locker interface {
	Lock() 
	Unlock()
} 
type Mutex struct { 
    // pad用于避免"false sharing"问题，
    // 也就是在不同CPU缓存线程之间共享同一个变量时，
    // 这个变量频繁被不同线程修改导致缓存失效的问题。
    pad  [cacheLineSize - cpu.CacheLinePadSize]byte
	state int32  // 代表互斥锁的状态，比如是否被锁定
	sema uint32 //表示信号量，协程阻塞会等待该信号量，解锁的协程释放信号量从而唤醒等待信号量的协程。
} 

const ( 
	mutexLocked = 1 << iota // mutex is locked 
	mutexWoken // 2 ;从正常模式被从唤醒; 2^1
	mutexStarving // 4 ;处于饥饿状态; 2^2
	mutexWaiterShift = iota // 3 ;获得互斥锁上等待的Goroutine个数需要左移的位数: 1 << mutexWaiterShift
	starvationThresholdNs = 1e6 // 锁进入饥饿状态的等待时间
)
```

其中`state`表示当前互斥锁的状态，`sema`表示控制锁状态的信号量.
注意到 state 是一个 int32 变量，内部实现时把该变量分成四份，用于记录 Mutex 的状态。

1.  pad字段：pad字段用于避免"false sharing"问题，这个问题指的是在多个 CPU 缓存线程之间共享同一个变量时，如果这个变量频繁被不同线程修改，会导致缓存失效，从而影响性能。而通过增加一个临时的、无需共享的缓存行，可以减少这种现象的出现，提高线程安全性能。
2.  state字段：state字段表示互斥锁的状态，其值为0表示锁处于未锁定状态，而非0表示锁已经处于锁定状态。当一个goroutine想要获取这个互斥锁时，它会在state字段的值变成0之前等待。当一个goroutine持有这个互斥锁时，它会将state字段设成非0值表示锁已经被占用。
3.  sema字段：sema字段是信号量，用于阻塞等待这个互斥锁的goroutine。当一个goroutine尝试获取这个互斥锁时，如果锁已经被占用，那么这个goroutine会在sema字段上进行等待。当一个持有该互斥锁的goroutine释放锁时，它会通过sema字段唤醒一个等待的goroutine。

-   `Locked`: 表示该 Mutex 是否已经被锁定，0表示没有锁定，1表示已经被锁定；
-   `Woken`: 表示是否有协程已经被唤醒，0表示没有协程唤醒，1表示已经有协程唤醒，正在加锁过程中；标志出当前是否已有 goroutine 在自旋抢锁或存在 goroutine 从阻塞队列中被唤醒；倘若 mutexWoken 为 1，且此时有解锁动作发生时，就没必要再额外唤醒阻塞的 goroutine 从而引起竞争内耗
-   `Starving`: 表示该 Mutex 是否处于饥饿状态，0表示没有饥饿，1表示饥饿状态，说明有协程阻塞了超过1ms；

  上面三个表示了 Mutex 的三个状态：锁定 - 唤醒 - 饥饿。

`Waiter` 信息虽然也存在 state 中，其实并不代表状态。它表示阻塞等待锁的协程个数（2^29 -1个），协程解锁时根据此值来判断是否需要释放信号量。

协程之间的抢锁，实际上争抢给`Locked`赋值的权利，能给 `Locked` 置为1，就说明抢锁成功。抢不到就阻塞等待 `sema` 信号量，一旦持有锁的协程解锁，那么等待的协程会依次被唤醒。

`Woken` 和 `Starving` 主要用于控制协程间的抢锁过程。

#### 上锁/解锁

遵循由简入繁的思路，我们首先忽略大量的实现细节以及基于并发安全角度的逻辑考量，思考实现一把锁最简单纯粹的主干流程：

-  通过 Mutex 内一个状态值标识锁的状态，例如，取 0 表示未加锁，1 表示已加锁；
-  上锁：把 0 改为 1；
-  解锁：把 1 置为 0.
-  上锁时，假若已经是 1，则上锁失败，需要等他人解锁，将状态改为 0.

#### 由自旋到阻塞的升级过程

针对 goroutine 加锁时发现锁已被抢占的这种情形，此时的策略有如下两种：

-  阻塞/唤醒：将当前 goroutine 阻塞挂起，直到锁被释放后，以回调的方式将阻塞 goroutine 重新唤醒，进行锁争夺；
-  自旋 + CAS：基于自旋结合 CAS 的方式，重复校验锁的状态并尝试获取锁，始终把主动权握在手中.

| 方案      | 优势                           | 劣势                                   | 适用场景             |
| --------- | ------------------------------ | -------------------------------------- | -------------------- |
| 阻塞/唤醒 | 精准打击，不浪费 CPU 时间片    | 需要挂起协程，进行上下文切换，操作较重 | 并发竞争激烈的场景   |
| 自旋+CAS  | 无需阻塞协程，短期来看操作较轻 | 长时间争而不得，会浪费 CPU 时间片      | 并发竞争强度低的场景 | 

sync.Mutex 结合两种方案的使用场景，制定了一个锁升级的过程，反映了面对并发环境通过持续试探逐渐由乐观逐渐转为悲观的态度，具体方案如下：

-  首先保持乐观，goroutine 采用自旋 + CAS 的策略争夺锁；
-  尝试持续受挫达到一定条件后，判定当前过于激烈，则由自旋转为 阻塞/挂起模式.

上面谈及到的由自旋模式转为阻塞模式的具体条件拆解如下：

-  自旋累计达到 4 次仍未取得锁；
-  CPU 单核或仅有单个 P 调度器；（此时自旋，其他 goroutine 根本没机会释放锁，自旋纯属空转）；
-  当前 P 的执行队列中仍有待执行的 G. （避免因自旋影响到 GMP 调度效率）.

#### 饥饿模式

-  `饥饿`：顾名思义，是因为非公平机制的原因，导致 Mutex 阻塞队列中存在 goroutine 长时间取不到锁，从而陷入饥荒状态；
-  `饥饿模式`：当 Mutex 阻塞队列中存在处于饥饿态的 goroutine 时，会进入模式，将抢锁流程由非公平机制转为公平机制.

在 sync.Mutex 运行过程中存在两种模式：

-  **正常模式/非饥饿模式**：这是 sync.Mutex 默认采用的模式. 当有 goroutine 从阻塞队列被唤醒时，会和此时先进入抢锁流程的 goroutine 进行锁资源的争夺，假如抢锁失败，会重新回到阻塞队列头部.
（值得一提的是，此时被唤醒的老 goroutine 相比新 goroutine 是处于劣势地位，因为新 goroutine 已经在占用 CPU 时间片，且新 goroutine 可能存在多个，从而形成多对一的人数优势，因此形势对老 goroutine 不利.）
-  **饥饿模式**：这是 sync.Mutex 为拯救陷入饥荒的老 goroutine 而启用的特殊机制，饥饿模式下，锁的所有权按照阻塞队列的顺序进行依次传递. 新 goroutine 进行流程时不得抢锁，而是进入队列尾部排队.

两种模式的转换条件：

-  默认为正常模式；
-  正常模式 -> 饥饿模式：当阻塞队列存在 goroutine **等锁超过 1ms 而不得**，则进入饥饿模式；
-  饥饿模式 -> 正常模式：当阻塞队列已清空，或取得锁的 goroutine 等锁时间已低于 1ms 时，则回到正常模式.

#### TryLock 

1.18

```go
func (m *Mutex) TryLock() bool {  
   old := m.state  
   if old&(mutexLocked|mutexStarving) != 0 {  
      return false  
   }    
   if !atomic.CompareAndSwapInt32(&m.state, old, old|mutexLocked) {  
      return false  
   }  
   if race.Enabled {  
      race.Acquire(unsafe.Pointer(m))  
   }  
   return true  
}
```

### RWMutex底层

```go
type RWMutex struct {
 w           Mutex  // 控制 writer 在 队列B 排队
 writerSem   uint32 // 写信号量，用于等待前面的 reader 完成读操作
 readerSem   uint32 // 读信号量，用于等待前面的 writer 完成写操作
 readerCount int32  // reader 的总数量，同时也指示是否有 writer 在队列A 中等待
 readerWait  int32  // 队列A 中 writer 前面 reader 的数量
}

// 允许最大的 reader 数量，共享读锁的 goroutine 数量上限，值为 2^29
const rwmutexMaxReaders = 1 << 30
```

可以看到，RWMutex 的成员有一个互斥锁（用于在写入时获取），读写者的信号量，读者数量等。

- 从逻辑上，可以把 RWMutex 理解为一把读锁加一把写锁；
- 写锁具有严格的排他性，当其被占用，其他试图取写锁或者读锁的 goroutine 均阻塞；
- 读锁具有有限的共享性，当其被占用，试图取写锁的 goroutine 会阻塞，试图取读锁的 goroutine 可与当前 goroutine 共享读锁；
- 综上可见，RWMutex 适用于读多写少的场景，最理想化的情况，当所有操作均使用读锁，则可实现去无化；最悲观的情况，倘若所有操作均使用写锁，则 RWMutex 退化为普通的 Mutex.

**当写锁被阻塞时，即使是被读锁阻塞的，写锁后续的读锁也会被阻塞**
#### 上读锁

- 基于原子操作，将 RWMutex 的 readCount 变量加一，表示占用或等待读锁的 goroutine 数加一；
- 倘若 RWMutex.readCount 的新值仍==小于 0==，说明有 goroutine 未释放写锁，因此将当前 goroutine 添加到读锁的阻塞队列中并阻塞挂起.

#### 解读锁

- 基于原子操作，将 RWMutex 的 readCount 变量加一，表示占用或等待读锁的 goroutine 数减一；
- 倘若 RWMutex.readCount 的新值小于 0，说明有 goroutine 在等待获取写锁，则走入 RWMutex.rUnlockSlow 的流程中.
- 对 RWMutex.readerCount 进行校验，倘若发现当前协程此前未抢占过读锁，或者介入读锁流程的 goroutine 数量达到上限，则抛出 fatal；
(倘若 r+1 == -rwmutexMaxReaders，说明此时有 goroutine 介入写锁流程，但当前此前未加过读锁；倘若 r+1=0，则要么此前未加过读锁，要么介入读锁流程的 goroutine 数量达到上限)
- 基于原子操作，对 RWMutex.readerWait 进行减一操作，倘若其新值为 0，说明当前 goroutine 是最后一个介入读锁流程的协程，因此需要唤醒一个等待写锁的阻塞队列的 goroutine.（综合 RWMutex.readerCount 为负值，可以确定存在等待写锁的 goroutine）

#### 上写锁

- 对 RWMutex 内置的互斥锁进行加锁操作；
- 基于原子操作，对 RWMutex.readerCount 进行减少 -rwmutexMaxReader(即-2^30) 的操作；
- 倘若此时存在未释放读锁的 gouroutine，则基于原子操作在 RWMutex.readerWait 的基础上加上介入读锁流程的 goroutine 数量，并将当前 goroutine 添加到写锁的阻塞队列中挂起.

#### 解写锁

- 基于原子操作，将 RWMutex.readerCount 的值加上 rwmutexMaxReaders；
- 倘若发现 RWMutex.readerCount 的新值大于 rwmutexMaxReaders，则说明要么当前 RWMutex 未上过写锁，要么介入读锁流程的 goroutine 数量已经超限，因此直接抛出 fatal；
- 因此唤醒读锁阻塞队列中的所有 goroutine；(可见，竞争读锁的 goroutine 更具备优势)
- 解开 RWMutex 内置的互斥锁.

#### 注意

1. 当reader前面有writer进行锁等待阻塞时，即使现在有reader持有读锁，当前的reader仍然会阻塞挂起，因为writer挂起时已经将底层readerCount减1<<30了
2. 最后一个reader解锁时，发现readerWait等于0，则会去唤醒等待的writer
3. writer解锁时会先把所有阻塞的reader唤醒，再去解互斥锁，唤醒writer
4. writer先获取到互斥锁上锁，然后在判断是否有reader进行阻塞，因此后续writer会阻塞挂载到互斥锁的等待队列中

## 接口inteface

在Golang中接口（interface）是一种类型，一种抽象的类型。接口（interface）是一组函数method的集合，Golang中的接口不能包含任何变量。

在 Golang 中，interface 是一组 method 的集合，是 duck-type programming 的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。

```go
type 接口名 interface {
    方法名1 (参数列表1) 返回值列表1
    方法名2 (参数列表2) 返回值列表2
}
```

1. interface 是方法声明的集合
2. 任何类型的对象实现了在interface 接口中声明的全部方法，则表明该类型实现了该接口。  
3. interface 可以作为一种数据类型，实现了该接口的任何对象都可以给对应的接口类型变量赋值

 注意：  
1. interface 可以被任意对象实现，一个类型/对象也可以实现多个 interface  
2. 方法不能重载，如 eat() eat(s string) 不能同时存在

### 空接口

空接口可以作为函数的参数，使用空接口可以接收任意类型的函数参数

```go
// 空接口表示没有任何约束，任意的类型都可以实现空接口
type EmptyA interface {

}

func main() {
    var a EmptyA
    var str = "你好golang"
    // 让字符串实现A接口
    a = str
    fmt.Println(a)

	var a interface{}
	a = 20
	a = "hello"
	a = true
}
```

### 两个接口可以比较吗？

`DeepEqual` 函数的参数是两个 `interface`，实际上也就是可以输入任意类型，输出 true 或者 flase 表示输入的两个变量是否是“深度”相等。

```go
// 判断类型是否一样
reflect.TypeOf(a).Kind() == reflect.TypeOf(b).Kind()
// 判断两个interface{}是否相等
reflect.DeepEqual(a, b interface{})
// 将一个interface{}赋值给另一个interface{}
reflect.ValueOf(a).Elem().Set(reflect.ValueOf(b))
```

### 类型断言

前面说过，因为空接口 `interface{}` 没有定义任何函数，因此 Go 中所有类型都实现了空接口。当一个函数的形参是 `interface{}`，那么在函数中，需要对形参进行断言，从而得到它的真实类型。

类型断言的本质，跟类型转换类似，都是类型之间进行转换，不同之处在于，类型断言实在接口之间进行

```go
<目标类型的值>，<布尔参数> := <表达式>.( 目标类型 ) // 安全类型断言

<目标类型的值> := <表达式>.( 目标类型 )　　//非安全类型断言
```

```go
func test6() {
    var i interface{} = "TT"
    j, b := i.(int)
    if b {
        fmt.Printf("%T->%d\n", j, j)
    } else {
        fmt.Println("类型不匹配")
    }
}
```

**空接口类型断言实现流程：空接口类型断言实质是将`eface`中`_type`与要匹配的类型进行对比，匹配成功在内存中组装返回值，匹配失败直接清空寄存器，返回默认值。**

**小结**：**非空接口类型断言的实质是 iface 中 `*itab` 的对比。`*itab` 匹配成功会在内存中组装返回值。匹配失败直接清空寄存器，返回默认值。**

### 作用

1. 空接口
   1. **通用类型**：实现可以接收任意类型的函数参数，保存任意值的字典。
   2. **类型断言**：当我们需要在运行时确定一个值的类型时，可以使用类型断言将空接口转换为其他类型。
   3. **泛型编程**：可以使用空接口将不同的类型转换为通用的类型，在函数或方法中进行处理，然后再将其转换为原来的类型。
2. 接口可以**定义通用的行为，提高代码复用性**。例如，如果你编写了一个可以排序的数据结构，你可以定义一个名为Sort的接口，它定义了一个排序方法，然后任何实现了Sort接口的类型都可以使用这个排序方法。
3. 接口可以**实现多态性**，让一个变量可以持有多种类型的值。这使得你可以写出更灵活的代码，可以在运行时根据具体情况选择使用哪个具体类型的方法。这对于实现插件系统、扩展性很高的应用程序或者抽象底层实现等场景非常有用。
4. **抽象底层实现**，接口可以降低模块之间的耦合度，增强代码的灵活性和可扩展性。通过面向接口编程，不同的模块之间可以更容易地协作，可以实现组件化的架构，让系统更加易于维护和扩展。使得上层代码只关注接口定义的行为特征，而不需要关心底层的实现细节。这使得代码更加易于维护和扩展

### 多态 怎么去复用一个接口的方法?

在Go语言中，实现接口只需要实现接口中所有的方法即可。也就是说，当一个类型定义了接口所包含的全部方法时，该类型就自动地实现了该接口。由于Go语言中不存在显示实现的语法，一个类型实现的接口的集合是由该类型自动地决定的。

在Go语言中，接口的嵌套是一种用于组合接口类型的机制。嵌套接口就是将多个接口的方法组合在一起，以便某个类型可以同时满足这些接口的方法要求。

```go
package main

import "fmt"

type Phone interface {
    call()
}

type NokiaPhone struct {
}

func (nokiaPhone NokiaPhone) call() {
    fmt.Println("I am Nokia, I can call you!")
}

type ApplePhone struct {
}

func (iPhone ApplePhone) call() {
    fmt.Println("I am Apple Phone, I can call you!")
}

func main() {
    var phone Phone
    phone = new(NokiaPhone)
    phone.call()

    phone = new(ApplePhone)
    phone.call()
}
```

上述中体现了`interface`接口的语法，在`main`函数中，也体现了`多态`的特性。  
同样一个`phone`的抽象接口，分别指向不同的实体对象，调用的call()方法，打印的效果不同，那么就是体现出了多态的特性。

### 底层 

[【golang】interface原理 - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000038138695)

`iface` 和 `eface` 都是 Go 中描述interface{}的底层结构体，区别在于 `iface` 描述的接口包含方法，而 `eface` 则是不包含任何方法的空接口：`interface{}`。

#### eface

`eface`表示不含 method 的 interface 结构，或者叫 empty interface。对于 Golang 中的大部分数据类型都可以抽象出来 `_type` 结构，同时针对不同的类型还会有一些其他信息。

eface结构体是golang中实现interface的一种方式。在语言中，interface是一种类型，代表了一组方法的签名，也就是说实现一个interface的类型必须拥有该interface定义的一组方法。而在golang中，使用interface时，由于interface的底层实现是复合类型，需要保存类型信息和值信息等，在实现中就要使用到eface结构体。

```go
type eface struct {  
 _type *_type  
 data  unsafe.Pointer  
}  
  
type _type struct {  
 size       uintptr // type size  
 ptrdata    uintptr // size of memory prefix holding all pointers  
 hash       uint32  // hash of type; avoids computation in hash tables  
 tflag      tflag   // extra type information flags  
 align      uint8   // alignment of variable with this type  
 fieldalign uint8   // alignment of struct field with this type  
 kind       uint8   // enumeration for C  
 alg        *typeAlg  // algorithm table  
 gcdata    *byte    // garbage collection data  
 str       nameOff  // string form  
 ptrToThis typeOff  // type for pointer to this type, may be zero  
}  
```

其中_type指向类型信息(type information)，data指向该类型的值(value of type)。因此，eface结构体可以保存任何类型的值，而不需要提前知道其类型。

当程序使用interface来定义变量时，这个变量实际上是一个eface结构体。程序在使用该变量时，可以通过类型信息对其进行断言，并调用具体的方法。

#### iface

`iface` 表示 non-empty interface 的底层实现。相比于 empty interface，non-empty 要包含一些 method。method 的具体实现存放在 itab.fun 变量里。如果 interface 包含多个 method，这里只有一个 fun 变量怎么存呢？这个下面再细说。

```go
type iface struct {  
 tab  *itab   // 方法表
 data unsafe.Pointer  // 具体的值
}  
  
// layout of Itab known to compilers  
// allocated in non-garbage-collected memory  
// Needs to be in sync with  
// ../cmd/compile/internal/gc/reflect.go:/^func.dumptypestructs.  
type itab struct {  
 inter  *interfacetype  
 _type  *_type  
 link   *itab  
 bad    int32  
 inhash int32      // has this itab been added to hash?  
 fun    [1]uintptr // variable sized  
}  
//  包含了一些关于 interface 本身的信息
type interfacetype struct {  
 typ     _type  
 pkgpath name  
 mhdr    []imethod  
}  
  
type imethod struct {   //这里的 method 只是一种函数声明的抽象，比如  func Print() error  
 name nameOff  
 ityp typeOff  
}
```

iface 结构体有两个字段：

-   tab，指向该接口类型变量的方法表指针，其中 itab 是一个包含了该接口类型的方法集的结构体。
-   data，指向该接口类型变量具体的值的指针，其中 data 具体指向实现该接口的具体类型的值。

通过 iface 结构体的方法表指针，可以在运行时动态分派实际调用的具体实现方法。

使用 iface 结构体，可以在运行时实现接口类型的多态，这些多态的接口类型变量指向的具体类型也会在运行时动态确定。因此，iface 结构体在 Go 中的作用非常重要。

### 注意 nil != nil

1.  接口是一种引用类型的数据结构，它的值可以为nil。
2.  **实现接口的类型必须实现接口中所有的方法**，否则会编译错误。
3.  接口的值可以赋给实现接口的类型的变量，反之亦然。
4.  在实现接口的类型的方法中，可以通过类型断言来判断接口值的实际类型和值。

```go
var i interface{} = nil
var j interface{} = (*int)(nil)
var k interface{}
var a chan int
var b chan int
var c chan bool
fmt.Println(i, j, k, a, b, c)
fmt.Println(i == nil, j == nil, a == nil, b == nil, c == nil)
fmt.Println(i == j, i == k, i == a, a == b)
// a == c invalid operation: a == c (mismatched types chan int and chan bool)
// 输出<nil> <nil> <nil> <nil> <nil> 
// true false true true true
// false true false true
```

#### nil特点

- nil 不是关键字或保留字:
   `var nil = errors.New("my god")` 不会报错
- nil没有默认类型：
   `fmt.Printf("%T", nil) // ./hello.go:9:7: use of untyped nil
- 不同类型 nil 的指针是一样的
   ```go
   var arr []int 
   var num *int 
   fmt.Printf("%p %p", arr, num) // 0x0 0x0
```
- nil 是 map、slice、pointer、channel、func、interface 的零值
- 不同类型的 nil 是不能比较的
- 不同类型的 nil 值占用的内存大小可能是不一样的

#### 不能和nil比较的情况 

1. nil 标识符是不能比较的: `invalid operation: nil == nil (operator == not defined on nil)`
2. 不同类型的 nil 是不能比较的
3. `map` 、 `slice` 和 `function` 类型的 `nil` 值不能比较，比较两个无法比较类型的值是非法的

   ```go
   var s1 []int 
   var s2 []int 
   fmt.Printf(s1 == s2) // invalid operation: s1 == s2 (slice can only be compared to nil)
```

## map

Go 语言map采用的是`哈希查找表`，并且使用`链表`解决哈希冲突。

哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。

### 不能做为map的key

slice、map、func
以及包含这些类型的struct

**why**？因为这些类型不可以用` == `比较

### nil map 和空map的区别 

根据官方定义，nil是预定义标识，代表了`指针pointer`、`通道channel`、`函数func`、`接口interface`、`map`、`切片slice`类型变量的零值。

-   只声明一个map类型变量时，为`nil map`
-   此时为**只读map**，无法进行写操作，否则会触发panic
-   `nil map`和`empty map`区别：
    -   `nil map`：只声明未初始化，此时为只读map，不能写入操作，示例：`var m map[t]v`
    -   `empty map`：空map，已初始化，可写入，示例：`m := map[t]v{}`或`m := make(map[string]string, 0)`

### 删除

外层的循环就是在遍历整个 map，删除的核心就在那个`empty`。它修改了当前 key 的标记，而不是直接删除了内存里面的数据。

内存没有释放。清空只是修改了一个标记，底层内存还是被占用了
只有将整个map置为nil时才会被GC `map = nil`
08794
我觉得这样不算是内存泄漏。如果继续给这个`map`写入值，如果这个值命中了之前被删除的bucket，那么会覆盖之前的empty数据。

### 哈希冲突

当两个不同的 key 落在同一个桶中，就是发生了哈希冲突。冲突的解决手段是采用链表法：在 桶 中，从前往后找到第一个空位进行插入。如果8个kv满了，那么当前桶就会连接到下一个溢出桶（bmap）

### 如何有序遍历map

当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。

1. 将 `Map` 中的 key 拿出来，放入 `slice` 中做排序
2. 利用官方库里的 `list(链表)` 封装一个结构体，实现一个有序的 K-V 存储结构，在里面维护一个 keys 的 list。
```go
type OrderedMap struct { 
	//存储 k-v,使用 *list.Element 当做 value 是利用 map O(1) 的性能找到 list 中的 
	element kv map[interface{}]*list.Element 
	//按顺序存储 k-v，保证插入、删除的时间复杂度O(1) 
	ll *list.List
}
```

### 可以对key/value取地址吗？

不可以，因为没必要，扩容会改变

如果通过其他 hack 的方式，例如 unsafe.Pointer 等获取到了 key 或 value 的地址，也不能长期持有，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。

### 注意

-   map的key是无序的，不会通过key保持data的顺序。
-   map中的data不是按插入顺序存储的。
-   每次迭代循环map时，key的输出都是无序的
-   在迭代期间对map进行添加的新元素有可能被输出，也有可能被跳过。
-   在使用make函数初始化map时，指定元素个数，在操作中可以降低内存分配次数，提高性能。
- map是非并发安全的，不能同时对同一个map进行读和写。想满足并发安全的场景，需要通过sync.RWMutex进行加锁同步。
- 可作为map的key的类型必须是能够是用 == 操作符进行可比较的类型。
- 当从map访问一个不存在的键时，他会返回该类型的零值
- 两个map不能判断相等，只能判断深度相等

### 底层

[Golang | 由浅入深理解哈希表Map - 掘金 (juejin.cn)](https://juejin.cn/post/7100271910344196127)

哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。

在go的map实现中，它的底层结构体是hmap，hmap里维护着若干个bucket数组 (即桶数组)。

Bucket数组中每个元素都是bmap结构，也即每个bucket（桶）都是bmap结构，【ps：后文为了语义一致，和方便理解，就不再提bmap了，统一叫作桶】 每个桶中保存了8个kv对，如果8个满了，又来了一个key落在了这个桶里，会使用overflow连接下一个桶(溢出桶)。

![image-202304061953544](attachments/image-202304061953544.png)

```go
type hmap struct {
    count int    // 元素的个数
    flags uint8 // 标识 map 是否被 goroutine 并发读写
    B         uint8  // buckets 数组的长度就是 2^B 个
    overflow uint16 // 溢出桶的数量
    buckets    unsafe.Pointer // 2^B个桶对应的数组指针
    oldbuckets unsafe.Pointer  // 发生扩容时，记录扩容前的buckets数组指针
    nevacuate unsafe.Pointer // 扩容时的进度标识,index 小于 nevacuate 的桶都已经由老桶转移到新桶中
    extra *mapextra //用于保存溢出桶的地址
}
type mapextra struct {
    overflow    *[]*bmap // 供桶数组 buckets 使用的溢出桶
    oldoverflow *[]*bmap // 扩容流程中，供老桶数组 oldBuckets 使用的溢出桶；
    nextOverflow *bmap // 下一个可用的溢出桶.
}
const bucketCnt = 8
type bmap struct { 
// bmap 就是 map 中的桶，可以存储 8 组 key-value 对的数据，以及一个指向下一个溢出桶的指针；
//每组 key-value 对数据包含 key 高 8 位 hash 值 tophash，key 和 val 三部分；
    tophash [bucketCnt]uint8
}
 //在编译期间会产生新的结构体
type bmap struct {
    tophash [8]uint8 //存储哈希值的高8位
    data    byte[1]  //key value数据:key/key/key/.../value/value/value...
    overflow *bmap   //溢出bucket的地址
}
```

#### 核心流程

**写**：

1. 根据 key 取 hash 值；
2. 根据 hash 值对桶数组取模，确定所在的桶；
3. 倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；
4. 沿着桶链表依次遍历各个桶内的 key-value 对；
5. 倘若命中相同的 key，则对 value 中进行更新；
6. 倘若 key 不存在，则插入 key-value 对；
7. 倘若发现 map 达成扩容条件，则会开启扩容模式，并重新返回第2步.

**读**：

1. 根据 key 取 hash 值；
2. 根据 hash 值对桶数组取模，确定所在的桶；
3. 沿着桶链表依次遍历各个桶内的 key-value 对；
4. 命中相同的 key，则返回 value；倘若 key 不存在，则返回零值.

**删**：

1. 根据 key 取 hash 值；
2. 根据 hash 值对桶数组取模，确定所在的桶；
3. 倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；
4. 沿着桶链表依次遍历各个桶内的 key-value 对；
5. 倘若命中相同的 key，删除对应的 key-value 对；并将当前位置的 tophash 置为 emptyOne，表示为空；
6. 倘若当前位置为末位，或者下一个位置的 tophash 为 emptyRest，则沿当前位置向前遍历，将毗邻的 emptyOne 统一更新为 emptyRest.

#### 桶数组

map 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储：

1. 每个桶固定可以存放 8 个 key-value 对；
2. 倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.

#### 解决哈希冲突

在 map 解决 hash /分桶 冲突问题时，实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述：

1. 桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；
2. 每个桶固定可以存放 8 个 key-value 对；
3. 当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；
4. 倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第3步；
5. 倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.

#### 哈希算法

对于哈希算法的选择，程序会根据当前架构判断是否支持AES，如果支持就使用AES hash，其实现代码位于src/runtime/asm_{386,amd64,arm64}.s中；若不支持，其hash算法则根据xxhash算法（[https://code.google.com/p/xxhash/](https://link.zhihu.com/?target=https%3A//code.google.com/p/xxhash/)）和cityhash算法（[https://code.google.com/p/cityhash/](https://link.zhihu.com/?target=https%3A//code.google.com/p/cityhash/)）启发而来，代码分别对应于32位（src/runtime/hash32.go）和64位机器（src/runtime/hash64.go）中，对这部分内容感兴趣的读者可以深入研究。

### map扩容机制 

[[go源码#map#扩容]]

在赋值过程中，会判断是否需要扩容，主要有两个函数：overLoadFactory和tooManyOverflowBuckets

（1）扩容分为增量扩容和等量扩容；
（2）当桶内 key-value 总数/桶数组长度 > 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；
（3）当桶内溢出桶数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶的长度保持为原值；
（4）采用**渐进扩容**的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动.

小结一下：map扩容有两种情况，一==种是map的负载因子超过了6.5，一种是溢出桶（数组）太多了==

扩容方式：

1. 相同容量扩容：因为有添加和删除操作，所以桶中会出现一些空位，这种扩容实际上是进行了元素重排，不会换桶。
2. 2倍容量扩容：由于当前桶数组确实不够用了，发生这种扩容时，元素会重排，可能会发生桶迁移。

扩容迁移规则：只有写操作会触发扩容

（1）在等量扩容中，新桶数组长度与原桶数组相同；
（2）key-value 对在新桶数组和老桶数组的中的索引号保持一致；
（3）在增量扩容中，新桶数组长度为原桶数组的两倍；
（4）把新桶数组中桶号对应于老桶数组的区域称为 x 区域，新扩展的区域称为 y 区域.
（5）实际上，一个 key 属于哪个桶，取决于其 hash 值对桶数组长度取模得到的结果，因此依赖于其低位的 hash 值结果.；
（6）在增量扩容流程中，新桶数组的长度会扩展一位，假定 key 原本从属的桶号为 i，则在新桶数组中从属的桶号只可能是 i （x 区域）或者 i + 老桶数组长度（y 区域）；
（7）当 key 低位 hash 值向左扩展一位的 bit 位为 0，则应该迁往 x 区域的 i 位置；倘若该 bit 位为 1，应该迁往 y 区域对应的 i + 老桶数组长度的位置.

扩容过程：
==类似redis的渐进式rehash==
由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。
当每次触发写、删操作时，会为处于扩容流程中的 map 完成两组桶的数据迁移：

1. 一组桶是当前写、删操作所命中的桶；
2. 另一组桶是，当前未迁移的桶中，索引最小的那个桶.

上面说的 `hashGrow()` 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 `growWork()` 函数中，而调用 `growWork()` 函数的动作是在 mapassign 和 mapdelete 函数中。==也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作==。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。

### 如何保证并发安全？

（1）并发读没有问题；
（2）并发读写中的“写”是广义上的，包含写入、更新、删除等操作；
（3）读的时候发现其他 goroutine 在并发写，抛出 fatal error；
（4）写的时候发现其他 goroutine 在并发写，抛出 fatal error.

需要关注，此处并发读写会引发 fatal error，是一种比 panic 更严重的错误，无法使用 recover 操作捕获.

如果对map进行并发读写会报fatal error，是不能被recover捕获的

使用时加锁或使用sync.Map


倘若发现存在其他 goroutine 在写 map，直接抛出并发读写的 fatal error；其中，并发写标记，位于 hmap.flags 的第 3 个 bit 位；
==在读写前，和读写后都会判断==

```go
// 检测 hmap 中的 flags uint8 // 标识 map 是否被 goroutine 并发读写
const hashWriting  = 4  
if h.flags&hashWriting != 0 {
	fatal("concurrent map read and map write") 
}
```

### sync.Map

底层是两个map , 一个read map 一个dirty map , 一开始读read map ,没有数据则加锁穿透去读dirty map

并且记录一个计数 ,计数满的时候read map被用dirty map进行覆盖

```go
type Map struct { 
	mu sync.Mutex 
	read atomic.Value // readOnly 
	dirty map[interface{}]*entry 
	misses int 
}

type entry struct { 
	p unsafe.Pointer // *interface{} 
}

type readOnly struct { 
	m map[interface{}]*entry 
	amended bool // true if the dirty map contains some key not in m. 
}
```

-   通过 `read` 和 `dirty` 两个字段将读写分离，读的数据存在只读字段 read 上，将最新写入的数据则存在 dirty 字段上
-   读取时会先查询 read，不存在再查询 dirty，写入时则只写入 dirty
-   读取 read 并不需要加锁，而读或写 dirty 都需要加锁
-   另外有 misses 字段来统计 read 被穿透的次数（被穿透只需要读 dirty 的情况），超过一定次数则将 dirty 数据同步到 read 上
-   对于删除数据则直接通过标记来延迟删除

sync.Map 由两个 map 构成：

-   • read map：访问时全程无锁；
-   • dirty map：是兜底的读写 map，访问时需要加锁.
    
之所以这样处理，是希望能根据对读、删、更新、写操作频次的探测，来实时动态地调整操作方式，希望在读、更新、删频次较高时，更多地采用 CAS 的方式无锁化地完成操作；在写操作频次较高时，则直接了当地采用加锁操作完成.

-   • sync.Map 适用于读多、更新多、删多、写少的场景；
-   • 倘若写操作过多，sync.Map 基本等价于互斥锁 + map；
-   • sync.Map 可能存在性能抖动问题，主要发生于在读/删流程 miss 只读 map 次数过多时（触发 missLocked 流程），下一次插入操作的过程当中（dirtyLocked 流程）.

#### 读流程

-   • 查看 read map 中是否存在 key-entry 对，若存在，则直接读取 entry 返回；
-   • 倘若第一轮 read map 查询 miss，且 read map 不全，则需要加锁 double check；
-   • 第二轮 read map 查询仍 miss（加锁后），且 read map 不全，则查询 dirty map 兜底；
-   • 查询操作涉及到与 dirty map 的交互，misses 加一；
-   • 解锁，返回查得的结果.

-   • 在读流程中，倘若未命中 read map，且由于 read map 内容存在缺失需要和 dirty map 交互时，会走进 missLocked 流程；
-   • 在 missLocked 流程中，首先 misses 计数器累加 1；
-   • 倘若 miss 次数小于 dirty map 中存在的 key-entry 对数量，直接返回即可；
-   • 倘若 miss 次数大于等于 dirty map 中存在的 key-entry 对数量，则使用 dirty map 覆盖 read map，并将 read map 的 amended flag 置为 false；
-   • 新的 dirty map 置为 nil，misses 计数器清零.

#### 写流程

（1）倘若 read map 存在拟写入的 key，且 entry 不为 expunged 状态，说明这次操作属于更新而非插入，直接基于 CAS 操作进行 entry 值的更新，并直接返回（存活态或者软删除，直接覆盖更新）；
（2）倘若未命中（1）的分支，则需要加锁 double check；
（3）倘若第二轮检查中发现 read map 或者 dirty map 中存在 key-entry 对，则直接将 entry 更新为新值即可（存活态或者软删除，直接覆盖更新）；
（4）在第（3）步中，如果发现 read map 中该 key-entry 为 expunged 态，需要在 dirty map 先补齐 key-entry 对，再更新 entry 值（从硬删除中恢复，然后覆盖更新）；
（5）倘若 read map 和 dirty map 均不存在，则在 dirty map 中插入新 key-entry 对，并且保证 read map 的 amended flag 为 true.（插入）
（6）第（5）步的分支中，倘若发现 dirty map 未初始化，需要前置执行 dirtyLocked 流程；
（7）解锁返回.

#### 删流程

（1）倘若 read map 中存在 key，则直接基于 cas 操作将其删除；
（2）倘若read map 不存在 key，且 read map 有缺失（amended flag 为 true），则加锁 dou check；
（3）倘若加锁 double check 时，read map 仍不存在 key 且 read map 有缺失，则从 dirty map 中取元素，并且将 key-entry 对从 dirty map 中物理删除；
（4）走入步骤（3），删操作需要和 dirty map 交互，需要走进 3.3 小节介绍的 missLocked 流程；
（5）解锁；
（6）倘若从 read map 或 dirty map 中获取到了 key 对应的 entry，则走入 entry.delete() 方法逻辑删除 entry；
（7）倘若 read map 和 dirty map 中均不存在 key，返回 false 标识删除失败.

## Context

context包定义了Context类型，该类型包含了截止日期、取消信号以及跨API的进程间的其他用户级别范围的变量。

### 作用 

一句话：context 用来解决 goroutine 之间`退出通知`、`元数据传递`的功能。

传递共享数据、取消goroutine、

Go语言中的`context`包提供了一种在程序中传递请求范围内的上下文信息的方式。这个上下文信息可以包括请求相关的元数据、取消信号以及其他请求范围内的数据。
context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。

#### 取消 goroutine（ctx怎么通知子节点取消的） 

`Done()` 返回一个 channel，==标识ctx是否结束==，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个只读的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 `receive-only` 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。

```go
func Perform(ctx context.Context) {
    for {
        calculatePos()
        sendResult()

        select {
        case <-ctx.Done():
            // 被取消，直接返回
            return
        case <-time.After(time.Second):
            // block 1 秒钟 
        }
    }
}
```

### 底层 [[go源码#context]]

```go
type Context interface {
    // 当 context 被取消或者到了 deadline，返回一个被关闭的 channel
    Done() <-chan struct{}

    // 在 channel Done 关闭后，返回 context 取消原因
    Err() error

    // 返回 context 是否会被取消以及自动取消时间（即 deadline）
    Deadline() (deadline time.Time, ok bool)

    // 获取 key 对应的 value
    Value(key interface{}) interface{}
}
```

`Context` 是一个接口，定义了 4 个方法，它们都是`幂等`的。也就是说连续多次调用同一个方法，得到的结果都是相同的。

`Done()` 返回一个 channel，==标识ctx是否结束==，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个只读的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 `receive-only` 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。

`Err()` 返回一个==错误==，表示 context 被关闭的原因。例如是被取消，还是超时。

`Deadline()` 返回 context 的截止时间，==过期时间==，通过此时间，函数就可以决定是否进行接下来的操作，如果时间太短，就可以不往下做了，否则浪费系统资源。当然，也可以用这个 deadline 来设置一个 I/O 操作的超时时间。

`Value()` 获取之前设置的 key 对应的 value。==返回ctx存放的对应key的value==

### context有几种类型 

##### WithCancel

`context.WithCancel(parent Context) (ctx Context, cancel CancelFunc)`
返回派生 context 和取消函数。只有创建它的函数才能调用取消函数来取消此 context。如果您愿意，可以传递取消函数，但是，强烈建议不要这样做。这可能导致取消函数的调用者没有意识到取消 context 的下游影响。

```go
ctx, cancel := context.WithCancel(context.Background())
```

##### WithDeadline

`context.WithDeadline(parent Context, d time.Time) (ctx Context, cancel CancelFunc)`
此函数返回其父项的派生 context，当截止日期超过或取消函数被调用时，该 context 将被取消。例如，您可以创建一个将在以后的某个时间自动取消的 context，并在子函数中传递它。当因为截止日期耗尽而取消该 context 时，获此 context 的所有函数都会收到通知去停止运行并返回。

```go
ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(2 * time.Second))
```

##### WithTimeout

`context.WithTimeout(parent Context, timeout time.Duration) (ctx Context, cancel CancelFunc)`

此函数类似于 context.WithDeadline。不同之处在于它将持续时间作为参数输入而不是时间对象。此函数返回派生 context，如果调用取消函数或超出超时持续时间，则会取消该派生 context。

```go
ctx, cancel := context.WithTimeout(context.Background(), 2 * time.Second)
```

##### WithValue

`context.WithValue(parent Context, key, val interface{}) (ctx Context, cancel CancelFunc)`

此函数接收 context 并返回派生 context，其中值 val 与 key 关联，并通过 context 树与 context 一起传递。这意味着一旦获得带有值的 context，从中派生的任何 context 都会获得此值。

## 闭包

**在函数内部引用了函数内部变量的函数**

==一个函数内引用了外部的局部变量，这种现象，就称之为闭包。==

一般来说，一个函数返回另外一个函数，这个被返回的函数可以引用外层函数的局部变量，这形成了一个闭包。通常，闭包通过一个结构体来实现，它存储一个函数和一个关联的上下文环境。但 Go 语言中，匿名函数就是一个闭包，它可以直接引用外部函数的局部变量

-   **在函数外部访问函数内部变量成为可能**
-   **函数内部变量离开其作用域后始终保持在内存中而不被销毁**

闭包环境中引用的变量是不能够在栈上分配的，而是在**堆上分配**。因为如果引用的变量在栈上分配，那么该变量会跟随函数f返回之后回收，那么闭包函数就不可能访问未分配的一个变量，即未声明的变量，之所以能够再堆上分配，而不是在栈上分配，是Go的一个语言特性----escape analyze（能够自动分析出变量的作用范围，是否将变量分配堆上）。

### 应用场景

1. 数据隔离
2. defer延迟调用与闭包
3. 中间件
   在闭包中，除了动态创建函数，还可以通过参数传递的方式，将函数穿进去，实现闭包。典型应用计算函数执行时间
4. 访问到原本访问不到的数据
5. 二分查找，排序时实现排序函数

### 注意

1. 闭包对自由变量的修改是**引用**的方式。
2. 闭包中，自由变量的生命周期等同于闭包函数的生命周期，和局部环境的周期无关。

```go
type Closure struct{ 
	func()() //匿名函数地址，当然语法要求一定要有变量名，这里只是为了表达匿名的含义 
	i *int //引用的变量地址 
}
```


