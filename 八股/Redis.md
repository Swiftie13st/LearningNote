# Redis

## 介绍下Redis

Redis是一个基于Key-Value存储结构的Nosql开源内存数据库。
它提供了5种常用的数据类型。像String、Map、ZSet、Set、List。那么针对于不同的结构呢，可以解决不同场景的问题。因此，它可以去覆盖应用开发里面的大部分的业务场景。比如说，像top10的问题或者好友关注列表、热点话题等等。
其次，由于Redis本身是一个基于内存的一个存储。并且在数据结构上做了大量的一些优化，所以IO的性能呢比较好。在实际开发里面，我们会把它用在应用和数据库之间的一个分布式缓存中间件。
并且它又是一个非关系数据库的存储。它不存在表之间关联查询的一些问题，所以，它可以很好的去提升应用程序数据IO效率。
最后作为企业级开发来说，它又提供了主从复制+哨兵，以及集群的方式去实现高可用。在redis集群里面，通过hash槽的方式去实现了数据的分片，进一步提升了整体的一个性能和可扩展性。以上就是我的理解。

## 你刚刚说 Redis 支持的数据类型丰富，你都用过哪些数据类型？

常用的数据类型有五种：string，hash，list，set，zset

-  `string`，`set`是最简单也是使用最多的，存储字符串，内部是字符数组。string类型是**二进制安全**的，意思是redis的string可以包含任何数据，比如jpg图片或者序列化的对象。==底层是动态字符串或者（如果是数字）long（int类型8字节）==
-  `list`（列表），`lpush/rpush`list 类似于 Java 中的 LinkedList ，是链表，我们都知道链表的数据结构插入和删除操作非常快，时间复杂度为 O(1)。**可以用作消息队列**，==底层实现方式：quicklist==
- `hash`（字典），`hset`hash 类似于 Java 中的 HashMap，原理几乎是一模一样，当发生 hash 碰撞时就会将碰撞的元素使用链表串接起来，不同的是 Redis 中的 hash 只能存储字符串，所以 Java 代码中如果在 hash 的 value 中传入的是对象，实际上会序列化成字节数组。==底层实现方式：压缩列表ziplist 或者 字典dict==
-  `set`（集合），`sadd`set 相当于 Java 里面的 HashSet，内部的值是无序不重复的。内部实现相当于一个特殊字典，所有的 value 都是一个 NULL 值。Redis还为集合提供了**求交集、并集、差集**等操作，可以非常方便的实现如共同关注、共同喜好、二度好友等功能。==底层实现方式：有序整数集合intset 或者 字典dict==
-  `zset(sortedSet)`（有序集合），`zadd`类似于 Java 中 SortedSet 和 HashMap 的结合，一方面是个 set 保证 value 的唯一，另一方面它给每一个 value 弄了一个权重 score 代表这个 value 的排序权重。zset集合是通过**哈希表实现**的，所以添加O(logn)，删除，查找的复杂度都是 O(1)。==底层实现方式：字典dict + 跳跃表==

其他五种：

- `GEO Geospatial`(地理空间)，主要用于存储地理位置信息，并对存储的信息进行操作，包括添加、获取地理位置的坐标，计算两个位置之间的距离，根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
- `HyperLogLog`（基数统计），用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定且是很小的。但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种==求集合中不重复元素个数==的问题称为基数问题。
- `Bitmap`（位图），由0和1状态表现的二进制位的bit数组，每日签到，广告是否点击过。按年去存储一个用户的签到情况，365 天只需要 365 / 8 ≈ 46 Byte，1000W 用户量一年也只需要 44 MB 就足够了。

- `bitfield`（位域）,通过bitfield命令可==以一次性操作多个比特位域==(指的是连续的多个比特位)
- `Stream`（流5.0），Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。

## Redis为什么速度快

- `内存存储`：Redis是使用内存(in-memeroy)存储，没有磁盘IO上的开销。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)。
- `单线程实现`（ Redis 6.0以前）：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。注意：单线程是指的是在核心网络模型中，网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。
- `非阻塞IO`：Redis使用多路复用IO技术，将epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。多线程的弊端主要在上下文的切换中会影响性能，采用单线程如何实现多个客户端的请求相应，利用的就是非阻塞的IO多路复用机制（epoll），IO多路复用主要有三种分别是select、poll、epoll，性能最好的是epoll。
- `优化的数据结构`：Redis有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能。
- `使用底层模型不同`：Redis直接自己构建了 VM (虚拟内存)机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。Redis的VM(虚拟内存)机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。Redis提高数据库容量的办法有两种：一种是可以将数据分割到多个RedisServer上；另一种是使用虚拟内存把那些不经常访问的数据交换到磁盘上。**需要特别注意的是Redis并没有使用OS提供的Swap，而是自己实现。**

## redis 是单线程，是怎么解决高并发问题的?

1. redis 是基于内存的，内存的读写速度非常快(纯内存); 数据存在内存中，数据结构用 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)。
2. redis是单线程的，省去了很多上下文切换线程的时间(避免线程切换的资源消耗)。
3. redis 使用 I/O 多路复用技术，可以处理高并发的连接(非阻塞I/O)。(如果你懂 I/O 多路复用，可以展开讲一讲，展示你钻研的深度)

## Redis为什么不适用多线程？为什么6.0又引入多线程

**那 Redis6.0 之前为什么不使用多线程？** 

-   单线程编程容易并且更容易维护；
-   Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
-   多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

## 优缺点

### 优点：

- **因为是纯内存操作**，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value 数据库。**读写性能极高**， Redis能读的速度是110000次/s，写的速度是81000次/s。
- **支持数据持久化**，支持AOF和RDB两种持久化方式。
- Redis的所有操作都是**原子性**的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的，多个操作也支持使用Lua脚本。
- **数据结构丰富**，除了支持string类型的value外，还支持hash、set、zset、list等数据结构。
- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。
- 丰富的特性 – Redis还支持 publish/subscribe， 通知， key 过期等特性。

### 缺点：

- 数据库容量受到**物理内存的限制**，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
- **主机宕机，宕机前有部分数据未能及时同步到从机**，切换IP后还会引入数据不一致的问题，降低了系统的可用性。

## Redis的常用场景有哪些?

**1、缓存**
缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升网站访问速度，还能大大降低数据库的压力。Redis提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在Redis用在缓存的场合非常多。
**2、排行榜**
很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。Redis提供的有序集合数据类构能实现各种复杂的排行榜应用。
**3、计数器**
什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。Redis提供的`incr`命令来实现计数器功能，内存操作，性能非常好，非常适用于这些计数场景。分布式id，Redis实现分布式唯一ID主要是通过提供像 `INCR` 和 `INCRBY` 这样的自增原子命令，由于Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的。
**4、分布式会话**
集群模式下，在应用不多的情况下一般使用容器自带的session复制功能就能满足，当应用增多相对复杂的系统中，一般都会搭建以Redis等内存数据库为中心的session服务，session不再由容器管理，而是由session服务及内存数据库管理。
**5、分布式锁**
在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多。
**6、 社交网络**
点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希、集合等数据结构能很方便的的实现这些功能。如在微博中的共同好友，通过Redis的set能够很方便得出。
**7、最新列表**
Redis列表结构，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可用来限制列表的数量，这样列表永远为N个ID，无需查询最新的列表，直接根据ID去到对应的内容页即可。
**8、消息系统**
消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。

## 通信协议 RESP 协议

Redis客户端与服务端通信，使用 RESP 协议通信，该协议是专门为 Redis 设计的通信协议，但也可以用于其它客户端-服务器通信的场景。

RESP 协议有如下几个特点：实现简单；快速解析；可阅读；

客户端发送命令给服务端，服务端拿到命令后进行解析，然后执行对应的逻辑，之后返回给客户端，当然了，这一发一回复都是用的 RESP 协议特点的格式。

## Redis 持久化方式

主要是 RDB(Redis Database) 和 AOF(Append Only File)。

生产当中，一般都需要 RDB 和 AOF `同时开启`，以确保最大程度上的持久化到所有的数据的变更。

### RDB

在指定的`时间间隔`内将内存中的数据集`快照`写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。

Redis会单独创建（fork）一个子进程来进行持久化，会==先将数据写入到 一个临时文件==中，待持久化过程都结束了，再用这个==临时文件替换上次持久化好的文件==。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。**RDB的缺点是最后一次持久化后的数据可能丢失**。

RDB 持久化有两种形式，save 和 bgsave。
`save` 会阻塞主进程，在生成rdb文件期间，redis 服务端不能处理客户端的请求。
`bgsave`会从主线程中fork出一个子进程，进程中保存的是fork子进程时，redis主进程中的所有保存的数据，并以这个时间点的数据进行rdb文件的生成。

#### fork子进程会影响到性能吗？ 

会，`fork`创建子进程，RDB过程由子进程负责，完成后自动结束，阻塞只会发生在fork阶段，一般时间很短

### AOF

以**日志**的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(**读操作不记录**)， **只许追加文件但不可以改写文件**，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作

AOF 的追加，大致可分为三步。第一步，命令追加，redis服务器在接收到命令时，会将这条命令添加到 aof_buf 中。第二步，文件写入，aof_buf 中记录的指令写入到aof文件当中，类似于mysql的日志写入机制。第三步，文件同步，aof文件刷写到磁盘，aof的同步机制有三种，分别为 always(每个时间循环都进行同步)、everysec(每秒都进行同步)、no(交由操作系统进行文件同步)。

对于AOF文件的重写(write off aof)，也会和bgsave一样在fork出的子进程中进行操作。重写时，是以保存时的时间为节点，进行相应命令的重写，如果出现重写开始后有新的数据改变的情况，除了会将改动命令写入到 aof_buf 中，还会将命令写入到重写 aof_buf 中。待子进程重写完毕后，发送通知信号到父进程，由父进程再阻塞式的将重写 aof_buf 中的命令追加到新的 aof 文件中，然后再将老的 aof 文件进行覆盖。

#### 写回策略

-   **always**：同步写回，写指令执行完毕立马将 `aof_buf`缓冲区中的内容刷写到 AOF 文件。
-   **everysec**：每秒写回，写指令执行完，日志只会写到 AOF 文件缓冲区，每隔一秒就把缓冲区内容同步到磁盘。
-   **no：** 操作系统控制，写执行执行完毕，把日志写到 AOF 文件内存缓冲区，由操作系统决定何时刷写到磁盘。

#### 重写机制

其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。

##### 写时复制

Redis中执行bgsave，bgrewriteaof，即在生成数据库快照和重写aof文件时，为了不堵塞主线程，都会采用fork()系统调用创建一个子进程来，此时子进程与父进程共享相同的物理内存数据，防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。

但是子进程重写过程中，主进程依然可以正常处理命令。

如果此时**主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的**。

所以如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险。
还有个问题，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了。
为了解决这种数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。
在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。
在整个 AOF 后台重写过程中，**除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程。**

#### 流程

1. 命令追加（append） ：所有的写命令会追加到 AOF 缓冲区中。  
2. 文件写入（write） ：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用 write 函数（系统调用）， write 将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。  
3. 文件同步（fsync） ：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做  同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步， fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。  
4. 文件重写（rewrite） ：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。  
5. 重启加载（load） ：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。

### 混合持久化

当RDB与AOF两种方式都开启时，Redis会优先使用AOF恢复数据，因为AOF保存的文件比RDB文件更完整。

重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。

Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——**混合持久化**。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。

于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

所以 RDB 内存快照以稍微慢一点的频率执行，在两次 RDB 快照期间使用 AOF 日志记录期间发生的所有「写」操作。

这样快照就不用频繁的执行，同时由于 AOF 只需要记录两次快照之间发生的「写」指令，不需要记录所有的操作，避免出现文件过大的情况。

## 布隆过滤器

==由一个初值为0的bit数组和多个哈希函数构成，用于快速判断集合中是否存在某个元素。==

可以高效的插入和查询，占用空间少，返回的结果是不确定性+不够完美。

一个元素如果判断结果：**存在时元素不一定存在，但是判断结果为不存在时，则一定不存在。**

### 注意

布隆过滤器可以添加元素，但是**不能删除元素**，因为设计哈希函数判断，存在哈希冲突问题，删除元素可能会导致误判率增加。

当实际元素数量超过初始化数量时，应该对布隆过滤器进行重建，重新分配一个size更大的过滤器，在将所有的历史元素批量参加。

### 使用场景

1. 解决缓存穿透问题，和redis结合bitmap使用
2. 黑白名单
3. 安全连接网址，全球上10亿网址判断

## 缓存异常

### 缓存预热

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。
这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

#### 如何做？

1. 上线前手动查询一遍
2. 项目启动时直接初始化加载一遍

### 缓存雪崩

1. redis**主机挂掉**，Redis全盘崩溃，偏硬件运维
2. redis中有**大量key同时过期大面积失效**，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。

#### 解决方案

1. Redis的key设置永不过期或**过期时间**错开。在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。

***如果真的发生了缓存雪崩，有没有什么兜底的措施？***

2. **缓存降级**。使用熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
3. 提高数据库的容灾能力，可以使用分库分表，读写分离的策略。
4. 为了防止Redis宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。（主从+哨兵，集群，开启redis持久化机制aof/rdb，尽快恢复集群）

### 缓存穿透

**一直查询不存在的记录（既不在Redis，也不在Mysql）**
我们使用Redis大部分情况都是通过Key查询对应的值，假如发送的请求传进来的key是不存在Redis中的，那么就查不到缓存，查不到缓存就会去数据库查询。假如有大量这样的请求，这些请求像“穿透”了缓存一样直接打在数据库上，这种现象就叫做缓存穿透。

#### 解决方案

1. 使用**空对象缓存**，或者**缺省值**
   存在问题：空对象也会回写redis，如果大量key不同的请求会使得redis中无用的key越来越多（==记得设置过期时间==）
2. 使用**布隆过滤器**，在redis前加一层布隆过滤器。
   布隆过滤器的作用是某个 key 不存在，那么就一定不存在，它说某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回。

### 缓存击穿

**简单说就是热点key突然失效，导致大量请求到mysql**
其实跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。

#### 解决方案

1.**差异失效时间**，对于访问频繁的热点key，干脆不设置过期时间。一般需要**提前估计热点key**，做到心里有数
2. **互斥更新，采用双检加锁策略**

## Redis事务的三个阶段

1. `multi` 开启事务
2. 大量指令入队
3. `exec`执行事务块内命令，**截止此处一个事务已经结束。**
4. `discard` 取消事务
5. `watch` 监视一个或多个key，如果事务执行前key被改动，事务将打断。unwatch 取消监视。

事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队.

## 主从、哨兵、集群

### 主从复制replica

就是主从复制,master以写为主，Slave以读为主
当master数据变化的时候，自动将新的数据异步同步到其它slave数据库

`配从库不配主库`

#### 作用

- 读写分离
- 容灾恢复
- 数据备份
- 水平扩容支持高并发

#### 基本命令

每此与master断开连接时都要重新连接，除非配置到redis.conf

- `info replication` ：可以查看复制节点的主从关系和配置信息
- `replicao of 主库IP 主库端口`：**主从复制**，一般写入redis.conf配置文件
- `slaveof 主库IP 主库端口`：**改换门庭**，在运行期间修改slave节点信息，可以修改原主库
- `slaveof no one` ：**自立为王**，当前数据库转成主数据库

#### 原理

1. slave启动，同步初清：slave自身数据会被覆盖清除
2. 首次连接，全量复制：master将RDB和所有修改数据库缓存命令发给slave
3. 心跳持续，保持通信：master发出PING包的周期，默认是10秒
4. 进入平稳，增量复制：master将后续收到的命令自动传给slave同步
5. 从机下线，重连续传：Master只会把已经复制的offset后面的数据复制给Slave，类似断点续传

1. **首次连接**
	1. 执行了 replicaof 命令后，从服务器就会给主服务器发送 `psync` 命令，表示要进行数据同步。psync 命令包含两个参数，分别是**主服务器的 runID** 和**复制进度 offset**。
	2. 主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。
	3. 在生成RDB期间与传输期间和从机加载RDB时的命令会写入**replication buffer 缓冲区**，当从机加载完毕会回复确认消息，然后主机会将缓冲区命令发给从机
2. **基于长连接的命令传播**：主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。
3. **增量复制**：网络断开又恢复后，从主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。
	1. 主机维护了repl_backlog_buffer一个**环形缓冲区**用于主从服务器断连后，从中找到差异的数据，以及**replication offset**标记上面那个缓冲区的同步进度
	2. 主服务器使用 master_repl_offset 来记录自己「_写_」到的位置，从服务器使用 slave_repl_offset 来记录自己「_读_」到的位置。
	3. 在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。
	4. 网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：当还在缓冲区时执行增量复制，如果不在就全量复制

#### 缺点

1. 复制延时，信号衰减
2. master挂了需要人工干预

#### 优化

1. 主库只负责写操作，从库负责读操作
2. 如需持久化则主节点不做持久化，从节点做持久化
3. 主从复制在同一局域网下
4. 主从复制不要采用网状结构，通过线性结构薪火相传

#### 薪火相传

主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

-   由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；
-   传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。

**主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器**。

#### 过期key如何处理

主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。

#### 主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？

replication buffer 、repl backlog buffer 区别如下：

-   出现的阶段不一样：
    -   repl backlog buffer 是在增量复制阶段出现，**一个主节点只分配一个 repl backlog buffer**；
    -   replication buffer 是在全量复制阶段和增量复制阶段都会出现，**主节点会给每个新连接的从节点，分配一个 replication buffer**；
-   这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
    -   当 repl backlog buffer 满了，因为是环形结构，会直接**覆盖起始位置数据**;
    -   当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，**重新开始全量复制**。

#### 如何如何应对主从数据不一致

之所以会出现主从数据不一致的现象，是**因为主从节点间的命令复制是异步进行的**，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。

1. 尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。
2. 可以开发一个外部程序来监控主从节点间的复制进度。具体做法：
	1. Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从节点和主节点间的复制进度差值了。
	2. 如果某个从节点的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从节点都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。

### 哨兵sentinel

吹哨人巡查监控后台master主机是否故障，如果故障了根据投票数自动将某一个从库转换为新主库，继续对外服务。**监控、选主、通知**。

1. 监控redis运行状态，包括master和slave
2. 当master down机，能自动将slave切换成新master

#### 哨兵的作用：

1. 主从监控：监控主从redis库运行是否正常
2. 消息通知：哨兵可以将故障转移的结果发送给客户端
3. 故障转移：如果Master异常，则会进行主从切换，将其中一个Slave作为新Master
4. 配置中心：客户端通过连接哨兵来获得当前Redis服务的主节点地址

#### 运行流程

总：当一个主从配置中的master失效之后，哨兵sentinel可以选举出一个新的master田于自动接替原master的工作，主从配置中的其他redis服务器自动指向新的master同步数据般建议sentinel采取奇数台，防止某一台sentinel无法连接到master导致误切换。

##### 1. SDown主观下线（Subjectively Down）

即**单个sentinel认为某个服务下线**（有可能是接收不到订阅，之间的网络不通等等原因）
SDOWN(主观不可用)是单个sentinel自己主观上观测到关于master的状态，从sentinel的角度看，给发送了ping心跳后，在一定时间内没有收到合法的回复，就达到了SDOWN的条件。
sentinel的配置文件中sentinel down-after-milliseconds设置了判断主观下线的时间长度。

##### 2. ODown客观下线（Objectivly Down）

ODOWN需要一定数量的sentinel，**多个哨兵达成一致意见**才能认为一个master客观上挂掉。

**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**

##### 3. 选举出领导者哨兵

当主节点被判断客观下线后，各个哨兵节点会进行协商，先选举出一个**领导者节点**（兵王）并由该领导者节点进行failover（故障迁移）

##### 4. 由领导者哨兵开始推动故障切换流程并选出一个新master

1) 新主登基：某个Slave被选中成为新Master。
   规则：
	   1. 看redis.conf中优先级最高，slave-priority/replica-priority数字小的。
	   2. 复制偏移位置offset最大的节点（偏移量是指获得原主机数据最全的）
	   3. 最小的Run ID节点，字典序
2) 群臣俯首：其他slave成为新master的slave
   1. 执行slaveofno one命令让选出来的从节点成为新的主节点，并通过slaveof命令让其他节点成为其从节点
   2. Sentinelleader会对选举出的新master执行slaveof no one操作，将其提升为master节点
   3. Sentinel leader向其它slave发送命令，让剩余的slave成为新的master节点的slave
3) 旧主拜服：原master恢复也降级成slave
   1. 将之前已下线的老master设置为新选出的新master的从节点，当老master重新上线后，它会成为新master的从节点
   2. Sentinelleader会让原来的master降级为slave并恢复正常工作。

#### 选举原理

监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是`Raft`算法；Raft算法的基本思路**是先到先得**：
即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者

#### 使用建议

1. 哨兵节点的数量应为多 个，哨兵本身应该集群， 保证高可用
2. 哨兵节点的数量应该是奇数
3. 各个哨兵节点的配置应一致
4. 如果哨兵节点部署在Docker等容器里面，尤其要注意端口的正确映射
5. 哨兵集群+主从复制，并不能保证数据零丢失，因此需要集群

### 集群(cluster)

**由于数据量过大**，单个Master复制集难以承担，因此需要对多个复制集进行集群，形成水平扩展**每个复制集只负责存储整个数据集的一部分**，这就是Redis的集群，==其作用是提供在多个Redis节点间共享数据的程序集==。
==Redis集群可以支持多个master。==

Redis集群**不保证强一致性**，这意味着在特定的条件下，Redis集群可能会丢掉一些被系统收到的写入请求命令

#### 作用

1. Redis集群支持多个Master，每个Master又可以挂载多个slave
   1. 读写分离
   2. 支持数据的高可用
   3. 支持海量数据的读写存储操作
2. 由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持，==无需再去使用哨兵功能==
3. 客户端与Redis的节点连接，不再需要连接集群中所有的节点，只需要任意连接集群中的一个可用节点即可
4. 槽位slot负责分配到各个物理服务节点，由对应的集群来负责维护节点、插槽和数据之间的关系

#### 槽位slot

Redis 集群没有使用一致性hash,而是引入了 哈希槽的概念。

Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽,集群的每个节点负责一部分hash槽

#### 分片

使用Redis集群时我们会将存储的数据分散到多台redis机器上，这称为分片。简言之，集群中的每个Redis实例都被认为是整个数据的一个分片。

为了找到给定key的分片，我们对key进行`CRC16(key)`算法处理并通过对总分片数量取模。然后，使用确定性哈希函数，这意味着给定的key将多次始终映射到同一个分片，我们可以推断将来读取特定key的位置。

#### 使用槽位和分片的优势(Redis Cluster 扩容缩容期间可以提供服务吗？Redis Cluster 支持重新分配哈希槽吗？)

**最大优势，方便扩缩容和数据分派查找**

这种结构很容易添加或者删除节点.比如我想新添加个节点D,我需要从节点A,B,C中得部分槽到D上.如果我想移除节点A.需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可.由于从一个节点将哈希槽移动到另一个节点**并不会停止服务**,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.

#### 为什么 Redis Cluster 的哈希槽是 16384 个?

1) 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。

在消息头中最占空间的是myslots\[CLUSTER_SLOTS/8\]。 当槽位为65536时，这块的大小是: 65536÷8÷1024=8kb 

在消息头中最占空间的是myslots\[CLUSTER_SLOTS/8\]。 当槽位为16384时，这块的大小是: 16384÷8÷1024=2kb 

因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。

2) redis的集群主节点数量基本不可能超过1000个。

集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。

3) 槽位越小，节点少的情况下，压缩比高，容易传输

Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。

#### 为什么不用一致性哈希？

一致性哈希算法大大缓解了扩容或者缩容导致的缓存失效问题，只影响本节点负责的那一小段key。如果集群的机器不多，且平时单机的负载水位很高，某个节点**宕机带来的压力很容易引发雪崩效应**。

例如：Redis 集群 总共有4台机器，假设数据分布均衡，每台机器承担 四分之一的流量，如果某一台机器突然挂了，顺时针方向下一台机器将要承担这多出来的 四分之一 流量，最终要承担 二分之一 的流量，还是有点恐怖。

如果采用 CRC16计算后，并结合槽位与实例的绑定关系，无论是扩容还是缩容，只需将相应节点的key做下数据平滑迁移，广播存储新的槽位映射关系，不会产生缓存失效，灵活性很高。

另外，如果服务器节点配置存在差异化，我们可以==自定义分配不同节点负责的 slot 编号，调整不同节点的负载能力==，非常方便。

-   **一致性哈希**的节点分布基于圆环，无法很好的手动设置数据分布，比如有些节点的硬件差，希望少存一点数据，这种很难操作。而哈希槽可以很==灵活的配置每个节点占用哈希槽的数量==
-   一致性哈希的某个节点宕机或者掉线后，当该机器上原本缓存的数据被请求时，会从数据源重新获取数据，并将数据添加到失效机器后面的机器，这个过程被称为 **"缓存抖动"** ，而使用哈希槽的节点宕机，会导致一定范围内的槽不可用，只能通过主从复制加哨兵模式保证高可用。
-   真是基于一致性哈希的特点，当某台机器宕机时，极易引起**雪崩**，如上述介绍中删除节点。
-   **Redis Cluster的槽位空间**是可以用户手动自定义分配的，类似于 windows 盘分区的概念，可以手动控制大小。
-   相对于哈希槽，一致性哈希算法更复杂

#### Redis Cluster 中的节点是怎么进行通信的？

redis cluster节点间采取`gossip协议`进行通信  
gossip协议消息  
gossip协议包含多种消息，包括ping，pong，meet，fail等等。

Redis cluster节点间采取gossip协议进行通信，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更之后U不断地i将元数据发送给其他节点让其他节点进行数据变更。

节点互相之间不断通信，保持整个集群所有节点的数据是完整的。主要交换故障信息、节点的增加和移除、hash slot信息等。

这种机制的好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力;

缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后。

#### 集群中怎么使用Redis+Lua脚本？ 

首先在Redis Cluster环境下，由于key会根据CRC 16算法分配到不同的hash槽中，这就会出现keys之类的可以一次性操作多个key的Redis命令被禁止掉了，所以当lua脚本中包含多个KEYS参数时，也会无法在Redis Cluster环境下运行。

**不过Redis留下了一个小的逻辑口：如果在key中存在 {} ，则会使用第一个 {} 中的值进行CRC运算。那么在key命名时，如果第一个 {} 中的值相同，那么这些key就会被分配进同一个哈希槽中。**

#### 故障恢复

##### 1. PFAIL

当节点1发现与节点3的断连时间超过了node_timeout之后，就会标记节点3为PFAIL，即 Possible failure ，可以中文意为`主观下线`。节点1标记节点3为PFAIL只是说明节点1认为节点3故障了，但并不代表节点3真正的故障了，因为或许是因为节点1和节点3之间的网络出了问题。

##### 2. FAIL

当集群中有超过1/2数目的节点都认为节点3处于PFAIL，那么就判定节点3为FAIL。**同时需要指出的是，节点1把Gossip消息发送给其他节点后，只有同样认为节点3处于PFAIL状态的节点才会去做客观下线状态判定。**由于节点2也判定节点3处于PFAIL，所以节点2进入客观下线的判定。当节点2发现有一半以上（包括自己）的**主节点**都报告节点3处在PFAIL状态时，节点2标记节点3为FAIL状态，并立刻向集群所有节点广播这个信息。

##### 3. 广播信息

一半以上的节点都认为A下线，那么就判定A真正的下线，标记为FAIL。判定结束后，向集群广播节点A下线消息，其他节点都会更新自己维护的节点A的状态信息，标记A为FAIL。

##### 4. 故障迁移

当节点3的的两个`子节点`接收到其主节点的FAIL状态消息时，两个节点就会开始发起故障迁移，竞选成为新的Master节点。两个节点参与竞选之前，首先要检查自身是否有资格参与竞选。

#### 故障迁移过程

##### 资格检查

Slave节点会不停的与Master节点通信来复制Master节点的数据，如果一个Slave节点长时间不与Master节点通信，那么很可能意味着该Slave节点上的数据已经落后Master节点过多（因为Master节点再不停的更新数据但是Slave节点并没有随之更新）。Redis认为，==当一个Slave节点过长时间不与Master节点通信，那么该节点就不具备参与竞选的资格==。

##### 休眠时间计算

当S1和S3都发现自己具备竞选资格时，就开始参与竞选。Redis子节点竞选成为新的Master节点采用了Raft协议。Raft协议选举过程中，所有参与选举的节点首先随机休眠一段时间，每个节点一旦唤醒就立刻向所有的投票节点发起拉票请求。对于投票节点来说，每一轮选举中只能投出一票，投票的规则就是先到先得。所以一般情况下，都是休眠时间最短的节点容易获得大部分投票。

##### 发起拉票&选举投票

我们假设S1先唤醒，S1唤醒后向所有节点发起拉票请求，即向其他节点发送 _CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST_ 类型的消息。**但是我们需要说明的是，虽然所有的节点（主节点+子节点）都会收到拉票请求，但是只有主节点才具备投票资格** 。当其他主节点接收到拉票请求时，如果这一轮投票过程中该主节点没有投出自己的票，那么就会把自己的票投给S1，即向S1回复 _FAILOVER_AUTH_ACK_ 消息。当S1接收到来自其他节点的ACK消息时会统计自己获得的票数，当S1发现自己收到集群中一半以上的主节点的投票时就会开始执行failover，即替换自己的主节点过程。

##### 替换节点

S1替换节点3的过程比较清晰易懂。即首先标记自己为主节点，然后将原来由节点3负责的slots标记为由自己负责，最后向整个集群广播现在自己是Master同时负责旧Master所有slots的信息。其他节点接收到该信息后会更新自己维护的S1的状态并标记S1为主节点，将节点3负责的slots的负责节点设置为S1节点。

##### 易主

节点3故障恢复重新上线后，发现原先本该由自己负责的slot被S1负责了，那么他就知道自己被替代了，会自动成为S1节点的子节点，当S2节点发现原先应该由其Master节点3负责的slot被S1负责了，那么他就知道自己的Master被替代了，就会成为S1的Slave节点。

#### 如果redis集群出现资源倾斜的情况怎么办

数据倾斜：由于业务数据特殊性，按照指定的分片规则，可能导致不同的实例上数据分布不均匀，大量的数据集中到了一台或者几台机器节点上计算，从而导致这些节点负载多大，而其他节点处于空闲等待中，导致最终整体效率低下。

原因：

**bigkey**：
比如存储一个或多个 String 类型的 bigKey 数据，内存占用很大。
解决：拆分

**slot 槽位分配不均**
可以手动做迁移，将一个比较大的 slot 迁移到稍微空闲的机器上，保证存储和访问的均匀性。

#### 缓存热点问题

缓存热点是指大部分甚至所有的业务请求都命中同一份缓存数据，给缓存服务器带来了巨大压力，甚至超过了单机的承载上限，导致服务器宕机。

**复制多份热点数据副本**：
我们可以在key的后面拼上有序编号，比如key#01、key#02。。。key#10多个副本，这些加工后的key位于多个缓存节点上。

客户端每次访问时，只需要在原key的基础上拼接一个分片数上限的随机数，将请求路由不到的实例节点。

注意：缓存一般都会设置过期时间，为了避免缓存的集中失效，我们对缓存的过期时间尽量不要一样，可以在预设的基础上增加一个随机数。

至于数据路由的均匀性，这个由 Hash 算法来保证。

**本地内存缓存**：
把热点数据缓存在客户端的本地内存中，并且设置一个失效时间。对于每次读请求，将首先检查该数据是否存在于本地缓存中，如果存在则直接返回，如果不存在再去访问分布式缓存的服务器。

本地内存缓存彻底“解放”了缓存服务器，不会对缓存服务器有任何压力。

缺点：实时感知最新的缓存数据有点麻烦，会产生数据不一致的情况。我们可以设置一个比较短的过期时间，采用被动更新。当然，也可以用监控机制，如果感知到数据已经发生了变化，及时更新本地缓存。

#### redis集群如何保证数据一致性

1. 主从复制：Redis集群中的每个主节点都会有若干个从节点，主节点会将自己的写操作同步到所有从节点上，从节点再执行相同的写操作，这样可以保证所有节点上的数据都是一致的。
2. 槽分区：Redis集群将数据分成16384个槽，每个槽分配到不同的节点上，这样每个节点只需要处理自己分配到的槽，可以有效避免数据冲突的问题。
3. 写操作同步：当客户端向Redis集群中的某个节点发送写操作时，该节点会先将操作转发给负责相应槽的主节点，主节点再将操作同步到所有从节点上，最后返回客户端执行结果。这样可以保证所有节点上的数据都是一致的。
4. 哨兵机制：Redis集群中的哨兵节点会监控主节点的健康状况，如果主节点故障了，哨兵会自动将某个从节点提升为主节点，这样可以保证集群中始终有可用的主节点。

## 并发

为了保证并发访问的正确性，Redis提供了两种方法，分别是`加锁`和`原子操作`。

### 加锁

加锁是一种常用的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。当一个客户端获得锁后，就会一直持有这把锁，直到客户端完成数据更新，才释放这把锁。

看上去好像是一种很好的方案，但是，其实这里会有两个问题：一个是，如果加锁操作多，会降低系统的并发访问性能；第二个是，Redis客户端要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作

#### 分布式锁

1. 使用setnx上锁，通过del释放锁
2. 锁一直没有释放，设置过期时间，自动释放
3. 上锁之后突然出现异常，无法设置过期时间了
	上锁时候同时设置过期时间即可
1
```sql
set sku:1:info “OK” NX PX 10000
```

- `EX` second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。
- `PX` millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。
- `NX` ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。
- `XX` ：只在键已经存在时，才对键进行设置操作。

##### 注意

setnx获取锁时，设置一个指定的唯一值（例如：uuid）；释放前获取这个值，判断是否自己的锁.

- 不使用`DEL`命令来释放锁，而是发送一个**Lua脚本**，这个脚本只在客户端传入的值和键的口令串相匹配，才对键进行删除。

### 原子操作

**原子操作是另一种提供并发访问控制的方法**。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。

Redis提供了两种原子操作的方法来实现并发控制，分别是`单命令操作`和`Lua脚本`。因为原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。

#### 单命令操作

Redis提供了`INCR/DECR`命令，可以对数据进行**增值/减值**操作，而且它们本身就是单个命令操作，Redis在执行它们时，本身就具有互斥性。

#### Lua脚本

Redis会把整个Lua脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了Lua脚本中操作的原子性。如果我们有多个操作要执行，但是又无法用INCR/DECR这种命令操作来实现，就可以把这些要执行的操作编写到一个Lua脚本中。然后，我们可以使用Redis的EVAL命令来执行脚本。这样一来，这些操作在执行时就具有了互斥性。

## 过期删除策略

1.  **惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。
2.  **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了

### Redis内存淘汰策略

当内存耗尽，则自动触发该机制选取key删除

_注意内存淘汰机制策略或者内存限制的阈值都是可以在Redis配置的，具体命令可以自行查看_

内存淘汰机制策略选取的方式有一下几种：

-   `noeviction`：如果已满则新写入的会报错。**默认策略，不淘汰**
-   `allkeys-lru`：最近最少使用的key移除。**全部LRU**
-   `allkeys-random`：随机移除key。**全部随机**
- `allkeys-lfu`：移除最不经常使用的key。**全部LFU**
-   `volatile-lru`：在设置了过期时间的key中，移除最近最少使用的key。**过期LRU**
-   `volatile-random`：在设置了过期时间的key中，随机移除key。**过期随机**
-   `volatile-ttl`：在设置了过期时间的key中，将最早过期的key移除。**过期最早**
-  `volatile-lfu` ：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰。**过期LFU**

### 过期的数据结构是怎么实现的 

判断是否过期很简单，Redis在dictEntry中存储了上次更新的时间戳，只需要判断当前时间戳和上次更新时间戳之间的gap是否超过设定的过期时间即可。

## Redis为什么不用多线程

1.  普通的kv操作其实瓶颈不在cpu，而在于 _内存及I/O_
2.  redis中有多种数据类型的操作，甚至包括事务，采用 _多线程会因为切换问题而困扰，甚至加锁解锁等都会增加复杂度_
3. Redis6.0后引入了多线程，但是它主要是用于 _处理网络IO_ 方面，对网络事件进行监听，分发给 work thread 进行处理，处理完以后将主动权交还给 ==主线程，进行 执行操作==

>Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。

### 6.0引入多线程

业务量大后需要更大的QPS，所以Redis6.0后引入了多线程，但是它主要是用于 _处理网络IO_ 方面，对网络事件进行监听，分发给 work thread 进行处理，处理完以后将主动权交还给 ==主线程，进行 执行操作==

### redis真的是单线程吗？

1. redis6.0针对网络IO引入了多线程
2. redis会fork子进程bgsave去写入rdb
3. aof的刷盘同步fsync线程
4. fork一个bgrewriteaof子进程进行aof重写
5. lazyfree机制，而lazy free的本质就是把某些cost(主要时间复制度，占用主线程cpu时间片)较高删除操作，从redis主线程剥离让bio子线程来处理，极大地减少主线阻塞时间。从而减少删除导致性能和稳定性问题。原理是在删除的时候只进行逻辑删除，把key释放操作放在bio(Background I/O)单独的子线程处理中，减少删除大key对redis主线程的阻塞。
6. 处理关闭文件描述符的后台线程
7. 集群数据同步

## redis事务

Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

Redis事务的主要作用就是**串联多个命令**防止别的命令插队。

从输入`multi`命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入`exec`后，Redis会将之前的命令队列中的命令依次执行。

**不保证原子性**：事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚
**隔离性**：redis是单线程，事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

### watch & unwatch

在执行multi之前，先使用`watch key1 [key2]`可以监视一个(或多个) key ，如果在事务**执行之前这个(或这些) key被其他命令所改动，那么事务将被打断。

这个命令就是 watch，该命令可以为 Redis 事务提供 check-and-set （CAS）行为。
我们可以使用 watch 命令来监视一个或多个 key，如果被监视的 key 在事务执行前被修改过那么本次事务将会被取消，也就是所谓的回滚。
只有确保被监视的 key，在事务开始前到执行 这段时间内未被修改过事务才会执行成功（类似乐观锁）
如果一次事务中存在被监视的 key，无论此次事务执行成功与否，该 key 的监视都将会在执行后失效 也就是说监视是一次性的。

## 底层数据结构

### sds

 sds 数据结构主要由 len、alloc、buf\[] 三个属性组成，其中 buf\[] 为实际保存字符串的 char 类型数组；len 表示 buf\[] 数组所保存的字符串的长度，alloc表示字符串的最大容量。由于使用 len 记录了保存的字符串长度，所以在获取字符串长度的时候，不需要从前往后遍历数组，直接获取 len 的值就可以了

1. 可动态扩展内存。sds表示的字符串其内容可以修改，也可以追加。
2. 采用预分配冗余空间的方式来减少内存的频繁分配，从而优化字符串的增长操作
3. 二进制安全（Binary Safe）。sds能存储任意二进制数据，而不仅仅是可打印字符。
4. 与传统的C语言字符串类型兼容。

**扩容**：

1. 判断sds预留空闲空间是否大于addlen，大于addlen，则直接返回就行了，不需要扩容
2. 计算新sds的占用空间大小 ,如果sds.len+addlen小于1M的话，则进行（sds.len+addlen)\*2的扩容
3. 如果sds.len+addlen 大于1M的话，每次扩容加1M
4. 根据新长度计算新sds的类型
5. 如果新sds类型与旧sds类型一致，则进行s_realloc动态扩容
6. 如果新sds类型与旧sds类型不一致，则需要申请全新的空间进行sds重构，并释放掉原来的sds内存空间
7. 最后返回sds

### dict

哈希表，采用拉链法解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存

### ziplist

 ziplist是一个经过特殊编码的双向链表，可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以O(1)的时间复杂度在表的两端提供`push`和`pop`操作。ziplist使用一块**连续的内存空间来存储数据**，并采用可变长的编码方式，支持不同类型和大小的数据的存储，更加节省内存，而且数据存储在一片连续的内存空间，读取的效率也非常高。

### quicklist

quicklist是一个基于ziplist的双向链表，quicklist的每个节点都是一个ziplist。quicklist 实际上是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。

### intset

intset是一个由整数组成的有序集合，从而便于进行二分查找，用于快速地判断一个元素是否属于这个集合。它在内存分配上与ziplist有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。

### skiplist

跳表是一种可以进行二分查找的有序链表，采用空间换时间的设计思路，跳表在原有的有序链表上面增加了多级索引（例如每两个节点就提取一个节点到上一级），通过索引来实现快速查找。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都为O(logn)，空间复杂度为 O(n)。跳表非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

#### redis最多建几层跳表

Redis 跳跃表默认允许最大的层数是 **32**，被源码中 ZSKIPLIST_MAXLEVEL 定义，当 Level[0] 有 2^64 个元素时，才能达到 32 层，所以定义 **32 完全够用了**

## 查看生命周期 

查看： `ttl key`
设置： `expire key time`
设置永不过期：`persist key`

ttl命令查出来的key生命周期，如果返回值为-1则表示永不过期，返回值为-2则表示键过期，不存在

## Hash的扩容，渐进式rehash 

hash的底层是哈希表，采用拉链法解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存

**redis字典（hash表）当数据越来越多的时候，就会发生扩容，也就是rehash**

在扩容和收缩的时候，如果哈希字典中有很多元素，一次性将这些键全部rehash到`ht[1]`的话，可能会导致服务器在一段时间内停止服务。所以，采用渐进式rehash的方式，详细步骤如下：

1.  为`ht[1]`分配空间，让字典同时持有`ht[0]`和`ht[1]`两个哈希表
   扩容：那么ht[1] 的大小为第一个大于等于`ht[0] .used*2`的`2的n次幂`
   缩容：那么ht[1] 的大小为第一个大于等于`ht[0].used `的`2的n次幂`
2.  将`rehashindex`的值设置为`0`，表示rehash工作正式开始
3.  在rehash期间，每次对字典执行增删改查操作是，程序除了执行指定的操作以外，还会顺带将`ht[0]`哈希表在`rehashindex`索引上的所有键值对rehash到`ht[1]`，当rehash工作完成以后，`rehashindex`的值`+1`
4.  随着字典操作的不断执行，最终会在某一时间段上`ht[0]`的所有键值对都会被rehash到`ht[1]`，这时将`rehashindex`的值设置为`-1`，表示rehash操作结束
5. 将`ht[0]`释放，然后将`ht[1]`设置成`ht[0]`，最后为`ht[1]`分配空白哈希表。

**渐进式rehash采用的是一种分而治之的方式，将rehash的操作分摊在每一个的访问中，避免集中式rehash而带来的庞大计算量。**

### 扩容条件

1)Redis服务器目前没有在执行BGSAVE或BGREWRITEAOF命令，并且哈希表的负载因子大于等于1。

2)Redis服务器目前在执行BGSAVE或BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。

缩容的条件：哈希表的负载因子小于0.1。

负载因子的计算公式：哈希表已保存节点数量 / 哈希表大小 `load_factor = ht[0].used / ht[0].size`

### 在迁移的过程中，会不会造成读少数据?

不会，因为在迁移时，首先会从`ht[0]`读取数据，如果`ht[0]`读不到，则会去`ht[1]`读。

### 在迁移过程中，新增加的数据会存放在哪个ht?

迁移过程中，新增的数据只会存在`ht[1]`中，而不会存放到`ht[0]`，`ht[0]`只会减少不会新增。

### 操作

1. 操作辅助rehash：在redis中每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式rehash，如果是则帮助执行一次。

2. 定时辅助rehash：虽然redis实现了在读写操作时，辅助服务器进行渐进式rehash操作，但是如果服务器比较空闲，redis数据库将很长时间内都一直使用两个哈希表。所以在redis周期函数中，如果发现有字典正在进行渐进式rehash操作，则会花费**1毫秒**的时间，帮助一起进行渐进式rehash操作。

## keys命令存在的问题？

`keys *`查看当前库所有key    (匹配：`keys *1`)

redis的单线程的。keys指令会导致线程阻塞一段时间，直到执行完毕，服务才能恢复。

### scan

```sh
SCAN cursor [MATCH pattern] [COUNT count]
```

SCAN 命令是一个基于游标的迭代器。SCAN 命令每次被调用之后， 都会向用户返回一个新的游标，用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。
scan采用渐进式遍历的方式来解决keys命令可能带来的阻塞问题，每次scan命令的时间复杂度是O(1)，但是要真正实现keys的功能，需要执行多次scan。

**scan的缺点**：在scan的过程中如果有键的变化（增加、删除、修改），遍历过程可能会有以下问题：新增的键可能没有遍历到，遍历出了重复的键等情况，也就是说scan并不能保证完整的遍历出来所有的键。

## bigkey

Bigkey 是指当 Redis 的字符串类型过大，非字符串类型元素过多。

字符串类型：单个Value过大，一般认为超过10kb就为bigkey
其他类型：哈希、列表、集合等体现在元素的个数过多

### 危害

1. Redis 阻塞 ：因为 Redis 单线程特性，如果操作某个 Bigkey 耗时比较久，则后面的请求会被阻塞。
2. 内存空间不均匀 ：比如在 Redis cluster 或者 codis 中，会造成节点的内存使用不均匀。
3. 过期时可能阻塞 ：如果 Bigkey 设置了过期时间，当过期后，这个 key 会被删除，假如没有使用 Redis 4.0 的过期异步删除，就会存在阻塞 Redis 的可能性，并且慢查询中查不到（因为这个删除是内部循环事件）。
4. 导致倾斜：某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。实例的处理压力就会增大，速度变慢，甚至还可能会引起这个实例的内存资源耗尽，从而崩溃。

### 排查

```sh
redis-cli --bigkeys
```

 Redis 可以**在执行redis-cli 命令时带上–bigkeys 选项，进而对整个数据库中的键值对大小情况进行统计分析**，比如说，统计每种数据类型的键值对个数以及平均大小。

### 处理

1. 删除 bigkey：将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。Redis 4.0及之后版本：您可以通过`UNLINK`命令安全地删除大Key甚至特大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。
   不过，异步删除操作是 Redis 4.0 以后才有的功能，如果你使用的是 4.0 之前的版本，当你遇到 bigkey 删除时，我给你个小建议：先使用集合类型提供的 `SCAN` 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。例如，对于 Hash 类型的 bigkey 删除，你可以使用 HSCAN 命令，每次从 Hash 集合中获取一部分键值对（例如 200 个），再使用 HDEL 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了
2. 拆分：有时也可以考虑对 Bigkey 进行拆分，具体方法如下：对于 string 类型的 Bigkey，可以考虑拆分成多个 key-value。对于 hash 或者 list 类型，可以考虑拆分成多个 hash 或者 list。
3. 不用 Redis:Redis 对于长文本不是最优的，可考虑文档型数据库如：MongoDB 等

## Hotkey 

### 问题

- 占用大量的CPU资源，影响其他请求并导致整体性能降低。
- 集群架构下，产生访问倾斜，即某个数据分片被大量访问，而其他数据分片处于空闲状态，可能引起该数据分片的连接数被耗尽，新的连接建立请求被拒绝等问题。
- 在抢购或秒杀场景下，可能因商品对应库存Key的请求量过大，超出Redis处理能力造成超卖。
- 热Key的请求压力数量超出Redis的承受能力易造成缓存击穿，即大量请求将被直接指向后端的存储层，导致存储访问量激增甚至宕机，从而影响其他业务。

### 检测

[如何快速定位 Redis 热 key? - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/127128142)

1. **客户端收集上报**  
    改动 Redis SDK，记录每个请求，定时把收集到的数据上报，然后由一个统一的服务进行聚合计算。方案直观简单，但没法适应多语言架构，一方面多语言 SDK 对齐是个问题，另外一方面后期 SDK 的维护升级会面临比较大的困难，成本很高。
2. **代理层收集上报**  
    如果所有的 Redis 请求都经过代理的话，可以考虑改动 Proxy 代码进行收集，思路与客户端基本类似。该方案对使用方完全透明，能够解决客户端 SDK 的语言异构和版本升级问题，不过开发成本会比客户端高些。
3. **Redis 节点抓包解析**  
    在可能存在热 key 的节点上(流量倾斜判断)，通过 tcpdump 抓取一段时间内的流量并上报，然后由一个外部的程序进行解析、聚合和计算。该方案无需侵入现有的 SDK 或者 Proxy 中间件，开发维护成本可控，但也存在缺点的，具体是热 key 节点的网络流量和系统负载已经比较高了，抓包可能会情况进一步恶化。
4. **凭借业务经验，进行预估哪些是热key**
   比如某商品在做秒杀，那这个商品的key就可以判断出是热key。
5. **通过redis-cli的hotkeys**
   自Redis 4.0版本起提供了hotkeys参数，可以快速帮您找出业务中的热Key

### 解决

1. **利用二级缓存**
	比如利用`ehcache`，或者一个`HashMap`都可以。在你发现热key以后，把热key加载到系统的JVM中。  针对这种热key请求，会直接从jvm中取，而不会走到redis层。  假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。  
	有赞在监控到热key后，Hermes服务端集群会通过各种手段通知各业务系统里的Hermes-SDK，告诉他们:"老弟，这个key是热key，记得做本地缓存。"  于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现这个是一个热key，直接从本地中拿，而不会去访问集群。
2. **备份热key**
	这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。  
	在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。
3. **使用读写分离架构**
   如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。
   读写分离架构同样存在缺点，在请求量极大的场景下，读写分离架构会产生不可避免的延迟，此时会有读取到脏数据的问题。因此，在读、写压力都较大且对数据一致性要求很高的场景下，读写分离架构并不是最优方案。

## 线程模型 

在 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型：利用 epoll/select/kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端：

6.0之后：这种模式不再是单线程的事件循环，而是有多个线程（IO Thread）各自维护一个独立的事件循环。整体模型是由 Main 线程负责接收新连接，并分发给 IO Thread 去独立处理（解析请求命令），但是具体命令的执行还是使用main 线程来执行，最后使用IO 线程回写响应给客户端。

IO线程轮训socket列表读事件，然后解析为redis命令，并把解析好的命令放到全局待执行队列，然后主线程从全局待执行队列读取命令然后具体执行命令，最后把响应结果分配到不同IO线程，由IO线程来具体执行把响应结果写回客户端。

也就是具体命令执行还是由main线程所在的事件循环单线程处理，只是读写socket事件由IO线程来处理。

redis基于reactor模型，开发了文件事件处理器，它的组成包括四部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器是单线程的，所以redis是单线程模型。文件事件处理器使用IO多路复用程序来监听多个套接字，并根据套接字目前执行的任务去关联不同的事件处理器

## redis和其他的对比，为什么选择redis

目前分布式存储使用比较多的`memcached`和`redis`，而且使用redis越来越广泛了

1.  _redis支持的数据类型更丰富_，memcached只支持简单的k/v，而redis还支持list、set、zset、hash等
2.  _redis支持持久化_，也就是支持将内存数据保存到磁盘中，保证了数据的安全，memcached就不可以
3.  redis因为有持久化就可以 _实现灾难恢复_
4.  redis是 _支持cluster模式的_，memcached需要自己实现
5.  Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用 _单线程的多路 IO 复用模型_（Redis 6.0 引入了多线程 IO ）
6.  redis提供更丰富的附加功能：_发布订阅模型、Lua脚本、事务_ 等
7.  redis过期数据的删除策略有 _惰性删除和定期删除_，而Memcached 只有惰性删除

redis在遇到内存使用完成之后利用淘汰机制，将数据放到磁盘中，memcached则直接就抛异常了

## Redis内存优化

1.  利用 jemalloc 特性进行优化
    -   由于 jemalloc 分配内存时数值是不连续的，因此 key/value 字符串变化一个字节，可能会引起占用内存很大的变动（比如两个 SDS 分别占据 32/33Bytes，实际占用值是 32/64Bytes）；在设计时可以利用这一点。
        -   例如，如果 Key 的长度如果是 8 个字节，则 SDS 为 17 字节，jemalloc 分配 32 字节；此时将 key 长度缩减为 7 个字节，则 SDS 为 16 字节，jemalloc 分配 16 字节；则每个key所占用的空间都可以缩小一半。
    -   使用整型/长整型：如果是整型/长整型，Redis 会使用 int 类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。
2.  共享对象
    -   利用共享对象，可以减少对象的创建（同时减少了 redisObject 的创建），节省内存空间。
    -   目前 Redis 中的共享对象只包括 10000 个整数（0-9999）；可以通过调整 REDIS_SHARED_INTEGERS 参数提高共享对象的个数；例如将 REDIS_SHARED_INTEGERS 调整到 20000，则 0-19999 之间的对象都可以共享。
        -   例：论坛网站在 redis 中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在 0-20000 之间，这时候通过适当增大 REDIS_SHARED_INTEGERS 参数，便可以利用共享对象节省内存空间。
3.  避免过度设计
    -   需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；例如如果只有 90000 个键值对，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。
4.  关注内存碎片率
    -   内存碎片率是一个重要的参数，对 Redis 内存的优化有重要意义。定义如下：
    -   `mem_fragmentation_ratio = used_memory_rs / used_memory`，即 Redis 进程占据内存大小，与 Redis 分配器分配内存大小的比值；
    -   内存碎片率越高（ 在 1.03 左右比较正常），说明内存碎片越多，内存浪费越严重；这时便可以考虑重启 redis 服务，在内存中对数据进行重排，减少内存碎片。
    -   如果内存碎片率小于 1，说明 redis 内存不足，部分数据使用了**虚拟内存**（即 swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时 redis 的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加[服务器](https://cloud.tencent.com/product/cvm?from=20065&from_column=20065)节点数量，或提高单机内存），或减少 redis 中的数据。
5.  回收策略
    -   设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。

### redis对int类型做了那些优化？

如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型

## 如何通过redis实现异步的消息队列

https://mp.weixin.qq.com/s/MSmipbE5cyK2_m5iiKv7pw

list：LPUSH + RPOP/BRPOP

|**mq 实现方案**|**发布/订阅能力**|**消费端ACK机制**|**消息缓存能力**|**数据丢失风险**|
|---|---|---|---|---|
|list|不支持|不支持|支持|低|
|pub/sub|支持|不支持|不支持|高|
|streams|支持|支持|支持|低|

- redis list：最简单粗暴的实现，存在问题包括：不支持发布/订阅模式、消费端缺少 ack 机制
- redis pub/sub：支持发布/订阅模式，有较高的丢数据风险，消费端同样不支持 ack 机制
- redis streams：趋近于成熟的 mq 实现方式. 支持发布/订阅模式，消费端能支持 ack 机制. 但是受限于 redis 自身的特性，仍无法杜绝丢失数据的可能性

##  redis网络传输报文格式是什么？ 

Redis客户端和服务端交互是通过tcp协议，在通讯的报文格式使用的是RESP协议规范，也就是意味只要和Redis服务端建立Scoket连接，通过RESP报文格式传输数据就可以实现Redis客户端和服务端的交互。看起来是很简单的，但是实际上的确是这么简单，RESP报文格式的可读性也是很高的。

RESP是Redis通讯的协议规范，有以下几种特点：

- 简单的实现，人工也就可以写的出来
- 快速的被计算机解析
- 简单的可以被人工解析
- 基于网络层，Redis在tcp端口6379（默认）上监听到来的连接（本质是Socket），客户端连接到来时，Redis服务器为此建立一个tcp连接。

RESP中涉及到主要的两个符号，分别是`*`和`$`，其中`*`表示此报文里面有几个`$`符，准确的说是几组。`$`表示本组数据所占的字符数。

```sh
*3
$3
SET
$3
key
$5
joker
```

- 报文总共有三组`$`数据组成，所以开头的`*`标明的值是3
- 第一组数据是`SET`，占用3个字符，所以`$`标明的值为3，下面的两组以此类推

为了可阅读性上面写成是一列，但是实际上他们是组成一个字符串发送，需要注意的是，每一行都是独立的一行，需要在字符串中加入`\r\n`换行才行，压缩后如下：

```shell
*3\r\n$3\r\nSET\r\n$3\r\nkey\r\n$5\r\njoker\r\n
```

注意压缩成字符串后末尾也是需要`\r\n`的。（Redis的AOF持久化文件中也是这样保存的）

###  有几种报文格式？ 

Redis的[通信协议](https://so.csdn.net/so/search?q=%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE&spm=1001.2101.3001.7020)全称是 REdis Serialization Protocol(RESP)  
它有5种通信格式
#### 正常回复

以"`+`“开头， 以”`\r\n`"结尾的字符串形式  

```resp
+OK\r\n
```
#### 错误回复

以"`-`“开头， 以”`\r\n`"结尾的字符串形式  

```resp
-Error message\r\n
```

##### 整数

以"`:`“开头， 以”`\r\n`"结尾的字符串形式  

```resp
:123456\r\n
```

##### 多行字符串

以"`$`“开头，后跟实际发送字节数， 以”`\r\n`"结尾的字符串形式  

```resp
// “test”  
$4\r\n`test`\r\n
// 空字符串  
$0\r\n\r\n
// 或者需要换行符"test1\r\ntest2"  
$14\r\ntest1\r\ntest2\r\n
```


## 底层

### string

字符串对象的值实际可以是字符串、数字、甚至是二进制，最大不能超过512MB 

字符串对象的编码可以是int，raw或者embstr。
**int 编码是用来保存整数值，raw编码是用来保存长字符串，而embstr是用来保存短字符串**

1. int 编码：保存的是可以用 long 类型表示的整数值。如果一个字符串对象保存的是整数值,并且这个整数值可以用`long`类型来表示,那么字符串对象会将整数值保存在字符串对象结构的`ptr`属性里面(将`void*`转换成`1ong`),并将字符串对象的编码设置为`int`。
2. raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。如果字符串对象保存的是一个字符串值,并且这个字符串值的长度大于32字节,那么字符串对象将使用一个简单动态字符串(SDS)来保存这个字符串值,并将对象的编码设置为`raw`。
3. embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）如果字符串对象保存的是一个字符串值,并且这个字符申值的长度小于等于32字节，那么字符串对象将使用一个简单动态字符串(SDS)来保存这个字符串值，并将对象的编码设置为`embstr`

当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw。对于 embstr 编码，由于 Redis 没有对其编写任何的修改程序（embstr 是只读的），在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节。

![Pasted image 20230918000826](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701437.png)

embstr与raw都使用redisObject和sds保存数1据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。

因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。

而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读


#### 命令

|命令|`int` 编码的实现方法|`embstr` 编码的实现方法|`raw` 编码的实现方法|
|---|---|---|---|
|SET|使用 `int` 编码保存值。|使用 `embstr` 编码保存值。|使用 `raw` 编码保存值。|
|GET|拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 然后向客户端返回这个字符串值。|直接向客户端返回字符串值。|直接向客户端返回字符串值。|
|APPEND|将对象转换成 `raw` 编码， 然后按`raw` 编码的方式执行此操作。|将对象转换成 `raw` 编码， 然后按`raw` 编码的方式执行此操作。|调用 `sdscatlen` 函数， 将给定字符串追加到现有字符串的末尾。|
|INCRBYFLOAT|取出整数值并将其转换成 `longdouble` 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。|取出字符串值并尝试将其转换成`long double` 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。 如果字符串值不能被转换成浮点数， 那么向客户端返回一个错误。|取出字符串值并尝试将其转换成 `longdouble` 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。 如果字符串值不能被转换成浮点数， 那么向客户端返回一个错误。|
|INCRBY|对整数值进行加法计算， 得出的计算结果会作为整数被保存起来。|`embstr` 编码不能执行此命令， 向客户端返回一个错误。|`raw` 编码不能执行此命令， 向客户端返回一个错误。|
|DECRBY|对整数值进行减法计算， 得出的计算结果会作为整数被保存起来。|`embstr` 编码不能执行此命令， 向客户端返回一个错误。|`raw` 编码不能执行此命令， 向客户端返回一个错误。|
|STRLEN|拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 计算并返回这个字符串值的长度。|调用 `sdslen` 函数， 返回字符串的长度。|调用 `sdslen` 函数， 返回字符串的长度。|
|SETRANGE|将对象转换成 `raw` 编码， 然后按`raw` 编码的方式执行此命令。|将对象转换成 `raw` 编码， 然后按`raw` 编码的方式执行此命令。|将字符串特定索引上的值设置为给定的字符。|
|GETRANGE|拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 然后取出并返回字符串指定索引上的字符。|直接取出并返回字符串指定索引上的字符。|直接取出并返回字符串指定索引上的字符。|
### list

列表（list）类型是用来存储多个有序的字符串，列表中的每个字符串称为元素(element)，一个列表最多可以存储232-1个元素。
在Redis中，可以对列表两端插入（push）和弹出（pop），还可以获取指定范围的元素列表、获取指定索引下标的元素等。

列表是一种比较灵活的数据结构，它可以充当栈和队列的角色，在实际开发上有很多应用场景。

列表类型有两个特点：

1. 列表中的元素是==有序的==，这就意味着可以通过索引下标获取某个元素或者某个范围内的元素列表。
2. 列表中的元素==可以是重复的==.

底层：

- `ziplist（压缩列表）`：当列表的元素个数小于list-max-ziplist-entries配置（默认512个），同时列表中每个元素的值都小于list-max-ziplist-value配置时（默认64字节），Redis会选用ziplist来作为列表的内部实现来减少内存的使用。
- `linkedlist（双端链表）`：当列表类型无法满足ziplist的条件时，Redis会使用linkedlist作为列表的内部实现。

当同时满足下面两个条件时，使用ziplist（压缩列表）编码：

1. 列表保存元素个数小于512个
2. 每个元素长度小于64字节

不能满足这两个条件的时候使用 linkedlist 编码
而在Redis3.2版本开始对列表数据结构进行了改造，==使用 quicklist 代替了 ziplist 和 linkedlist.==

#### ziplist :

它有点儿类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它==允许存储的数据大小不同==。

![Pasted image 20230918001138](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701438.png)

`zlbytes`：记录整个压缩列表占用的内存字节数。1unit32_t-4byte  
`zltail`：记录压缩列表表尾节点距离压缩列表起始地址有多少字节。unit32_t-4byte  
`zllen`：记录了压缩列表包含的节点数量。值小于unit16_max(65535)时，表示包含节点数量，等于时，需要遍历整个压缩列表才能计算得出 unit16_t-2byte  
`entryN`：压缩列表的节点，节点长度由节点保存的内容决定。  
`zlend`：特殊值0xFF（十进制255），用于标记压缩列表的末端。 unit8_t-1byte

entryN-压缩列表节点结构:
![Pasted image 20230918001150](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701439.png)

```cpp
typedef struct zlentry {
    unsigned int prevrawlensize;     //previous_entry_length字段长度
    unsigned int prevrawlen;         //previous_entry_length字段存储的内容
    unsigned int lensize;            //encod1ing字段的长度
    unsigned char encoding;          //数据类型
    unsigned int len;                //数据内容长度
    unsigned int headersize;         //当前元素的首部长度 = previous_entry_length字段长度与encoding字段长度之和
    unsigned char *p;                //当前元素首地址   
} zlentry;
```

- `previous_entry_length`：记录压缩列表中前一个节点的长度。previous_entry_length属性的长度可以是1字节或者5字节：如果前一节点的长度小于 254 字节，那么previous_entry_length属性的长度为1字节，前一节点的长度就保存在这一个字节里面。如果前一节点的长度大于等于254字节，那么previous_entry_length属性的长度为5字节，其中属性的第一字节会被设置为0xFE（十进制值 254），而之后的四个字节则用于保存前一节点的长度。因为节点的previous_entry_length属性记录了前一个节点的长度，所以程序可以通过指针运算，根据当前节点的起始地址来计算出前一个节点的起始地址，缩列表的从表尾向表头遍历操作就是使用这一原理实现的。
- `encoding`：记录节点的contents属性所保存数据的类型以及长度。分两种情况：
	- 一字节、两字节或者五字节长，值的最高位为00 、01或者10的是字节数组编码，这种编码表示节点的content属性保存着字节数组，数组的长度由编码除去最高两位之后的其他位记录；
	- 一字节长，值的最高位以11开头的是整数编码，这种编码表示节点的content属性保存着整数值，整数值的类型和长度由编码除去最高两位之后的其他位记录。
- `contents`：保存节点的值，可以是一个字节数组或整数，类型和长度由节点的'encoding'属性决定。


#### linklist :

![Pasted image 20230918001202](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701440.png)

![Pasted image 20230918001211](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701441.png)

```cpp
typedef struct list {
    listNode *head;  // 表头指针
    listNode *tail;     // 表尾指针 
    unsigned long len;   // 节点数量
    void *(*dup)(void *ptr);  // 复制函数
    void (*free)(void *ptr);  // 释放函数
    int (*match)(void *ptr, void *key);  // 比对函数
} list;

typedef struct listNode {
    struct listNode *prev;  // 前驱节点
    struct listNode *next;   // 后继节点 
    void *value;  // 值
} listNode;
```

#### 快速列表quicklist

quicklist 实际上是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。
![Pasted image 20230918001225](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701442.png)
#### 命令

|命令|说明|时间复杂度|
|---|---|---|
|BLPOP key \[key ...\] timeout|删除，并获得该列表中的第一元素，或阻塞，直到有一个可用|O(1)|
|BRPOP key \[key ...\] timeout|删除，并获得该列表中的最后一个元素，或阻塞，直到有一个可用|O(1)|
|BRPOPLPUSH source destination timeout|弹出一个列表的值，将它推到另一个列表，并返回它;或阻塞，直到有一个可用|O(1)|
|LINDEX key index|获取一个元素，通过其索引列表|O(N)|
|LINSERT key BEFORE|AFTER pivot value在列表中的另一个元素之前或之后插入一个元素|O(N)|
|LLEN key|获得队列(List)的长度|O(1)|
|LPOP key|从队列的左边出队一个元素|O(1)|
|LPUSH key value \[value ...\]|从队列的左边入队一个或多个元素|O(1)|
|LPUSHX key value|当队列存在时，从队到左边入队一个元素|O(1)|
|LRANGE key start stop|从列表中获取指定返回的元素|O(S+N)|
|LREM key count value|从列表中删除元素|O(N)|
|LSET key index value|设置队列里面一个元素的值|O(N)|
|LTRIM key start stop|修剪到指定范围内的清单|O(N)|
|RPOP key|从队列的右边出队一个元|O(1)|
|RPOPLPUSH source destination|删除列表中的最后一个元素，将其追加到另一个列表|O(1)|
|RPUSH key value \[value ...\]|从队列的右边入队一个元素|O(1)|
|RPUSHX key value|从队列的右边入队一个元素，仅队列存在时有效|O(1)|

### set

Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。

集合类型的内部编码有两种：
- intset(整数集合):当集合中的元素都是整数且元素个数小于set-maxintset-entries配置（默认512个）时，Redis会选用intset来作为集合的内部实现，从而减少内存的使用。
- hashtable(哈希表):当集合类型无法满足intset的条件时，Redis会使用hashtable作为集合的内部实现。

集合的主要几个特性，无序、不可重复、支持并交差等操作。因此集合类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。
#### intset

创建一个intset编码的集合对象所有元素都被直接包含在一个整数集合里

![Pasted image 20230918001235](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701443.png)

contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。

向整数集合中添加新元素的时间复杂度为O(N);

#### hashtable

当传入字符时，变为hashtable编码，hashtable编码的集合对象底层由字典实现。字典的键就是集合的内容，值为null。

![Pasted image 20230918001246](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701444.png)![Pasted image 20230918001303](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701445.png)
![Pasted image 20230918001313](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701446.png)
#### 命令

|命令|说明|时间复杂度|
|---|---|---|
|SADD key member \[member ...]|添加一个或者多个元素到集合(set)里|O(N)|
|SCARD key|获取集合里面的元素数量|O(1)|
|SDIFF key \[key ...]|获得队列不存在的元素|O(N)|
|SDIFFSTORE destination key \[key ...]|获得队列不存在的元素，并存储在一个关键的结果集|O(N)|
|SINTER key \[key ...]|获得两个集合的交集|O(N\*M)|
|SINTERSTORE destination key \[key ...]|获得两个集合的交集，并存储在一个关键的结果集|O(N\*M)|
|SISMEMBER key member|确定一个给定的值是一个集合的成员|O(1)|
|SMEMBERS key|获取集合里面的所有元素|O(N)|
|SMOVE source destination member|移动集合里面的一个元素到另一个集合|O(1)|
|SPOP key \[count]|删除并获取一个集合里面的元素|O(1)|
|SRANDMEMBER key \[count]|从集合里面随机获取一个元素||
|SREM key member \[member ...]|从集合里删除一个或多个元素|O(N)|
|SUNION key \[key ...]|添加多个set元素|O(N)|
|SUNIONSTORE destination key \[key ...]|合并set元素，并将结果存入新的set里面|O(N)|
|SSCAN key cursor \[MATCH pattern] \[COUNT count]|迭代set里面的元素|O(1)|

#### 为什么要维护两个hash表？为了扩容

redis字典为了控制创建的hash表的空间开销，redis会动态调整hash表的空间大小，当ht\[0]的长度满了，这里的ht\[0]满了并不是指dictEntry数组里面每一个元素都存储了一个dictEntry，而是dictht的used和size相同，可能有部分dictEntry会发生散列冲突的。此时再向字典添加元素，此时redis字典就会进行扩容。

首先对ht\[1]进行扩容，扩容的大小为比当前当前容量大的2的n次方，目标大小必须为2的n次方，这样系统进行内存分配的效率才有保证，

比如当前容量ht\[0]的容量为4，那么扩容的大小就应该为2的3次方也就是8.再将ht\[0]的内容迁移到ht\[1]此时redis字典的结构如下
![Pasted image 20230918001333](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701447.png)
这样就可以减少hash表的内存占用，不够的时候就扩容hash表。

这种方法虽然节约了内存，但如果hash表已经很长了的时候，此时再扩容它的内存再分配的规模可能就会很大，造成性能影响。

因此，为了避免rehash对服务器性能造成影响，服务器不是一次性将ht\[0]里面的所有键值对全部rehash到ht\[1]，而是分多次、渐进式地将ht\[0]里面的键值对慢慢地rehash到ht\[1]。

以下是哈希表渐进式rehash的详细步骤：

1）为ht\[1]分配空间，让字典同时持有ht\[0]和ht\[1]两个哈希表。  
2）在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。  
3）在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht\[0]哈希表在rehashidx索引上的所有键值对rehash到ht\[1]，当rehash工作完成之后，程序将rehashidx属性的加一。  
4）随着字典操作的不断执行，最终在某个时间点上，ht\[0]的所有键值对都会被rehash至ht\[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。
### hash

在redis中，哈希类型是指Redis键值对中的值本身又是一个键值对结构，形如`value=[{field1，value1}，...{fieldN，valueN}]`

哈希类型的内部编码有两种：ziplist(压缩列表)、hashtable(哈希表)

只有当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型。具体需要满足两个条件：

- 当哈希类型元素个数小于 hash-max-ziplist-entries配置（默认512个）
- 所有值都小于hash-max-ziplist-value配置（默认64字节）  
    `ziplist`使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比`hashtable`更加优秀。当哈希类型无法满足`ziplist`的条件时，Redis会使用`hashtable`作为哈希的内部实现，因为此时`ziplist`的读写效率会下降，而`hashtable`的读写时间复杂度为O（1）

#### ziplist

![Pasted image 20230918001351](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701448.png)


#### hashtable

![Pasted image 20230918001408](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701449.png)


#### 命令

|命令|说明|时间复杂度|
|---|---|---|
|HDEL key field \[field ...\]|删除一个或多个Hash的field|O(N) N是被删除的字段数量。|
|HEXISTS key field|判断field是否存在于hash中|O(1)|
|HGET key field|获取hash中field的值|O(1)|
|HGETALL key|从hash中读取全部的域和值|O(N) N是Hash的长度|
|HINCRBY key field increment|将hash中指定域的值增加给定的数字|O(1)|
|HINCRBYFLOAT key field increment|将hash中指定域的值增加给定的浮点数|O(1)|
|HKEYS key|获取hash的所有字段|O(N) N是Hash的长度|
|HLEN key|获取hash里所有字段的数量|O(1)|
|HMGET key field \[field ...\]|获取hash里面指定字段的值|O(N) N是请求的字段数|
|HMSET key field value \[field value ...\]|设置hash字段值|O(N) N是设置的字段数|
|HSET key field value|设置hash里面一个字段的值|O(1)|
|HSETNX key field value|设置hash的一个字段，只有当这个字段不存在时有效|O(1)|
|HSTRLEN key field|获取hash里面指定field的长度|O(1)|
|HVALS key|获得hash的所有值|O(N) N是Hash的长度|
|HSCAN key cursor \[MATCH pattern\] \[COUNT count\]|迭代hash里面的元素||

### zset

有序集合类型 (Sorted Set或ZSet) 相比于集合类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。

有序集合保留了集合不能有重复成员的特性(分值可以重复)，但不同的是，有序集合中的元素可以排序。

有序集合是由 ziplist (压缩列表)或 skiplist (跳跃表)组成的。

当数据比较少时，有序集合使用的是 ziplist 存储的，有序集合使用 ziplist 格式存储必须满足以下两个条件：

- 有序集合保存的元素个数要小于 128 个；
- 有序集合保存的所有元素成员的长度都必须小于 64 字节。

如果不能满足以上两个条件中的任意一个，有序集合将会使用 skiplist 结构进行存储。

#### ziplist

![Pasted image 20230918001418](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701450.png)

#### skiplist

skiplist 编码的有序集合对象使用 zet 结构作为底层实现，一个 zset 结构同时包含一个字典和一个跳跃表：

```c
typedef struct zset{
     zskiplist *zsl;  //跳跃表
     dict *dice;  //字典
} zset;
```

字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。
这两种数据结构会通过指针来共享相同元素的成员和分值，所以不会产生重复成员和分值，造成内存的浪费。

说明：其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；假如我们单独使用跳跃表来实现，虽然能执行范围操作，但是查找操作有 O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。

跳跃表(skipList)是一种有序数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。

跳跃表支持评价O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。
![Pasted image 20230918001431](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310161701451.png)
最左边的结构为zskiplist结构 保存跳跃表节点的相关信息，比如节点数量，以及指向表头界定啊和表尾节点的指针等
后面的是四个zskiplistNode结构包含层（每一层都有前进指针和跨度）、后退指针、分值和成员对象

#### 命令

|命令|说明|时间复杂度|
|---|---|---|
|BZPOPMAX key \[key ...] timeout|从一个或多个排序集中删除并返回得分最高的成员，或阻塞，直到其中一个可用为止|O(log(N))|
|BZPOPMIN key \[key ...] timeout|从一个或多个排序集中删除并返回得分最低的成员，或阻塞，直到其中一个可用为止|O(log(N))|
|ZADD key \[NXXX] \[CH] \[INCR] score member \[score member ...]|添加到有序set的一个或多个成员，或更新的分数，如果它已经存在|O(log(N))|
|ZCARD key|获取一个排序的集合中的成员数量|O(1)|
|ZCOUNT key min max|返回分数范围内的成员数量|O(log(N))|
|ZINCRBY key increment member|增量的一名成员在排序设置的评分|O(log(N))|
|ZINTERSTORE|相交多个排序集，导致排序的设置存储在一个新的关键|O(N_K)+O(M_log(M))|
|ZLEXCOUNT key min max|返回成员之间的成员数量|O(log(N))|
|ZPOPMAX key \[count]|删除并返回排序集中得分最高的成员|O(log(N)\*M)|
|ZPOPMIN key \[count]|删除并返回排序集中得分最低的成员|O(log(N)\*M)|
|ZRANGE key start stop \[WITHSCORES]|根据指定的index返回，返回sorted set的成员列表|O(log(N)+M)|
|ZRANGEBYLEX key min max \[LIMIT offset count]|返回指定成员区间内的成员，按字典正序排列, 分数必须相同。|O(log(N)+M)|
|ZREVRANGEBYLEX key max min \[LIMIT offset count]|返回指定成员区间内的成员，按字典倒序排列, 分数必须相同|O(log(N)+M)|
|ZRANGEBYSCORE key min max \[WITHSCORES] \[LIMIT offset count]|返回有序集合中指定分数区间内的成员，分数由低到高排序。|O(log(N)+M)|
|ZRANK key member|确定在排序集合成员的索引|O(log(N))|
|ZREM key member \[member ...]|从排序的集合中删除一个或多个成员|O(M\*log(N))|
|ZREMRANGEBYLEX key min max|删除名称按字典由低到高排序成员之间所有成员。|O(log(N)+M)|
|ZREMRANGEBYRANK key start stop|在排序设置的所有成员在给定的索引中删除|O(log(N)+M)|
|ZREMRANGEBYSCORE key min max|删除一个排序的设置在给定的分数所有成员|O(log(N)+M)|
|ZREVRANGE key start stop \[WITHSCORES]|在排序的设置返回的成员范围，通过索引，下令从分数高到低|O(log(N)+M)|
|ZREVRANGEBYSCORE key max min \[WITHSCORES] \[LIMIT offset count]|返回有序集合中指定分数区间内的成员，分数由高到低排序。|O(log(N)+M)|
|ZREVRANK key member|确定指数在排序集的成员，下令从分数高到低|O(log(N))|
|ZSCORE key member|获取成员在排序设置相关的比分|O(1)|
|ZUNIONSTORE|添加多个排序集和导致排序的设置存储在一个新的关键|O(N)+O(M log(M))|
|ZSCAN key cursor \[MATCH pattern] \[COUNT count]|迭代sorted sets里面的元素|O(1)|