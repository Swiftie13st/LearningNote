# 计网

## 计算机网络体系结构

ISO 七层模型是国际标准化组织（International Organization for Standardization）制定的一个用于计算机或通信系统间互联的标准体系。[OSI七层模型详解](https://link.zhihu.com/?target=http%3A//blog.csdn.net/yaopeng_2005/article/details/7064869) 

- 应用层：网络服务与最终用户的一个接口，常见的协议有：**HTTP FTP  SMTP SNMP DNS**.
- 表示层：数据的表示、安全、压缩。，确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。
- 会话层：建立、管理、终止会话, 对应主机进程，指本地主机与远程主机正在进行的会话.
- 传输层：定义传输数据的协议端口号，以及流控和差错校验, 协议有**TCP UDP**.
- 网络层：进行逻辑地址寻址，实现不同网络之间的路径选择, 协议有**ARP**，**ICMP IGMP IP 等**.
- 数据链路层：在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路。
- 物理层：建立、维护、断开物理连接。

1.  物理层（Physical Layer）：该层负责在物理媒介上传输比特流（0和1），也就是将==数字信号转化为模拟信号==，以及在物理媒介中传输比特流。常见的物理媒介包括网线、光纤、无线电波等。
2.  数据链路层（Data Link Layer）：该层==负责将比特流组装成帧==（Frame），并为帧添加头部和尾部，以实现数据的传输和错误检测。常见的数据链路协议包括以太网协议（Ethernet）、局域网协议（LAN）等。
3.  网络层（Network Layer）：该层==负责将数据报（Datagram）从源主机传输到目的主机==，并实现路由和拥塞控制。常见的网络层协议包括Internet协议（IP）、Internet控制报文协议（ICMP）等。
4.  传输层（Transport Layer）：==该层负责提供可靠的端到端传输服务==，包括连接建立、数据传输和连接释放。常见的传输层协议包括传输控制协议（TCP）、用户数据报协议（UDP）等。
5.  会话层（Session Layer）：==该层负责建立、管理和终止会话==，以便进程之间进行通信。常见的会话层协议包括网络会话协议（NSP）、远程过程调用协议（RPC）等。
6.  表示层（Presentation Layer）：该层负责==将数据格式从应用程序中的内部表示转换为网络传输格式==，以及在接收端将网络传输格式转换为应用程序的内部表示。常见的表示层协议包括数据格式描述语言（DDL）、可扩展标记语言（XML）等。
7.  应用层（Application Layer）：该层==负责实现应用程序的网络功能==，例如电子邮件、文件传输、远程登录等。常见的应用层协议包括简单邮件传输协议（SMTP）、文件传输协议（FTP）、远程终端协议（Telnet）等。

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310261413353.png)

上图显示了数据在网络上传输时的封装和解封过程。

步骤 1：当设备 A 通过 HTTP 协议在网络上向设备 B 发送数据时，首先会在应用层添加一个 HTTP 标头。
步骤 2：然后在数据中添加 TCP 或 UDP 报头。数据在传输层被封装成 TCP 段。报头包含源端口、目的端口和序列号。
步骤 3：然后在网络层用 IP 标头对网段进行封装。IP 标头包含源/目的 IP 地址。
步骤 4：在数据链路层为 IP 数据报添加 MAC 标头，其中包含源/目的 MAC 地址。
步骤 5：封装后的帧被发送到物理层，并以二进制位的形式通过网络发送。
步骤 6-10：设备 B 从网络接收到比特后，会执行去封装过程，这是对封装过程的逆向处理。数据头被逐层删除，最终，设备 B 可以读取数据。

在网络模型中，我们需要分层，因为每一层都专注于自己的职责。每一层都可以依靠标头来处理指令，而不需要知道上一层数据的含义。

### 交换机和路由器的区别

1. 工作层次不同：交换机主要工作在数据链路层（第二层）路由器工作在网络层（第三层）。
2. 转发依据不同：交换机转发所依据的对象时：MAC地址。（物理地址）路由转发所依据的对象是：IP地址。（网络地址）
3. 主要功能不同：交换机主要用于组建局域网，而路由主要功能是将由交换机组好的局域网相互连接起来，或者接入Internet。

## 协议

### icmp协议

==网络层==
互联网控制消息协议(ICMP) 是**网络设备用来诊断网络通信问题的网络层协议**。
ICMP（Internet Control Message Protocol）协议是基于IP协议的一种网络层协议，它被用于在IP主机、路由器之间传递控制消息。ICMP协议提供了一种错误报告机制，可以让网络设备及时地发现并纠正错误，从而提高网络的可靠性和健壮性。

ICMP协议和IP协议密切相关，因为ICMP协议的消息是通过IP分组传输的。当网络中的某个设备出现故障时，它会向其他设备发送ICMP消息，告知其他设备出现了问题，需要进行处理。IP协议在处理这些ICMP消息时，会将它们传递到上层协议，从而实现网络层协议之间的交互。因此，ICMP协议和IP协议是相辅相成的关系。

#### Ping命令

Ping发送一个ICMP（Internet Control Messages Protocol），即因特网信报控制协议；接收端回声消息给目的地并报告是否收到所希望的ICMPecho （ICMP回声应答）。它的原理是：利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，通过对方回复的数据包来确定两台网络机器是否连接相通，时延是多少。

1. 向目的主机发送多个ICMP回送请求报文
2. 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。

#### 如何传回发送端的？

ICMP 大致可以分为两大类：

-   一类是用于诊断的查询消息，也就是「**查询报文类型**」
-   另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

1. **ICMP 回显请求**和 **ICMP 回显应答报文**是配合工作的。当源主机向目标主机发送了 ICMP 回显请求数据包后，它期待着目标主机的回答。目标主机在收到一个 ICMP 回显请求数据包后，它会交换源、目的主机的地址，然后将收到的 ICMP 回显请求数据包中的数据部分原封不动地封装在自己的 ICMP 回显应答数据包中，然后发回给发送 ICMP 回显请求的一方。如果校验正确，发送者便认为目标主机的回显服务正常，也即物理连接畅通。
3. **ICMP 目标不可达消息**：IP 路由器无法将 IP 数据报发送给目的地址时，会给发送端主机返回一个目标不可达 ICMP 消息，并在这个消息中显示不可达的具体原因。
4. **ICMP 重定向消息**：如果路由器发现发送端主机使用次优的路径发送数据时，那么它会返回一个 ICMP 重定向消息给这个主机，这个消息包含了最合适的路由信息和源数据。主要发生在路由器持有更好的路由信息的情况下，路由器会通过这个 ICMP 重定向消息给发送端主机一个更合适的发送路由。
5. **ICMP 超时消息**：IP 数据包中有一个字段 TTL(Time to live，生存周期)，它的值随着每经过一个路由器就会减 1，直到减到 0 时该 IP 数据包被丢弃。此时，IP 路由器将发送一个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。
6. **源抑制消息**：当 TCP/IP 主机发送数据到另一主机时，如果速度达到路由器或者链路的饱和状态，路由器发出一个 ICMP 源抑制消息。
7. **参数问题**：数据报首部出错时，丢弃该报文，并向源点发送参数问题报文。

#### traceroute说一下原理 

Traceroute 程序主要用来侦测源主机到目的主机之间所经过的路由的情况。

Traceroute 使用 ICMP 报文和 IP 首部中的 TTL 字段，它充分利用了 ICMP 超时消息。其原理很简单，开始时发送一个 TTL 字段为 1 的 UDP 数据报，而后每次收到 ICMP 超时后，按顺序再发送一个 TTL 字段加 1 的 UDP 数据报，以确定路径中的每个路由器，而每个路由器在丢弃 UDP 数据报时都会返回一个 ICMP 超时报文，而最终到达目的主机后，由于 ICM P选择了一个不可能的值作为 UDP 端口(大于30000)。这样目的主机就会发送一个端口不可达的 ICMP 差错报文。

### DHCP

==应用层==
DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）DHCP通常被用于局域网环境，主要作用是集中的管理、分配IP地址，使client动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。简单来说，DHCP就是一个不需要账号密码登录的、自动给内网机器分配IP地址等信息的协议。

### NAT

==网络层和传输层之间==
NAT协议是**将IP数据报头中的IP地址转换为另外一个IP地址的过程**， 主要用于实现私有网络访问公有网络的功能。 这种通过使用少量的IP地址代表较多的私有IP地址的方式，将有助于减少IP地址空间的枯竭。

### OSPF

OSPF通过路由器之间通告网络接口的状态来建立链路状态数据库，生成最短路径树，每个OSPF路由器使用这些最短路径构造路由表。

开放最短路径协议(OSPF)协议不仅能计算两个网络结点之间的最短路径，而且能计算通信费用。可根据网络用户的要求来平衡费用和性能，以选择相应的路由。在一个自治系统内可划分出若干个区域，每个区域根据自己的拓扑结构计算最短路径，这减少了OSPF路由实现的工作量；OSPF属动态的自适应协议，对于网络的拓扑结构变化可以迅速地做出反应，进行相应调整，提供短的收敛期，使路由表尽快稳定化。每个路由器都维护一个相同的、完整的全网链路状态数据库。这个数据库很庞大，寻径时， 该路由器以自己为根，构造最短路径树，然后再根据最短路径构造路由表。路由器彼此交换，并保存整个网络的链路信息，从而掌握全网的拓扑结构，并独立计算路由。

### ARQ 

==数据链路层+传输层==

TCP协议通过使用连续ARQ协议和滑动窗口协议，来保证数据传输的正确性，从而提供可靠的传输。

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ可能包括停止等待ARQ协议和连续ARQ协议，错误检测（Error Detection）、正面确认（Positive Acknowledgment）、超时重传（Retransmission after Timeout）和 负面确认及重传（Negative Acknowledgment and Retransmission）等机制。

**连续 ARQ 协议**

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

### 介绍下ARP协议（**广播问询，单播响应**）

==网络层==
ARP 协议，全称 **地址解析协议（Address Resolution Protocol）**，它解决的是网络层地址和链路层地址之间的转换问题。因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题。

#### MAC地址

MAC 地址的全称是 **媒体访问控制地址（Media Access Control Address）**。如果说，互联网中每一个资源都由 IP 地址唯一标识（IP 协议内容），那么一切网络设备都由 MAC 地址唯一标识。

#### 工作原理

每个网络设备都自己维护了一个 ARP 表，ARP 表记录了某些其他网络设备的 IP 地址-MAC 地址映射关系，该映射关系以 `<IP, MAC, TTL>` 三元组的形式存储。
TTL 为该映射关系的生存周期，典型值为 20 分钟，超过该时间，该条目将被丢弃。

##### 同一局域网A->B

1. A检索自己的ARP表，如没有
2. A发送一个ARP查询分组，广播发送到局域网
3. 局域网的每个设备都会收到，检查查询分组是否为自己的ip地址，不是丢弃
4. B收到后验证是自己的ip地址，会在自己的ARP表中加入A的ip，MAC地址，然后对A发送一个响应分组
5. A收到B的响应分组，将B的ip和MAC地址加入自己的ARP表中

##### 不同网络A->B

1. A查询ARP表，找到能够发给B的路由器的MAC地址，如果没有就重复同一局域网的广播查询
2. A构造IP数据报，源ip：a，目的ip，B，源mac：a，目的mac：路由器，单播发给路由器
3. 路由器接受到，解析目的ip，查ARP表，发给下一跳地址，封装数据链路帧目的MAC下一跳
4. 中途可能会经过多个路由器，知道B子网对应的路由器
5. 路由器查询ARP表，找B的MAC地址，如果没有也是重复同一局域网的广播查询
6. 路由器将IP数据报重新封装成数据链路帧，目的MAC地址为B的MAC地址，单播发送

#### 如果匹配到了多条路由，路由器会怎么转发

问题：当使用CIDR（无分类编址）时，路由表中存储的信息是【网络前缀，下一跳】，这就可能出现同一个目的IP可能与多个网络前缀相匹配，该如何解决呢？

当出现上述情况时，我们需要采用最长匹配原则。从匹配结果中选择具有最长网络前缀的路由：最长前缀匹配(longest-prefix matching)。网络前缀越长，其地址块就越小，因而路由就越具体(more specific) 。因此最长前缀匹配又称为最长匹配或最佳匹配。

### IP协议

==网络层==
IP 协议是 TCP/IP 协议族中最为核心的协议，更确切的说是网络层重要的协议之一。  
  
IP 协议把上层数据报封装成 IP 数据报后进行传输，如果 IP 数据报太大，还要对数据报进行分片后再传输，到了目的地址处再进行组装还原，以适应不同物理网络对一次所能传输数据大小的要求。  
  
IP协议具有以下几个显著的特点：

-   不能保证 IP 数据报能成功地到达目的地。IP 协议仅提供最好的传输服务，如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP 有一个简单的错误处理算法：丢弃该数据报，然后发送 ICMP 消息报给信源端。任何要求的可靠性必须由上层协议来提供（如TCP协议）。
-   IP 协议并不维护任何关于后续数据报的状态信息，每个数据报的处理是相互独立的。这也说明，IP数据报可以不按发送顺序接收。例如，如果一信源向相同的信宿发送两个连续的数据报（先是 A，然后是 B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此 B 可能在 A 之前先到达。
-   通信双方不同步传输数据的状态信息，无法处理乱序和重复的 IP 数据报；IP 数据报提供了标识字段用来唯一标识 IP 数据报，用来处理 IP 分片和重组，不指示接收顺序。

#### ip地址

IP 协议中有个概念叫 IP 地址。所谓 IP 地址，就是 Internet 中主机的标识，Internet 中的主机要与别的主机通信必须具有一个 IP 地址。就像房子要有个门牌号，这样邮递员才能根据信封上的地址送到目的地。  
  
IP 地址现在有两个版本，分别是 32 位的 IPv4 和 128 位的 IPv6，后者是为了解决前者不够用的问题而产生的。每个 IP 数据报都必须携带目的 IP 地址和源 IP 地址，路由器依靠此信息为数据报选择路由。

#### IPv4与IPv6的区别 

IPv4和IPv6用于用户标识和Internet上不同设备之间的通信。IPv4是32位IP地址，而IPv6是128位IP地址。
IPv4是数字地址，用点分隔。IPv6是一个字母数字地址，用冒号分隔。

1. **地址类型**。IPv4具有三种不同类型的地址：多播，广播和单播。IPv6还具有三种不同类型的地址：任意广播，单播和多播。
2. **数据包大小**。对于IPv4，最小数据包大小为576字节。对于IPv6，最小数据包大小为1208字节。
3. **header区域字段数**。**IPv4具有12个标头字段，而IPv6支持8个标头字段。
4. **可选字段**。IPv4具有可选字段，而IPv6没有。但是，IPv6具有扩展header，可以在将来扩展协议而不会影响主包结构。
5. **配置**。在IPv4中，新装的系统必须配置好才能与其他系统通信。在IPv6中，配置是可选的，它允许根据所需功能进行选择。
6. **安全性**。在IPv4中，安全性主要取决于网站和应用程序。它不是针对安全性而开发的IP协议。而IPv6集成了Internet协议安全标准（IPSec）。IPv6的网络安全不像IPv4是可选项，IPv6里的网络安全项是强制性的。
7. **与移动设备的兼容性**。IPv4不适合移动网络，因为正如我们前面提到的，它使用点分十进制表示法，而IPv6使用冒号，是移动设备的更好选择。
8. **主要功能**。IPv6允许直接寻址，因为存在大量可能的地址。但是，IPv4已经广泛传播并得到许多设备的支持，这使其更易于使用。

### DNS 

==应用层==
DNS服务器查询，（本地DNS，根DNS，顶级域DNS

1. 本地DNS服务器没有的话，发送请求到根DNS服务器
2. 根DNS服务器发回顶级域DNS服务器
3. 本地DNS服务器发送请求到顶级域DNS服务器
4. 顶级域DNS服务器收到后返回权威DNS服务器地址
5. 本地DNS服务器发送请求到权威DNS服务器
6. 权威DNS服务器发送ip地址到本地，完成域名的解析

#### DNS协议属于UDP还是TCP协议

DNS 并非只使用 UDP 协议，**它同时占用了 UDP 和 TCP 的 53 端口**

- 如果返回的响应超过512字节（UDP最大只支持512字节）使用TCP。DNS 在域名解析的过程中，会根据 DNS 响应报文的大小选择使用 TCP 还是 UDP。但是一般情况下，返回的 DNS 响应报文都不会超过 512 字节，==大多数情况下DNS使用UDP进行传输==，所以事实上，很多 DNS 服务器进行配置的时候，也仅支持 UDP 查询包；
-   DNS 在进行区域传输的时候使用 TCP 协议。（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）

以太网帧在局域网中的MTU是1500byte，但是在非局域网环境，如：internet下的时候，MTU是各个路由器进行一个配置的。所以，通常路由器默认的MTU为576字节。所以，为了适应网络环境，DNS协议在返回的数据报大于512的时候，就转化为了TCP协议。

1）若客户端**事先知道** DNS 响应报文的长度会大于 512 字节，则应当直接使用 TCP 建立连接

2）若客户端**事先不知道** DNS 响应报文的长度，一般会先使用 UDP 协议发送 DNS 查询报文，若 DNS 服务器发现 DNS 响应报文的长度大于 512 字节，则多出来的部分会被 UDP 抛弃（截断 TrunCation），那么服务器会把这个部分被抛弃的 DNS 报文首部中的 TC 标志位置为 1，以通知客户端该 DNS 报文已经被截断。客户端收到之后会重新发起一次 TCP 请求，从而使得它将来能够从 DNS 服务器收到完整的响应报文。

##### 什么是区域传输？

这就不得不提一下**主域名服务器和辅助域名服务器**。

设置域名服务器时，服务器管理员可以选择将域名服务器指定为主服务器还是辅助服务器（也称为从服务器）。

主域名服务器负责维护一个区域的所有域名信息，是特定的所有信息的权威信息源，数据可以修改。主服务器直接从本地文件获取此信息。只能在主服务器上更改区域的 DNS 记录，然后主服务器才能更新辅助服务器。

当主域名服务器出现故障、关闭或负载过重时，辅助域名服务器作为主域名服务器的备份提供域名解析服务。辅助域名服务器中的区域文件中的数据是从主域名服务器中复制过来的，无法自行修改。

其实就是主从的概念，各位应该也都比较熟悉了。主域名服务器用来写，辅助域名服务器用来读，**提供负载均衡的能力，缓解主域名服务器的压力**。

那么所谓区域传输（zone transfer）呢，就是辅助域名服务器与主域名服务器通信，并同步数据信息的过程。

辅域名服务器会定时向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传输。区域传输使用 TCP 而不是 UDP，因为**数据同步传送的数据量比一个 DNS 请求和响应报文的数据量要多得多**。

##### MTU

==MTU是数据链路层的概念，指数据链路层对数据帧长度的限制。==
最大传输单元MTU（Maximum Transmission Unit，MTU），是指**网络能够传输的最大数据包大小**，以字节为单位。MTU的大小决定了发送端一次能够发送报文的最大字节数。如果MTU超过了接收端所能够承受的最大值，或者是超过了发送路径上途经的某台设备所能够承受的最大值，就会造成报文分片甚至丢弃，加重网络传输的负担。如果太小，那实际传送的数据量就会过小，影响传输效率。

网络中通常以数据包为单位进行信息传递，那么，一次传送多大的包合适、多大的包最高效就成为一个核心问题之一。如果包大小设置的很大，意味着报文中的有效数据也更多，通信效率更高，但传送一个数据包的延迟也越大，数据包中bit位发生错误的概率也越大。并且如果这个报文丢掉了，重传的代价也很大。如果包大小设置的过小，则意味传输相同的数据量，设备需要处理更多的报文，这样会极大的考验设备的线速转发能力。通过设置MTU来调节网络上数据包的大小，让不同的网络找到最适宜的MTU从而提高转发效率，这就是MTU的作用。

##### MSS 

==TCP最大报文长度，相当于把MTU刨去IP头和TCP头之后的大小==
Maximum Segment Size ，TCP提交给IP层最大分段大小，不包含TCP Header和 TCP Option，只包含TCP Payload ，MSS是TCP用来限制application层最大的发送字节数。如果底层物理接口MTU= 1500 byte，则 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果application 有2000 byte发送，需要两个segment才可以完成发送，第一个TCP segment = 1460，第二个TCP segment = 540。

TCP为了避免被发送方分片，它主动把数据分成小段再交给网络层。最大的分段大小称为`MSS（Maximum Segment Size`），它相当于把MTU刨去IP头和TCP头之后的大小，所以一个MSS恰好能装进一个MTU中。

#### DNS 的解析过程涉及到了哪两种查询？

递归查询和迭代查询

通常来说，客户端和本地域名服务器是递归查询，而本地域名服务器和其他域名服务器之间是迭代查询。

##### 递归查询

假如我们本地客户端是A，有三个域名解析服务器B、C、D，首先在本地客户端A发起一次DNS解析请求，对B服务器请求解析DNS，B服务器查询后并无解析记录，==则B服务器对C服务器请求解析DNS==，C服务器查询后并无解析记录，则C服务器对D服务器请求解析DNS，，D服务器查询到解析记录，将解析记录返回到C服务器，C服务器将解析记录返回到B服务器，B服务器将解析记录返回到A服务器，完成一次递归解析查询。

```plain
A → B → C → D 
A ← B ← C ← D
```

##### 迭代查询

假如我们本地客户端是A，有三个域名解析服务器B、C、D，首先在本地客户端A发起一次DNS解析请求，对B服务器请求解析DNS，B服务器查询后并无解析记录，==返回到A未查询成功并携带C服务器的地址==，客户端A对C服务器请求解析DNS，C服务器查询后并无解析记录，返回到A未查询成功并携带D服务器的地址，客户端A对D服务器请求解析DNS，查询到解析记录，并将解析记录返回到A，完成一次迭代解析查询。

```plain
A → B 
A → C 
A → D
```

#### DNS域名解析服务使用的默认端口号是多少？

53，**它同时占用了 UDP 和 TCP 的 53 端口**

### RMTP 

==应用层==
RTMP（Real Time Messaging Protocol） 是由 Adobe 公司基于 Flash Player 播放器对应的音视频 flv 封装格式提出的一种，基于TCP 的数据传输协议。本身具有稳定、兼容性强、高穿透的特点。常被应用于流媒体直播、点播等场景。常用于推推流方（主播）的稳定传输需求。

## UDP

### UDP 报文大小

-   UDP 协议规定报文长度为 16 位，所以 UDP 的报文长度不能超过 2^16 = 65536 字节
-   以太网(Ethernet)数据帧的长度，这是由以太网的物理特性决定，也叫数据链路层的 MTU(最大传输单元)
-   socket 的 UDP 发送缓冲区大小

### 乱序问题

所谓乱序就是发送数据的顺序和接收数据的顺序不一致。
==UDP 协议并不保证数据报的按序接收==。
解决这个问题的方法就是发送端在发送数据时加入==数据报序号==，这样接收端接收到报文后可以先检查数据报的序号，并将它们按序排队，形成有序的数据报。

### udp缓冲区溢出

UDP 接收数据时直接将数据放进缓冲区内，如果用户没有及时将缓冲区的内容复制出来放好的话，后面到来的数据会接着往缓冲区放，当缓冲区满时，后来到的数据就会覆盖先来的数据而造成数据丢失（因为内核使用的 ==UDP 缓冲区是环形缓冲区==）。 因此，一旦发送方在某个时间点爆发性发送消息，接收方将因为来不及接收而发生信息丢失。

### 适用场景

UDP 不为 IP 提供可靠性、流量控制或差错恢复功能，所以 UDP 对应的则是可靠性要求低、传输流量大，传输速度快的应用。

-   面向数据报方式
-   网络数据大多为短消息
-   拥有大量 Client
-   对数据安全性无特殊要求
-   网络负担非常重，但对响应速度要求高

## TCP

### tcp用什么机制实现的

tcp为了通过IP数据报实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等，TCP通过校验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制等实现可靠性传输。

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202305251809351.png)

### TCP三次握手

==ACK 确认标志位，ack确认序号==
- 第一次握手 (发=0)，发送完毕后，客户端就进入 SYN_SENT 状态
- 第二次握手 (发送连接确认报文SYN=1, ACK=1, seq=y, ack=x+1)， 发送完毕后，服务器端就进入 SYN_RCV 状态。
- 第三次握手 (发出连接确认报文ACK=1，ack=y+1，序号seq=x+1)，发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态。

TCP/IP 协议是传输层的一个面向连接的安全可靠的一个传输协议，三次握手的机制是为了保证能建立一个安全可靠的连接，那么第一次握手是由客户端发起，客户端会向服务端发送一个报文，在报文里面：SYN标志位置为1，表示发起新的连接。当服务端收到这个报文之后就知道客户端要和我建立一个新的连接，于是服务端就向客户端发送一个确认消息包，在这个消息包里面：ACK标志位置为1，表示确认客户端发起的第一次连接请求。以上两次握手之后，对于客户端而言：已经明确了我既能给服务端成功发消息，也能成功收到服务端的响应。但是对于服务端而言：两次握手是不够的，因为到目前为止，服务端只知道一件事，客户端发给我的消息我能收到，但是我响应给客户端的消息，客户端能不能收到我是不知道的。所以，还需要进行第三次握手，第三次握手就是当客户端收到服务端发送的确认响应报文之后，还要继续去给服务端进行回应，也是一个ACK标志位置1的确认消息。通过以上三次连接，不管是客户端还是服务端，都知道我既能给对方发送消息，也能收到对方的响应。那么，这个连接就被安全的建了。

#### Why?

一：确保可靠的通信通道，**让双方都确认对方和自己的接收和发送功能是正常的**。
将三次握手通俗的说。
1. 第一次握手，Server知道Client的发送能力和自己的接收能力是正常的。
2. 第二次握手，Client知道Server的发送和接收能力和自己的发送和接收能力是正常的，但是Server还不知道我的接收和他的发送能力正常与否。
3. 第三次握手，Client回馈，让Server知道自己的发送能力和Client的接收能力正常。

二：如果两次握手，服务端无法确认客户端是否接收到了服务端发送的初始序号，如果第二次握手报文丢失，那么客户端无法知道服务端的初始序列号。

三：客户端由于某种原因发送了两次不同序号的syn包，旧的数据包有可能先到，如果两次握手服务端会之间对旧数据包建立连接。

四：两次握手无法抗住DDOS攻击

#### TCP初始序列号为什么是随机的

在TCP的三次握手中，采用随机产生的初始化序列号进行请求，这样做主要是出于网络安全的因素着想。如果不是随机产生初始序列号，黑客将会以很容易的方式获取到你与其他主机之间通信的初始化序列号，并且伪造序列号进行攻击，这已经成为一种很常见的网络攻击手段。

如果初始序列号固定，则收到一个包之后不知道其是旧连接还是新连接的

#### TCP三次握手交换了那些信息? 

TCP三次握手是建立TCP连接的过程，需要客户端和服务器总共发送3个报文。三次握手的目的是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息
MSS（Maximum Segment Size，最大报文长度），是TCP协议定义的一个选项，MSS选项用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度；

==双方序列号，tcp窗口大小，最大报文长度MSS==

#### 每次握手丢失后会发生什么 

**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

**第一次握手丢失：**

客户端触发「超时重传」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。
不同版本的操作系统可能超时时间不同，有的 1 秒的，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。**每次超时的时间是上一次的 2 倍**。

**第二次握手丢失：**

当第二次握手丢失了，客户端和服务端都会重传

**第三次握手丢失：**

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

### TCP四次挥手

具体流程

1. 第一次挥手：客户端发送连接释放报文FIN=1，序号(握手时初始序号 + 发送的字节数据数量 + 1)seq=u，发送完毕后，客户端进入**FIN_WAIT_1**状态。
2. 第二次挥手：服务器发出确认收到报文ACK=1，确认号ack=u+1，序列号(握手时初始序号 + 回复的字节数据)seq=v，发送完毕后，服务器端进入**CLOSE_WAIT**状态，客户端接收到这个确认包之后，进入**FIN_WAIT_2**状态。
3. 第三次挥手：关闭连接，发送连接释放报文FIN=1，确认号ack=u+1，初始序号seq=w，发送完毕后，服务器端进入**LAST_ACK**状态，等待来自客户端的最后一个 ACK。
4. 第四次挥手： 客户端接收到来自服务器端的关闭请求，发回确认收到报文ACK=1，确认序号seq=w+1，初始序号ack=u+1，客户端进入 TIME_WAIT 状态，**等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后**，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。

四次挥手：由客户端首先发起的，第一次挥手客户端会发送一个报文，在报文里面FIN标志位置1，当服务端收到这个报文就知道了客户端想要和我断开连接，但是此时服务端不一定能做好准备，因为当客户端发起断开连接的请求后，对于服务端而言还极有可能有未发送完的消息，还需继续发送，所以此时对于服务端而言只能进行一个消息确认（第二次挥手），即告诉客户端我知道你要和我断开连接，但是我这边还可能没有做好准备，你需要等我一下，等会儿我会告诉你（第三次挥手），于是，发完这个消息确认包过后，可能稍过片刻，服务端会继续发送一个断开连接的报文（第三次挥手），FIN位置1的报文，表示服务端已经做好断开连接的准备，当这个报文发给客户端的时候，客户端同样要给服务端发送一个消息确认的报文（第四次挥手），经过这四次的相互沟通和连接，我就知道了不管是客户端还是服务端都已经做好了断开连接的准备，于是连接断开了。

#### Why?

TCP是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

#### 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？

因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送。

其实如果没有数据，或者因为TCP延时确认机制，中间两次挥手是可以合并的

#### 第四次挥手可以去掉吗？

如果没有第四次挥手，假设服务端发完fin就关闭，fin丢失，此时客户端会一直处于fin_wait2状态

#### 为什么第四次挥手客户端需要等待 2\*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？

第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2\*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。

>**MSL(Maximum Segment Lifetime)** : 一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。

### TCP有哪些状态 

客户端的状态可以用如下的流程来表示：

CLOSED->SYN_SENT->ESTABLISHED->FIN_WAIT_1->FIN_WAIT_2->TIME_WAIT->CLOSED

服务器的状态可以用如下的流程来表示：

CLOSED->LISTEN->SYN-RCVD->ESTABLISHED->CLOSE_WAIT->LAST_ACK->CLOSED

### tcp流量控制

TCP 流量控制的核心机制是**滑动窗口**，TCP 流量控制是指 TCP 在数据传输过程中，对发送方的发送速率进行限制，以避免接收方无法处理过多数据而导致数据丢失或延迟的问题。

TCP 发送一个数据，如果需要收到确认应答，才会发送下一个数据。这样的话就会有个缺点：效率会比较低。因此TCP引入滑动窗口机制。

每个 TCP 连接都有一个发送窗口和一个接收窗口，分别用来控制数据的发送和接收。发送方维护了一个发送窗口，表示对方当前可接收的数据量，接收方维护了一个接收窗口，表示自己当前可接收的数据量。

每当接收方收到一些数据，它会向发送方发送一个通知，告诉发送方自己当前可接收的数据量是多少，这个信息被称为窗口大小。发送方根据接收方发送的窗口大小来控制自己的发送速率，确保不会发送超过接收方处理能力的数据量，从而避免数据丢失或延迟。

TCP 流量控制的优点是可以自适应网络环境的变化，不会因为网络拥塞而导致数据的堆积和丢失，保证了数据传输的可靠性。

#### TCP的接收缓冲区满了，收到数据后会向发送方发送ACK吗？

1. 只要收到了包（注意，这个包不一定有数据），就会ACK。  
2. TCP在ACK的同时会带有window大小值，表示这边能接受的数据量。发送方会根据这个调整数据量。  
3. 接收方缓冲区满时，回给发送方的window值就是0。  
4. 发送方看到window为0的包，会启动一个定时器，隔一段时间发一个包试探。  
5. 一旦接收方缓冲区有足够空间了，就会给window赋上非0值。发送方就又开始发送了。

### TCP 为什么不丢包？丢包了怎么办？

- 数据分片：发送端对数据进行分片，接受端要对数据进行重组，由TCP确定分片的大小并控制分片和重组
- 到达确认：接收端接收到分片数据时，根据分片数据序号向发送端发送一个确认
- 超时重发：发送方在发送分片时设置超时定时器，如果在定时器超时之后没有收到相应的确认，重发分片数据
- 滑动窗口：TCP连接的每一方的接受缓冲空间大小固定，接收端只允许另一端发送接收端缓冲区所能接纳的数据，TCP在滑动窗口的基础上提供流量控制，防止较快主机致使较慢主机的缓冲区溢出
- 失序处理：作为IP数据报来传输的TCP分片到达时可能会失序，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层;
- 重复处理：作为IP数据报来传输的TCP分片会发生重复，TCP的接收端必须丢弃重复的数据;
- 数据校验：TCP将保持它首部和数据的检验和，这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到分片的检验或有差错，TCP将丢弃这个分片，并不确认收到此报文段导致对端超时并重发

丢包用包号连续性确认，根据需求重发或忽略。

### 粘包拆包机制，收到的数据不够怎么办

TCP 是面向流，没有界限的一串数据。TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为，一**个完整的包可能会被 TCP 拆分成多个包进行发送**，**也有可能把多个小的包封装成一个大的数据包发送**，这就是所谓的 TCP 粘包和拆包问题。

解决方案：
- 发送端将每个数据包封装为固定长度
- 在数据尾部增加特殊字符进行分割
- 将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小。

#### MTU

==MTU是数据链路层的概念，指数据链路层对数据帧长度的限制。==
最大传输单元MTU（Maximum Transmission Unit，MTU），是指**网络能够传输的最大数据包大小**，以字节为单位。MTU的大小决定了发送端一次能够发送报文的最大字节数。如果MTU超过了接收端所能够承受的最大值，或者是超过了发送路径上途经的某台设备所能够承受的最大值，就会造成报文分片甚至丢弃，加重网络传输的负担。如果太小，那实际传送的数据量就会过小，影响传输效率。

网络中通常以数据包为单位进行信息传递，那么，一次传送多大的包合适、多大的包最高效就成为一个核心问题之一。如果包大小设置的很大，意味着报文中的有效数据也更多，通信效率更高，但传送一个数据包的延迟也越大，数据包中bit位发生错误的概率也越大。并且如果这个报文丢掉了，重传的代价也很大。如果包大小设置的过小，则意味传输相同的数据量，设备需要处理更多的报文，这样会极大的考验设备的线速转发能力。==通过设置MTU来调节网络上数据包的大小，让不同的网络找到最适宜的MTU从而提高转发效率，这就是MTU的作用。==

MTU其实就是在每一个节点的最大管控值，只要是大于这个值的数据帧，要么选择分片，要么直接丢弃。
因为根据当前节点的属性（主要是速度），要是没有MTU管控，都将大量数据包发来，当前节点都来不及处理了，全卡住不就完蛋了。
**其实就是因为兼顾延迟，使得大数据能发的同时，可以穿插的发送别的数据，不至于让其他的数据不能发送。**

#### MSS 

==TCP最大报文长度，相当于把MTU刨去IP头和TCP头之后的大小==
Maximum Segment Size ，TCP提交给IP层最大分段大小，不包含TCP Header和 TCP Option，只包含TCP Payload ，MSS是TCP用来限制application层最大的发送字节数。如果底层物理接口MTU= 1500 byte，则 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果application 有2000 byte发送，需要两个segment才可以完成发送，第一个TCP segment = 1460，第二个TCP segment = 540。

MSS为1460是由1500-20（IP头）-20（TCP头）计算出的。  
实际场景下，TCP包头中会带有12字节的选项----时间戳。  
这样，单个TCP包实际传输的最大量就缩减为1448字节。1448=1500-20（IP头）-32（20字节TCP头和12字节TCP选项时间戳）

IP层非常关心MTU，因为IP层会根据MTU来决定是否把上层传下来的数据进行分片。就像一条运输线路的承载能力是有限的，碰到大东西要运输，只能把大东西拆开成为散件，分开运输，到达目的地之后还必须能再次组装起来。

TCP为了避免被发送方分片，它主动把数据分成小段再交给网络层。最大的分段大小称为`MSS（Maximum Segment Size`），它相当于把MTU刨去IP头和TCP头之后的大小，所以一个MSS恰好能装进一个MTU中。

#### 为什么分mss mtu 

**出现MSS是为了避免让ip分片**
IP分片只有第一个带有传输层（tcp）或ICMP首部，其余的分片只有IP头。至于怎么重组就是到对端以后IP层的事情了。TCP分段每个都有完整首部。

为了照顾网络延迟，引入一个差不多大小的**MTU来限制单个IP包的大小**，而为了让IP层少分包或是不分包（因为IP分包中间丢了一个就得整个重传，而TCP分包只需要重传丢的那一个），传输层引入小于MTU的**MSS来限制单个TCP包的大小**。

#### 如果交给IP层分片会怎样？  

==只丢失一片数据也要重新传整个数据报==。  所以很可能造成经常大量重传。

因为IP层本身没有超时重传机制。只能让更高层（比如TCP）来负责超时和重传。当来自TCP报文段的某一片丢失后，TCP在超时后会重发整个TCP报文段，该报文段对应于一份IP数据报（而不是一个分片），没有办法只重传数据报中的一个数据分片。

这是因为IP分包后，除了第一个包有TCP报头信息，中间和后面的只有IP报头，所以没法重发一个。而TCP分包，会让每个IP包都有TCP报头信息和IP报头信息，可以做到重发只重发一个包。

#### 为什么UDP没有粘包

UDP 是基于报文发送的，**UDP首部采用了 16bit 来指示 UDP 数据报文的长度**，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。

而 TCP 是**基于字节流**的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 并没有把这些数据块区分边界，仅仅是**一连串没有结构的字节流**；另外从 TCP 的帧结构也可以看出，在 **TCP 的首部没有表示数据长度的字段**，基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。

### TCP 如何确保可靠性

**思路：**  TCP 是可靠的连接，为什么具有可靠性呢？记住这些点：

- 连接和断开的可靠性（三次握手，四次挥手）
- 有状态（哪些数据发送了，哪些没发）TCP 会记录哪些数据发送了，哪些数据被接收了，哪些没有被接受，并且保证数据包按序到达，保证数据传输不出差错。
- 可控制（超时重传、流量控制、拥塞控制等）它有数据包校验、ACK 应答、**超时重传 (发送方)**、失序数据重传（接收方）、丢弃重复数据、流量控制（滑动窗口）和拥塞控制等机制。

### TCP 与 UDP 的区别（重要）

-   **是否面向连接** ：UDP 在传送数据之前不需要先建立连接。而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。
-   **是否是可靠传输**：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。
-   **是否有状态** ：这个和上面的“是否可靠传输”相对应。TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。为此 ，TCP 需要维持复杂的连接状态表。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了。
-   **传输效率** ：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。
-   **传输形式** ： TCP 是面向字节流的，UDP 是面向报文的。
-   **首部开销** ：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。
-   **是否提供广播或多播服务** ：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多；

### 什么时候选择 TCP,什么时候选 UDP?

-   **UDP 一般用于即时通信**，比如： 语音、 视频 、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。
-   **TCP 用于对传输准确性要求特别高的场景**，比如文件传输、发送和接收邮件、远程登录等等。

### TCP五元组

**四元组是**：源IP地址、目的IP地址、源端口、目的端口

**五元组是:**   源IP地址、目的IP地址、协议号、源端口、目的端口

**七元组是:**   源IP地址、目的IP地址、协议号、源端口、目的端口，服务类型以及接口索引

### TCP的头部字段 

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202305032019153.png)

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

紧急指针：URG=1才生效

#### 网络包有哪些类型 

SYN, FIN, ACK, PSH, RST, URG.

SYN表示建立连接，FIN表示关闭连接，ACK表示响应，PSH表示有 DATA数据传输，RST表示连接重置，URG标识紧急数据，表示数据需要优先处理。

#### 其他

**MSL**：一个片段在网络中最大的存活时间

**MSS**：TCP报文段中**应用数据字段的最大长度**，不是TCP报文总长度。

**MTU**(以太网数据帧长度46~1500字节): 最大传输单元 (MTU = MSS + TCP头20字节+IP头20字节)，当IP层数据长度大于MTU时，IP层需要对数据进行分片（Fragmentation）

**路径MTU**：一个包从发送端传输到接收端，中间要跨越多个网络，每条链路的MTU都可能不一样，这个通信过程中最小的MTU称为路径MTU。


**RTT**往返时间，表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。
**RTO**重传超时时间，即从数据发送时刻算起，超过这个时间便执行重传。
RTT和RTO 的关系是：由于网络波动的不确定性，每个RTT都是动态变化的，所以RTO也应随着RTT动态变化。

### 拥塞控制

#### 慢启动

**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量


##### 涨到什么程度？

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

-   当 `cwnd` < `ssthresh` 时，使用慢启动算法。
-   当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

#### 拥塞避免

**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」

#### 拥塞发生

-   **超时重传**
	- `ssthresh` 设为 `cwnd/2`，
	- `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）
-   **快速重传**

	- `cwnd = cwnd/2` ，也就是设置为原来的一半;
	- `ssthresh = cwnd`;
	- 进入快速恢复算法

#### 快速恢复

当接收方发现丢了一个中间包的时候，==发送三次前一个包的 ACK==，于是发送端就会快速地重传，不必等待超时再重传。
快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

### tcp是一个连接一个线程吗，如果多个请求过来咋个办，不会创建很多线程吗

TCP是一种面向连接的协议，每个连接都需要一个独立的套接字，因此每个连接都需要一个独立的线程来处理。如果多个请求同时到达，服务器可以使用多线程来处理这些请求。对于这种情况，我们希望每当有一个Socket对象产生，服务器程序就产生一个线程去处理这个Socket对象。

### TCP是怎么保持长链接的？

TCP长连接保持：KeepAlive。TCP协议的实现里有一个KeepAlive机制，自动检测能否和对方连通并保持连接。

保活机制默认是关闭的，TCP连接的任何一方都可打开此功能。有三个主要配置参数用来控制保活功能。

向对端发送一个保活探测报文。

-   若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。
-   若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定**探测时间间隔（tcp_keepalive_intvl）** 后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的**探测循环次数上限（tcp_keepalive_probes）** 都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理。

#### tcp的探活(心跳)是多长时间？

-   保活时间（tcp_keepalive_time）默认：7200秒
-   保活时间间隔（tcp_keepalive_intvl）默认：75秒
-   探测循环次数（tcp_keepalive_probes）默认：9次

也就是默认情况下一条TCP连接在2小时（7200秒）都没有报文交换后，会开始进行保活探测，若再经过9\*75秒=11分钟15秒的循环探测都未收到探测响应，即共计：2小时11分钟15秒后会自动断开TCP连接。

#### 和http的keep-alive的区别

http协议是一个运行在TCP协议之上的无状态的应用层协议。它的特点是：客户端的每一次请求都要和服务端创建TCP连接，服务器响应后，断开TCP连接。下次客户端再有请求，则重新建立连接。

在早期的http1.0中，默认就是上述介绍的这种“请求-应答”模式。这种方式频繁的创建连接和销毁连接无疑是有一定性能损耗的。所以引入了**keep-alive**机制。http1.0默认是关闭的，通过http请求头设置“connection: keep-alive”进行开启；http1.1中默认开启，通过http请求头设置“connection: close”关闭。

**keep-alive**机制：若开启后，在一次http请求中，服务器进行响应后，不再直接断开TCP连接，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗。

## HTTP

HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

### http用什么协议实现的

~~**HTTP 协议是基于 TCP 协议的**，所以发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手。~~

修正（参见 [issue#1915open in new window](https://github.com/Snailclimb/JavaGuide/issues/1915)）：HTTP 3.0 之前是基于 TCP 协议的，而 HTTP3.0 将弃用 TCP，改用 **基于 UDP 的 QUIC 协议** 。此变化主要为了解决 HTTP/2 中存在的队头阻塞问题。由于 由于 HTTP/2 在单个 TCP 连接上使用了多路复用，受到 TCP 拥塞控制的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞。

### http协议的报文格式  

HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：
1.  起始行（start line）：描述请求或响应的基本信息；
2.  头部字段集合（header）：使用 key-value 形式更详细地说明报文；
3.  消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。

#### 请求行（请求报文）

请求行由三部分构成：
1.  请求方法：是一个动词，如 GET/POST，表示对资源的操作；
2.  请求目标：通常是一个 URI，标记了请求方法要操作的资源；
3.  版本号：表示报文使用的 HTTP 协议版本。
   
#### 状态行（响应报文）

比起请求行来说，状态行要简单一些，同样也是由三部分构成：

1.  版本号：表示报文使用的 HTTP 协议版本；
2.  状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误；
3.  原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。

#### 头部字段

头部字段是 key-value 的形式，用“:”分隔，不区分大小写，顺序任意，除了规定的标准头，也可以任意添加自定义字段，实现功能扩展；

http header 说几个：

Content-Type：返回内容的MIME类型
Content-Length：响应体的长度
User-Agent：应用类型，操作系统，软件和版本信息
Accept-Encoding：通知网络服务器在处理请求时使用哪种压缩算法
Accept：通知网络服务器可以向客户端返回什么类型的数据格式。

### HTTP为什么不安全

1. 明文传输
2. 传输过程中并不会验证通信方的身份
3. 传输过程中也不会验证报文的完整性

### https

#### HTTP 和 HTTPS 有什么区别？（重要）

-   **端口号** ：HTTP 默认是 80，HTTPS 默认是 443。
-   **URL 前缀** ：HTTP 的 URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`。
-   **安全性和资源消耗** ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 `SSL/TLS` 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。

1.  加密(Encryption)， HTTPS 通过对数据加密来使其免受窃听者对数据的监听，这就意味着当用户在浏览网站时，没有人能够监听他和网站之间的信息交换，或者跟踪用户的活动，访问记录等，从而窃取用户信息。
2.  数据一致性(Data integrity)，数据在传输的过程中不会被窃听者所修改，用户发送的数据会完整的传输到服务端，保证用户发的是什么，服务器接收的就是什么。
3.  身份认证(Authentication)，是指确认对方的真实身份，也就是证明你是你（可以比作人脸识别），它可以防止中间人攻击并建立用户信任。

#### HTTPs实现原理：

发起请求：客户端通过TCP和服务器建立连接后，发出一个请求证书的消息给到服务器。 证书返回：服务器端在收到请求后回应客户端并且返回证书。

TLS 使用一种称为[公钥加密](https://www.cloudflare.com/learning/ssl/how-does-public-key-encryption-work/)的技术：[密钥](https://www.cloudflare.com/learning/ssl/what-is-a-cryptographic-key/)有两个，即公钥和私钥，其中公钥通过服务器的 SSL 证书与客户端设备共享。当客户端打开与服务器的连接时，这两个设备使用公钥和私钥商定新的密钥（称为[会话密钥](https://www.cloudflare.com/learning/ssl/what-is-a-session-key/)），以加密它们之间的后续通信。

然后，所有 HTTP 请求和响应都使用这些会话密钥进行加密），使任何截获通信的人都只能看到随机字符串，而不是明文。

#### 加密过程

1) 客户端发起一个请求证书的http请求，告诉服务器自己支持哪些hash算法。
2) 服务端把自己的信息以数字证书的形式返回给客户端（证书内容有密钥公钥，网站地址，证书颁发机构，失效日期等）。证书中有一个公钥来加密信息，私钥由服务器持有。
3) 验证证书的合法性。客户端收到服务器的响应后会先验证证书的合法性（证书中包含的地址与正在访问的地址是否一致，证书是否过期）。
4) 生成随机密码（RSA签名）如果验证通过，或用户接受了不受信任的证书，浏览器就会生成一个随机的对称密钥（session key）并用公钥加密，让服务端用私钥解密，解密后就用这个对称密钥进行传输了，并且能够说明服务端确实是私钥的持有者。
5) 生成对称加密算法。验证完服务端身份后，客户端生成一个对称加密的算法和对应密钥，以公钥加密之后发送给服务端。此时被黑客截获也没用，因为只有服务端的私钥才可以对其进行解密。之后客户端与服务端可以用这个对称加密算法来加密和解密通信内容了。

#### 握手过程

1.  客户端向服务器发出 SSL/TLS 连接请求，包括 SSL/TLS 版本号、加密套件列表、随机数等信息。
2.  服务器收到客户端的连接请求后，向客户端发送 SSL/TLS 握手响应，包括 SSL/TLS 版本号、加密套件、服务器证书、随机数等信息。
3.  客户端收到服务器的握手响应后，验证服务器证书的合法性，并生成一个用于后续通信的随机数，然后使用服务器公钥对该随机数进行加密，并将加密结果发送给服务器。
4.  服务器收到客户端发送的加密随机数后，使用私钥对其进行解密，并使用该随机数生成一个对称加密密钥。
5.  客户端和服务器都已经生成了对称加密密钥，使用该密钥加密握手过程后续的所有通信数据，从此建立起一个安全通信通道。
6.  客户端向服务器发送一个“客户端完成”消息，表示 SSL/TLS 握手过程已经完成，可以开始进行正式的通信。
7.  服务器也向客户端发送一个“服务器完成”消息，表示 SSL/TLS 握手过程已经完成，可以开始进行正式的通信。

#### HTTPS是如何防止中间人攻击的

为了避免中间人攻击，HTTPS 中采用了证书验证机制。在握手阶段，服务器会向客户端发送数字证书，数字证书中包含了服务器的公钥以及服务器信息等，客户端会根据自己预置的信任机构证书库（Trust Store）来验证数字证书的合法性。如果数字证书通过了验证，客户端就可以使用服务器的公钥来加密数据并发送给服务器，同时也可以使用服务器的公钥解密服务器发来的数据，这样就可以确保通信的安全性，避免中间人攻击。

#### 如何确定数字证书不是假的

数字证书的真实性是由证书颁发机构（CA）确认的。证书颁发机构是可信的第三方机构，它们通过验证证书请求者的身份并颁发数字证书来确保数字证书的真实性。当客户端与 Web 服务器进行通信时，客户端会检查 Web 服务器发送的==数字证书是否由受信任的证书颁发机构签名==。如果数字证书被受信任的证书颁发机构签名，客户端就可以信任该数字证书的真实性，可以安全地进行通信。

#### 使用会话密钥有什么问题？

会话密钥是用于仅对单次通信会话进行加密的任何对称加密密钥。换句话说，它是一个临时密钥，只使用一次，仅在一个时间段内用于加密和解密双方之间发送的数据；双方之间的未来对话将使用不同的会话密钥进行加密。会话密钥就像每次登录时都会重置的密码一样。

在 TLS 中，两个通信方（客户端和服务器）在任何通信会话最开始的 TLS 握手期间生成会话密钥。尽管 TLS 的官方 RFC 实际上并未将这些密钥称为“会话密钥”，但是从功能上讲，这就是它们的本质。

以共享密钥方式加密时必须将密钥也发给对方。在互联网上转发密钥时，如果通信被监听，那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。**因此https首先使用非对称加密系统加密对称密钥来防止中间人攻击**。HTTPS 采用**共享密钥加密**和**公开密钥加密**两者并用的混合加密机制。公开密钥加密很安全。但是公开密钥加密与共享密钥加密相比，其处理速度要慢。

**公开密钥加密**使用一对非对称的密钥。一把叫做**私有密钥（private key）**，另一把叫做**公开密钥（public key）**。顾名思义，**私有密钥**不能让其他任何人知道，而**公开密钥**则可以随意发布，任何人都可以获得。

发送密文的一方使用**对方的**公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的**私有密钥**进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。另外，要想根据密文和公开密钥，恢复到信息原文是异常困难。

### keeplive

HTTP协议采用请求-应答模式，有普通的非KeepAlive模式，也有KeepAlive模式。

非KeepAlive模式时，每个请求/应答客户和服务器都要新建一个连接，完成 之后立即断开连接（HTTP协议为无连接的协议）；当使用Keep-Alive模式（又称持久连接、连接重用）时，Keep-Alive功能使客户端到服 务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能==避免了建立或者重新建立连接==。

#### Keep-Alive模式，客户端如何判断请求所得到的响应数据已经接收完成（或者说如何知道服务器已经发生完了数据）？

1. 使用消息首部字段Conent-Length
2. 使用消息首部字段Transfer-Encoding: chunked， chunk编码将数据分成一块一块的发生。Chunked编码将使用若干个Chunk串连而成，由一个标明**长度为0**的chunk标示结束。

### HTTP 常用的请求方式，区别和用途？
| 方法    | 作用                                                                                              |
| ------- | ------------------------------------------------------------------------------------------------- |
| GET     | 获取资源，对服务器资源获取的简单请求                                                              |
| POST    | 传输实体主体，用于发送包含用户提交数据的请求                                                      |
| PUT     | 上传文件，像服务器提交数据，以 **修改** 数据                                                      |
| DELETE  | 删除文件，删除服务器上的某些资源                                                                  |
| HEAD    | 和GET方法类似，但只返回报文**首部**，不返回报文实体主体部分，用于请求页面的首部，获取资源的元信息 |
| PATCH   | 对资源进行部分修改                                                                                |
| OPTIONS | 查询指定的URL支持的方法，返回所有可用的方法，常用于**跨域**                                       |
| CONNECT | 要求用ssl隧道协议连接**代理**                                                                     |
| TRACE   | 服务器会将通信路径返回给客户端，追踪请求-响应的传输路径                                           |

#### GET和POST的区别

- GET使用URL或Cookie传参，而POST将数据放在BODY中”，这个是因为HTTP协议用法的约定。 
-  GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。 
-  POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的区别。 
- GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是。这个是它们本质区别。（幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。）

### HTTP 状态码有哪些？

HTTP 状态码用于描述 HTTP 请求的结果，比如2xx 就代表请求被成功处理。
信息 (100-199) 成功 (200-299) 重定向 (300-399) 客户端错误 (400-499) 服务器错误 (500-599)

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310261412238.png)

#### 1xx Informational（信息性状态码）

相比于其他类别状态码来说，1xx 你平时你大概率不会碰到，所以这里直接跳过。

#### 2xx Success（成功状态码）

-   **200 OK** ：请求被成功处理。比如我们发送一个查询用户数据的HTTP 请求到服务端，服务端正确返回了用户数据。这个是我们平时最常见的一个 HTTP 状态码。
-   **201 Created** ：请求被成功处理并且在服务端创建了一个新的资源。比如我们通过 POST 请求创建一个新的用户。
-   **202 Accepted** ：服务端已经接收到了请求，但是还未处理。
-   **204 No Content** ： 服务端已经成功处理了请求，但是没有返回任何内容。

#### 3xx Redirection（重定向状态码）

-   **301 Moved Permanently** ： 资源被永久重定向了。比如你的网站的网址更换了。
-   **302 Found** ：资源被临时重定向了。比如你的网站的某些资源被暂时转移到另外一个网址。
-   **304** : 304状态码表示客户端请求的资源未被修改，服务器无需重新发送资源，而是直接返回响应头，让客户端使用本地缓存。客户端在请求时会带上If-Modified-Since等条件，服务端会根据这些条件来判断是否需要重新发送资源。如果服务端判断资源未被修改，则返回304状态码和相应的响应头信息，客户端就可以使用本地缓存了

#### 4xx Client Error（客户端错误状态码）

-   **400 Bad Request** ： 发送的HTTP请求存在问题。比如请求参数不合法、请求方法错误。
-   **401 Unauthorized** ： 未认证却请求需要认证之后才能访问的资源。
-   **403 Forbidden** ：直接拒绝HTTP请求，不处理。一般用来针对非法请求。
-   **404 Not Found** ： 你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。
-   **409 Conflict** ： 表示请求的资源与服务端当前的状态存在冲突，请求无法被处理。

#### 5xx Server Error（服务端错误状态码）

-   **500 Internal Server Error** ： 服务端出问题了（通常是服务端出Bug了）。比如你服务端处理请求的时候突然抛出异常，但是异常并未在服务端被正确处理。
-   **502 Bad Gateway** ：我们的网关将请求转发到服务端，但是服务端返回的却是一个错误的响应。

### URI 和 URL 的区别是什么?

-   URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。
-   URL(Uniform Resource Locator) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## http1/1.1/2/3 

HTTP/1.1` 相比 HTTP/1.0 性能上的改进：

- 使用`长连接`的方式改善了 HTTP/1.0 短连接造成的性能开销。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有**非流水线方式和流水线方式** 。流水线方式是客户在**收到HTTP的响应报文之前就能接着发送新的请求报文**。与之相对应的非流水线方式是客户**在收到前一个响应后才能发送下一个请求**。
- 支持`管道`（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
- 在HTTP1.1中新增了24个错误状态`响应码`，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
- `带宽优化及网络连接的使用`：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就**方便了开发者自由的选择以便于充分利用带宽和连接**。

**HTTP/1.1 自身的性能瓶颈：**

1. 请求/响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩Body的部分
2. 发送冗长的首部。每次互相发送相同的首部造成的浪费较多
3. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞
4. 没有请求优先级控制
5. 请求只能从客户端开始，服务器只能被动响应

## HTTP2

### HTTP1和HTTP2的区别

1. 新的`二进制格式`：HTTP2采用二进制格式而HTTP1使用`文本格式`。头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。
2. `多路复用`：HTTP2是完全多复用的，而非有序并阻塞的，只需一个连接即可实现并行。HTTP1一个连接只能发送一个请求。引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接，针对不同的 HTTP 请求用独一无二的 **Stream ID** 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。
3. `首部压缩`：HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用**HPack**来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
4. `服务器推送`：HTTP2在客户端请求资源的时候，会把相关的资源一起发送给客户端，而不需要客户端再次发起请求获取资源。HTTP/2在一定程度上改善了传统的「请求-应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。比如：在浏览器刚请求HTML的时候，就提前把可能用到的JS、CSS文件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫Cache Push）

### 为什么需要头部压缩？

HTTP协议是不带有状态的，每次请求头部都会附上所有的信息，而且很多的信息都是重复的，这会浪费很多宽带也会影响速度，所以HTTP2对头部进行了压缩，一方面使用gzip或compress进行头部压缩，另一方面，客户端和服务器会同时维护同一张头信息表，所有的字段都会存入这张表中，生成一个索引号，以后就不需要再发送同样的字段了，只发送索引号，提示了速度。

### 什么是HPack

HPACK本质上是**通过建立索引和头字段的映射，从而将出现的头字段编码成简短的索引，同时针对字段值也可以通过Huffman编码进行进一步的压缩**，对于HTTP2这种一次性发送多帧的协议，在传输上节省了很多空间，在以前这些重复的头部信息可能要占用大量的带宽。

### 队头阻塞问题

-   HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，==TCP 层必须保证收到的字节数据是完整且连续的==，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么==当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里==，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。

## http3

HTTP/2主要的问题在于：多个HTTP请求在复用一个TCP连接，下层的TCP协议是不知道有多少个HTTP请求。所以一旦发生了丢包现象，就会触发TCP的重传机制，这样在一个TCP连接中的所有的HTTP请求都必须等待这个丢了包被重传回来。（区别：HTTP/1.1 的管道传输中，如果有一个请求阻塞，那么队列请求也统统被阻塞住了）

UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

### 无队头阻塞

QUIC 有自己的一套机制可以保证传输的可靠性的。**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

**QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动**。

同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后 面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就 可以发给用户。

### 更快的连接建立

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果**。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商

### 连接迁移

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（`源 IP`、`源端口`、`目的 IP`、`目的端口`）确定一条 TCP 连接。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

### UDP 会出现丢包、重复等问题， 那么应用程序使用 HTTP /3 为什么还能得到完整的网页、图像、音视频等。

**QUIC 协议**，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。

QUIC 也有个序列号，是递增的。
任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个 包，序号是 100，发现没有返回;再次发送的时候，序号就是 101 了;如果返回的 ACK 100，就是对第 一个包的响应。如果返回 ACK 101 就是对第二个包的响应，RTT 计算相对准确。
QUIC 定义了一个 offset 概念。
QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个 偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发; 如果来了，按照 offset 拼接，还是能够拼成一个流。

### Quic握手

1. 客户端发起请求:客户端发送QUIC初始数据包(包含ClientHello消息)到服务器，请求建立连接。这个消息中包含了客户端支持的加密算法列表、随机数(ClientRandom)、以及其他必要的TLS参数。
2. 服务器响应并确认:服务器收到客户端的请求后，返回QUIC初始数据包，其中包含了ServerHello消息、服务器证书，以及ServerFinished消息。这些消息中包含了服务器选择的加密算法、随机数(ServerRandom)、证书、以及其他的TLS参数
3. 客户端验证并确认:客户端收到服务器的响应后，会验证服务器的证书。如果证书有效，客户端会使用协商的密钥进行加密通信，同时它发送的数据包(包含Client Finished消息)在传输路径上就已经加密了。

这个过程是在一个RTT内完成的，因为服务器在收到客户端的初始请求后，就能进行回应，而客户端在收到服务器的回应后，就可以开始发送加密的数据包。这里的关键在于，客户端的确认(通过发送加密的数据)和服务器的确认是同时发生的，不需要额外的RTT。

在第二次连接的时候,应用数据包可以和QUIC握手信息(连接信息+TLS信息)一起发送,达到0-RTT的效果

### stream

HTTP/3同HTTP/2一样采用二进制顿的结构，不同的地方在于HTTP/2的二进制里需要定义Stream而HTTP/3自身不需要再定义Stream直接使用QUIC里的Stream于是HTTP/3的帧的结构也变简单了。

HTTP/2是基于TCP的TCP协议中并没有流(Stream)的概念，所以HTTP/2需要自定义二进制帧来实现流的功能，而每个二进制顿都会包含一个StreamD来标识它属于哪个流。当你在HTTP/2中发送一个请求时，其实是在创建一个新的流，并通过设置二进制顿中的StreamID来指明这个请求应该在哪个流中被处理。

而在HTTP/3中，由于底层的QUIC协议已经包含了Stream的概念，所以HTTP/3不需要再自己定义二进制帧来实现流的功能，直接使用QUIC中的Stream就可以了。在HTTP/3中，当你发送一个请求时，你是在创建一个新的QUIC流，并且QUIC会自动处理StreamID的问题，所以HTTP/3的顺结构相较于HTTP/2更加简洁。

## ping命令是如何实现的

Ping发送一个ICMP（Internet Control Messages Protocol），即因特网信报控制协议；接收端回声消息给目的地并报告是否收到所希望的ICMPecho （ICMP回声应答）。它的原理是：利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，通过对方回复的数据包来确定两台网络机器是否连接相通，时延是多少。

1. 向目的主机发送多个ICMP回送请求报文
2. 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。
  
### 通过ip地址如何找到目标地址

查路由表，找下一跳，使用ARP协议将IP地址转MAC地址，找到下一跳

## 从输入URL 到页面展示到底发生了什么？（非常重要）

-   URL 输入
  1. 检查是否是合法的url连接，是否完整，补全前缀后缀
  2. 如果不合法会使用默认搜索引擎进行搜索
-   浏览器查找域名的 IP 地址，首先检测DNS缓存（hosts，浏览器）里找，找不到就发请求到DNS服务器进行[DNS 解析](https://cloud.tencent.com/product/cns?from=10680)
  1. 检测浏览器和本地的hosts是否有缓存记录
  2. 进行DNS服务器查询，（本地ISPDNS，根DNS，顶级域DNS
     1. 本地DNS服务器没有的话，发送请求到根DNS服务器
     2. 根DNS服务器发回顶级域DNS服务器
     3. 本地DNS服务器发送请求到顶级域DNS服务器
     4. 顶级域DNS服务器收到后返回权威DNS服务器地址
     5. 本地DNS服务器发送请求到权威DNS服务器
     6. 权威DNS服务器发送ip地址到本地，完成域名的解析
-   建立 TCP 连接（三次握手）
    路由器进行tcp连接的时候需要将ip地址转换为MAC地址，使用ARP协议
-   发送 HTTP / HTTPS 请求（建立 TLS 连接）
-   服务器响应请求，返回 HTTP 报文
-   浏览器解析渲染页面，DOM树
-   HTTP 请求结束，断开 TCP 连接（四次挥手）

### 解析过程中哪些步骤可以做性能优化

1. 缓存DNS：DNS存在着多级缓存，从离浏览器的距离排序的话，有以下几种: 浏览器缓存，系统缓存，路由器缓存，ISP服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。
2. DNS-prefetch（DNS预获取）是尝试在请求资源之前解析域名，这可能是后面要加载的文件，也可能是用户尝试打开的链接目标。域名解析和内容载入时串行的网络操作，所以这个方式能减少用户的等待时间，提升用户体验。
3. 使用CDN加速

### CDN工作流程

当用户请求一个文件时，CDN的工作流程如下：  
1. DNS请求当地DNS  
2. 当地DNS递归查询服务器的负载均衡（GSLB)  
3. 服务器根据当地DNS分配最佳节点，返回IP  
4. 用户获取最佳接入IP，访问最佳节点  
5. 如果该节点没有用户想要获取的内容，则通过内部路由访问上一节点，直到找到文件或到达源站为止  
6. CDN节点缓存该数据，下次请求该文件时可以直接返回

### 通过电脑面试，进一下从你进入电脑开始，在咱两之间传输的数据经过了哪些网络节点? 

这些节点包括您的电脑和面试官的电脑所连接的路由器，以及这些路由器之间的其他路由器。当您发送数据时，数据会被分成小块并通过网络传输。每个数据包都会被发送到下一个路由器，直到到达目标计算机。在传输过程中，每个路由器都会查看目标地址，并将数据包转发到下一个路由器，直到到达目标计算机。

查路由表，找下一跳，使用ARP协议将IP地址转MAC地址，找到下一跳

### ping一个域名到收到包发生了什么 

1.  如果是 ping 域名，首先需要通过 **DNS 服务**拿到对方的 IP。
2.  主机构建一个 **ICMP 格式的数据包**，由 ICMP 协议将这个数据包（有效负荷）连同目的 IP 地址一起交给 IP 协议。
3.  IP 协议构建一个**分组（本机 IP + 控制信息 + 目的 IP）**，控制信息至少包含了 01h 的协议字段，这样当此分组到达目的方时，这些内容就会告诉目的主机应该将这个有效负荷交付给哪个协议来处理，本例中就是 ICMP。
4.  如果目的 IP 不跟自己在同一个网段，则需要通过路由转发，先通过路由信息得到**网关 IP**。如果在同一网段则没有此步骤。
5.  如果之前与目的 IP （或网关 IP）通信过，应该在 ARP 缓存表中能查到对应的 **MAC 地址**。如果没有，就需要通过 ARP 广播来获取 MAC 地址了。把 IP 地址解析为 MAC 地址后，此分组就可被传送到数据链路层以组建成帧。
6.  数据链路层将控制信息封装到此分组上，**创建成帧**。在这个帧中，附加有目的 MAC 地址和源 MAC 地址，以及以太网类型字段（用来指明应用于帧数据字段的协议）。在帧的尾部是 FCS（帧校验序列）字段，这个部分装载了 CRC（循环冗余校验）的计算结果。
7.  把帧交付给物理层，**物理层**会以一次一比特的方式将帧**发送**到物理介质。
8.  这时，此冲突域中的每台设备都会接收这些比特，并将它重新组建成帧。每个设备都会对接收到的内容进行 CRC 运算，并与帧中 FCS 字段的内容进行比对。如果值不匹配，接收到的帧将被丢弃。如果匹配，接着将**检查目的 MAC 地址与自己的是否匹配**。如果匹配，则接下来查看以太网类型字段，以获悉完成数据后续处理的网络层协议。
9.  将分组从帧中取出，并将其他部分丢弃。然后，分组被**递交给**以太网类型字段中列出的协议（本例是 **IP 协议**）。
10.  IP 协议接收这个分组，并检查它的 IP 的地址。如果这是一个路由器（网关），跳到 11。如果这就是目的主机，跳到下一步 12。
11.  由于分组的目的 IP 地址与此接收路由器上的各个地址均不匹配，路由器会在其**路由表中查找目的 IP 的地址**，（在此路由表中需要包含目的子网的相关表项，否则路由器会立即将收到的分组丢弃，并同时向发送方回送一个携带有目标网络不可达信息的 ICMP 报文。），并按照路由规则被交换到指定的输出接口的缓冲区内。接着重复 5 ~ 11 步骤。
12.  分组的目的 IP 与此主机 IP 地址匹配，检查分组的协议字段，了解分组有效负荷的交付对象。此有效负荷将被递交给 ICMP，后者知道这是一个回应请求数据。ICMP 将负责应答这个请求，它首先立即丢弃这个接收到的分组然后**产生**一个新的有效负荷作为回应**应答数据**。

###  路由表是怎么建立起来的 

• 静态路由：由网络管理员设置并随时更新 †网络管理员的工作负担重，容易出错，无法根据网络状态，进行调 整，适应性差； †简单、开销小，只适用于小型网络。

• 动态路由：路由器运行过程中根据网络情况动态地维护 †减轻了网络管理员的工作负担重； †实时性好，适应性好； †能够满足大型网络的需要； †因要搜集网络运行状态，网络开销有所增加，实现也比较复杂。

RIP启动时的初始路由表仅包含本路由器的一些直连端口路由，RIP启动后的工作过程包括如下几个步骤。  
  
(1) RIP启动后向各端口广播一个Request报文。  
  
(2)邻居路由器的RIP从某端口收到Request 报文后，根据自己的路由表形成Response报文向该端口对应的网络广播。  
  
(3)IP接收邻居路由器回复的包含邻居路由器路由表的Response报文，形成路由表。**RIP以30s为周期用Response报文广播自己的路由表**。  
  
收到邻居发送而来的Response 报文后，RIP计算报文中的路由度量值，比较其与本地路由表中的路由度量值是否有差别，更新自己的路由表。报文中**路由度量值的计算公式为metric = MIN ( metric + cost, 16 )**。其中，metric为报文中携带的度量值信息; cost 为接收报文的网络的开销，默认为1; 16 代表不可达。  
  
RIP根据DV算法的特点，将协议的参加者分为主动机和被动机两种。主动机主动向外广播路由刷新报文，被动机被动地接收路由刷新报文。一般情况下，主机作为被动机，路由器则既是主动机又是被动机，即在向外广播路由刷新报文的同时，接收来自其他主动机的DV报文，并进行路由刷新。

（1）仅和相邻路由器交换信息。

（2）交换的信息是当前本路由器所知道的全部信息，即自己的路由表。==RIP交换的是本路由器上完整的路由表==。

（3）按固定的时间间隔交换路由信息（一般间隔为30s）

## http 上传一个json文件的全过程 

1.  首先，客户端需要创建一个HTTP请求，指定请求方法为POST，请求头中需要指定Content-Type为application/json，表示上传的数据是JSON格式的。请求体中包含要上传的JSON数据。
2.  然后，客户端将HTTP请求发送到服务器。
3.  服务器接收到HTTP请求后，首先需要解析请求头中的Content-Type字段，判断上传的数据是否为JSON格式。
4.  如果上传的数据是JSON格式，则服务器需要解析请求体中的JSON数据，并进行相应的处理。
5.  处理完成后，服务器需要创建一个HTTP响应，指定响应状态码为200 OK，并在响应头中指定Content-Type为application/json，表示响应的数据也是JSON格式的。响应体中包含处理后的JSON数据。
6.  最后，服务器将HTTP响应发送回客户端

## Cookie session

### Session和cookie具体干啥的？什么区别？  

Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；

Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。


cookie是客户端浏览器用来保存服务端数据以及用户信息的一种机制，当我们通过浏览器进行网页访问时，服务器可以把某一些状态数据以k-v的形式写入到cookie中，存储到客户端浏览器。客户端下次访问服务器时，可以携带cookie数据发送到服务端，服务器通过cookie中的状态数据去识别使用者。

session表示一个会话，它是在服务端保存的一个数据结构，默认情况下会针对每一个浏览器请求分配一个session对象，它可以用来在服务端存储当前会话产生的一些状态数据。因为http协议是一个无状态协议，服务端不知道客户端发出的多个请求是否属于同一用户，因此服务端通过session去存储客户端在同一个会话中的多次请求记录，通过服务端的session和客户端的cookie实现有状态的http协议。

工作原理：

1. 客户端第一次访问服务端时，服务端会针对次请求创建一个session并生成唯一的一个session id，
2. 并将此session id写入到客户端cookie中，用来实现客户端状态的一个保存
3. 后续请求中，客户端携带此session id，服务端根据id识别出当前会话的状态

#### cookie

Cookie是一个小文件，通常由web服务器在浏览器中存储。当用户访问网站时，服务器可以读取Cookie中的数据来识别用户。Cookie通常用于跟踪用户偏好，例如语言偏好、购物车内容等。Cookie还可以用于实现“记住我”功能，使用户不必每次都输入用户名和密码。但是，Cookie也可以被滥用来跟踪用户的行为，并被认为是用户隐私的潜在威胁。默认浏览器会话关闭时过期

-   name  Cookie名称
-   value  Cookie值
-   maxAge  Cookie失效时间（如果为0，即为删除cookie）
-   secure  是否仅被使用安全协议传输，HTTPS、SSL
-   path  Cookie的作用路径
-   domain  可以访问该Cookie的域名

#### session

Session是一种在web服务器上存储用户数据的机制。当用户访问网站时，服务器将创建一个唯一的标识符（称为Session ID）并将其存储在Cookie中。服务器会在其本地存储中创建一个与该Session ID相关联的数据存储空间，可以在其中存储有关用户身份和状态的数据。与Cookie不同，Session数据存储在服务器上，因此更加安全。Session可以用于在web应用程序中存储登录状态、购物车内容等用户数据。当用户在浏览器中关闭所有选项卡或窗口时，Session将被销毁。默认超时时间30分钟

#### 会话完整流程：

1. 用户输入登录信息。
2. 服务器验证信息，并创建Session，存储到数据库（Redis）。
3. 服务器为用户生成Session id，将带有Session id的Cookie放在用户浏览器。
4. 后续请求中，根据数据库验证Session id ，有效则接受。
5. 用户注销，会话在服务器和客户端都被销毁。

### 存在什么安全性问题？ 

**session劫持**实际上就是自己的PHPSESSID被攻击者以某种方式获取，然后在会话的有效期内，利用被攻击者的身份登录网站，来达到身份劫持，伪装成合法用户。一般PHPSESSID存储在cookie中，XSS攻击也会造成session劫持。

 **服务器端需维护大量 session_id**，有一定负担。

**cookie信息泄露**。cookie中存取了大量用户的信息，如身份id，浏览次数，手机号，等一些隐私信息，截取了某平台的cookie信息，存储的信息量非常多，Cookie的主要功能是实现用户个人信息的记录，它最根本的用途是帮助Web站点保存有关访问者的信息，可是一旦泄露除了信息泄露，攻击者无疑也可以通过用户身份登录，无疑也是很大的隐患。

### session如何做分布式？ 

1. session复制（session同步）：让所有服务器同步session
2. 存储再客户端cookie中
3. 统一存储，redis
4. 哈希一致性，一个ip始终对应一台机器

## 数字证书

### 作用

**数字证书**（或简称证书）是在 Internet 上唯一地标识人员和资源的电子文件。证书使两个实体之间能够进行安全、保密的通信。

数字证书可用于发送安全电子邮件、访问安全站点、网上证券、网上招标采购、网上签约、网上办公、网上缴费、网上税务等网上安全电子事务处理和安全电子交易活动。

证书就好像一本护照：它可以标识持有者并提供其他重要信息。证书由称为**证书授权机构** (Certification Authority, CA) 的可信赖第三方发布。CA 类似于护照申领办公室：它将验证证书持有者的身份并对证书进行签名，以使他人无法伪造或篡改证书。CA 对证书进行签名之后，持有者可以提供该证书作为身份证明并建立经过加密的保密通信。

### 原理

数字证书采用公钥密码体制，即利用一对互相匹配的密钥进行加密、解密。每个用户拥有一把仅为本人所掌握的私有密钥（私钥），用它进行解密和签名；同时拥有一把公共密钥（公钥）并可以对外公开，用于加密和验证签名。当发送一份保密文件时，发送方使用接收方的公钥对数据加密，而接收方则使用自己的私钥解密，这样，信息就可以安全无误地到达目的地了，即使被第三方截获，由于没有相应的私钥，也无法进行解密。通过数字的手段保证加密过程是一个不可逆过程，即只有用私有密钥才能解密。在公开密钥密码体制中，常用的一种是RSA体制。

用户也可以采用自己的私钥对信息加以处理，由于密钥仅为本人所有，这样就产生了别人无法生成的文件，也就形成了数字签名。采用数字签名，能够确认以下两点：

（1）保证信息是由签名者自己签名发送的，签名者不能否认或难以否认；

（2）保证信息自签发后到收到为止未曾作过任何修改，签发的文件是真实文件。

## 服务器出现TIME_WAIT和CLOSE_WAIT的原因以及解决方法？

`TIME_WAIT`和`CLOSE_WAIT`是TCP协议中的两个状态

### TIME_WAIT状态

当一条TCP连接被正常关闭时，会进入TIME_WAIT状态，等待2MSL（最长报文段寿命）时间后才会彻底关闭。这是因为TCP协议的四次挥手需要一定的时间来完成，为了确保网络中所有报文段都已经被正确处理，需要等待2MSL时间。

cat /proc/sys/net/ipv4/tcp_fin_timeout 
linux 60s

短时间内大量的断开连接，会大量消耗客户端机器的端口，毕竟端口只有65535个，端口被耗尽，便无法发起新的连接。可以进行TIME_WAIT的快速回收和重用来缓解。

#### 原因

-   客户端或服务器端主动关闭连接后，对方没有及时响应或没有正常关闭连接，导致一方认为连接还未关闭，继续等待。
-   短时间内建立和关闭大量TCP连接，导致大量TIME_WAIT状态的连接积压。

#### 解决方法

-   调整操作系统的TCP参数，如缩短2MSL时间、增大最大连接数、修改TCP的TIME_WAIT时间等。
-   使用连接池技术，重用已经建立好的连接，避免频繁创建和关闭连接。
-   优化应用程序，避免一次性创建和关闭大量的连接。

```sh
vim /etc/sysctl.conf

net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_max_tw_buckets = 5000
```

### CLOSE_WAIT状态

当一条TCP连接被客户端关闭后，服务器端可能会进入CLOSE_WAIT状态，等待最后的数据传输完成后再关闭连接。如果服务器端在CLOSE_WAIT状态下长时间未关闭连接，可能会导致连接积压，影响网络性能。

#### 原因

-   服务器端未及时响应客户端的关闭请求，导致客户端一直处于FIN_WAIT_2状态，服务器端一直处于CLOSE_WAIT状态。
-   服务器端收到客户端的FIN包后，没有及时发送ACK包，导致客户端一直处于FIN_WAIT_2状态，服务器端一直处于CLOSE_WAIT状态。

#### 解决方法

-   优化服务器端应用程序的代码，确保能够及时处理客户端的关闭请求，避免服务器端一直处于CLOSE_WAIT状态。
-   调整服务器端的TCP参数，如缩短TCP的超时时间、增加TCP的最大并发连接数等。
-   使用连接池技术，重用已经建立好的连接，避免频繁创建和关闭连接。

## 半连接队列有了解吗 

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

-   半连接队列，也称 SYN 队列；哈希表
-   全连接队列，也称 accept 队列；链表

服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。

### 客户端向服务端发起建立连接请求，如果服务端最大连接数满了，客户端会发生什么 

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

**当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象**。
实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。

1.  **如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；**
2.  **若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；**
3.  **如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog >> 2)，则会丢弃；**

## SYN泛洪攻击

在 SYN 泛洪攻击中，攻击者可以反复将 SYN 数据包发送到服务器上的每个端口（通常使用虚假 IP 地址或欺骗性 IP 地址），或发送到任意一个端口。由于这些请求看似合法的 TCP 连接，服务器会使用来自所请求的每个开放端口的 SYN-ACK 数据包响应各请求。最终的 ACK 数据包永远不会到达，于是服务器就会维持越来越多的开放端口连接。在所有可用端口均已开放后，服务器无法再正常运行，造成为真实用户管理 TCP 序列号极其困难。

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

### 防御

- 减少 SYN+ACK 重传次数，当重传超过次数达到上限后，就会断开连接。
- 增大半连接队列
- 防火墙，白名单等，过滤掉非法ip
- 开启 net.ipv4.tcp_syncookies
	-   当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；
	- 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端； 
	- 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。
	- 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

-   入侵检测系统 (IDS)，如果攻击使用非欺骗性源 IP，这类系统能检测并阻止来自 SYN 泛洪攻击和其他 DDoS 攻击的恶意流量
-   速率限制技术，用于限制任何时候可以向服务器发送的每秒 SYN 请求数或每秒 SYN 数据包数
-   配置更大的待处理任务队列，增加允许的“半开放”连接数量
-   部署解决方案以实现更高的网络监测能力，让安全团队能够查看和分析来自网络不同部分的流量
-   SYN Cookie，使用 ACK 数据包中的加密哈希在分配内存资源之前验证连接，也称为反欺骗方法
-   回收最早的半开放连接，为新连接腾出空间，并确保系统在泛洪攻击期间保持可访问状态
-   防火墙，可以过滤掉非法的 SYN 数据包（但这样做会降低性能）
-   云 DDoS 抵御

## 连接中如果客户端拔掉网线

### 拔掉网线后，有数据传输

在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，**服务端就会触发超时重传机制**，重传未得到响应的数据报文。

**如果在服务端重传报文的过程中，客户端刚好把网线插回去了**。由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。

**但如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去**。服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 `RST` 报文，客户端收到后就会释放该 TCP 连接。此时，客户端和服务端的 TCP 连接都已经断开了。

### 拔掉网线后，没有数据传输

1. 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
2. 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的TCP 连接还是能正常存在。

`KeepAlive`机制：当连接超过一段时间没有数据传输之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，连接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为连接丢失，没有必要保持连接。

### 如果是客户端宕机/杀死进程

杀死客户端的进程后，客户端的`内核`就会向服务端发送 FIN 报文，与服务端进行四次挥手。
即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。

## Http缓存机制 

对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。

所以，避免发送 HTTP 请求的方法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

### 强制缓存

强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：

-   `Cache-Control`， 是一个相对时间；
-   `Expires`，是一个绝对时间；

如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，**Cache-Control 的优先级高于 Expires** 。

Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：

-   当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
-   浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
-   服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

### 协商缓存

当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。

**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**。

协商缓存可以基于两种头部来实现。

第一种：请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现，这两个字段的意思是：

-   响应头部中的 `Last-Modified`：标示这个响应资源的最后修改时间；
-   请求头部中的 `If-Modified-Since`：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。

第二种：请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段，这两个字段的意思是：

-   响应头部中 `Etag`：唯一标识响应资源；
-   请求头部中的 `If-None-Match`：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。

第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。

如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，**这时 Etag 的优先级更高**，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。

**为什么 ETag 的优先级更高？**这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：

1.  在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求；
2.  可能有些文件是在秒级以内修改的，`If-Modified-Since` 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；
3.  有些服务器不能精确获取文件的最后修改时间。

注意，**协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

-   首先，浏览器端会根据Cache-Control是否是no-store来判断是否可以对返回的数据进行缓存，如果是no-store表示不允许缓存，之后的请求都不会走缓存，而是重新想服务器端发送请求。
-   如果不是no-store，一般就是返回max-age: 5000;来告诉浏览器端可以对数据进行缓存，并且设置缓存的失效时间，通过max-age一般会搭配no-cache或者must-revalidate一起返回，no-cache和must-revalidate就是控制要去服务器端进行验证数据是否真的有变化。
-   那如何验证变化呢？就是借助Last-Modified/if-Modified-Since，或者ETag/If-None-Match来判断，如果确实有变化，则返回最新数据，如果没有变化，则返回304，同时更新缓存的失效时间。

## 127.0.0.1 和 0.0.0.0 的区别

### 0.0.0.0

首先，`0.0.0.0`是不能被`ping`通的。0.0.0.0称为“unspecified”，即未指定（即无效的，无意义的）地址。从功能上看，一般用于某些程序/网络协议中不便使用具体ip的特殊情况（说白了就是一个用于某些比较坑的情况的“占位符”），比如DHCP客户端还未获取到ip的时候规定使用0.0.0.0作“源地址”，或者在服务器中，`0.0.0.0`并不是一个真实的的**IP地址**，它表示本机中所有的**IPV4地址**。服务器不指定在哪个网卡上监听时，也使用0.0.0.0,这个时候监听本机中所有**IP**的端口。

### 127.0.0.1

{127，}:即网络号为127的任意ip地址。都是内部主机回环地址(loopback),永远都不能出现在主机外部的网络中。

ipv6 `::1`

绑定到127.0.0.1只会监听来自本地的请求，绑定到0.0.0.0是监听所有来源的请求，这个应该是cidr的网段和ip匹配。

在实际应用中，一般我们在服务端绑定端口的时候可以选择绑定到0.0.0.0，这样我的服务访问方就可以通过我的多个ip地址访问我的服务。
比如我有一台服务器，一个外放地址A,一个内网地址B，如果我绑定的端口指定了0.0.0.0，那么通过内网地址或外网地址都可以访问我的应用。但是如果我之绑定了内网地址，那么通过外网地址就不能访问。 所以如果绑定0.0.0.0,也有一定安全隐患，对于只需要内网访问的服务，可以只绑定内网地址。

## CIDR

### 传统ABC类

1. A类地址
	一个A类地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”，地址范围从1.0.0.0到126.0.0.0，可用的A类网络有126个，每个网络能容纳1亿多个主机。
1. B类IP地址
	一个B类IP地址由2个字节的网络地址和2个字节但是主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机。
1. C类IP地址
	一个C类IP地址由3个字节的网络地址和1字节的主机地址组成，网络地址最高位必须是“110”，范围从192.0.0.0到233.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。

### CIDR

-   CIDR 消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。
-   CIDR 使用各种长度的 “网络前缀” ( network-prefix ) 来代替分类地址中的网络号和子网号。
-   IP 地址从三级编址（使用子网掩码）又回到了两级编址。

CIDR 使用 “斜线记法” (slash notation)，它又称为 CIDR 记法，即在 IP 地址后面加上一个斜线 “`/`” ，然后写上网络前缀所占的位数（这个数值对应于三级编址中子网掩码中 1 的个数）。

CIDR 把网络前缀都相同的连续的 IP 地址组成 “CIDR 地址块”。

`128.14.32.0/20`

表示的地址块共有 212 个地址（因为斜线后面的`20`是网络前缀的位数，所以这个地址的主机号是`12`位，因为总共是 32 位）。

-   这个地址块的起始地址是 `128.14.32.0`。
-   在不需要指出地址块的起始地址时，也可将这样的地址块简称为“`/20` 地址块”。

地址块的最小地址：`128.14.32.0`

地址块的最大地址：`128.14.47.255`

-   全 0 和全 1 的主机号地址一般不使用。

#### 最长匹配原则

-   使用 CIDR 时，路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。
-   应当从匹配结果中选择具有最长网络前缀的路由：`最长前缀匹配` (longest-prefix matching)。
-   网络前缀越长，其地址块就越小，因而路由就越具体 (more specific) 。
-   最长前缀匹配又称为最长匹配或最佳匹配。

## 如果一直发送数据包，用户进程不接收会发生什么，数据包会丢还是怎么样，缓冲区会溢出吗 

对于TCP，如果应用进程一直没有读取，接收缓冲区满了之后，接收端通知发发端，接收窗口关闭（win=0）。这个便是滑动窗口的实现。保证TCP套接口接收缓冲区不会溢出，从而保证了TCP是可靠传输。

对于UDP，如果应用进程一直没有读取，接收缓冲区满了之后，新到达的数据报将被丢弃。

### 如果客户端的部分IP不能接收到正常的服务器的服务，请问该怎么处理 

1. 自测，检查是否有宕机现象
2. 检查客户端所在地区网络服务是否正常，如CDN挂了
3. 查看日志，根据日志信息排查
4. 重启服务

## IP层怎么实现可靠通信 

第一，即使传送数据的因特网有一些缺陷（如造成比特差错或分组丢失），但具有很多智能的终端主机仍然有办法实现可靠的数据传输（例如，能够及时发现差错并通知发送方重传刚才出错的数据）。
第二，即使网络可以实现 100% 地无差错传输，端到端的数据传输仍然有可能出现差错。

IP层不可靠：是指不能保证IP数据报能成功到达目的地，是一种尽力而为的传输服务，路由器对IP报错误处理方式是丢包，并发送ICMP给源地址。

## HTTP发送一次请求与相应发送了多少个数据包

### HTTP1/2

1. TCP 3次握手
2. TLS 4次握手
3. 正常业务请求
4. TCP4次挥手

### HTTP3

第一次连接：
1. quic握手 1RTT
2. 正常业务

第二次连接
1. 握手加正常业务

## 外部请求怎么打到端口号上 

**端口映射：** 端口映射就是将内网中的主机的一个端口映射到外网主机的一个端口，提供相应的服务。当用户访问外网IP的这个端口时，服务器自动将请求映射到对应局域网内部的机器上。

## 网络攻击

### TCP 重置攻击

在 **TCP** 重置攻击中，攻击者通过向通信的一方或双方发送伪造的消息，告诉它们立即断开连接，从而使通信双方连接中断。正常情况下，如果客户端收发现到达的报文段对于相关连接而言是不正确的，**TCP** 就会发送一个重置报文段，从而导致 **TCP** 连接的快速拆卸。

**TCP** 重置攻击利用这一机制，通过向通信方发送伪造的重置报文段，欺骗通信双方提前关闭 TCP 连接。如果伪造的重置报文段完全逼真，接收者就会认为它有效，并关闭 **TCP** 连接，防止连接被用来进一步交换信息。服务端可以创建一个新的 **TCP** 连接来恢复通信，但仍然可能会被攻击者重置连接。万幸的是，攻击者需要一定的时间来组装和发送伪造的报文，所以一般情况下这种攻击只对长连接有杀伤力，对于短连接而言，你还没攻击呢，人家已经完成了信息交换。

从某种意义上来说，伪造 **TCP** 报文段是很容易的，因为 **TCP/IP** 都没有任何内置的方法来验证服务端的身份。有些特殊的 IP 扩展协议（例如 `IPSec`）确实可以验证身份，但并没有被广泛使用。客户端只能接收报文段，并在可能的情况下使用更高级别的协议（如 `TLS`）来验证服务端的身份。但这个方法对 **TCP** 重置包并不适用，因为 **TCP** 重置包是 **TCP** 协议本身的一部分，无法使用更高级别的协议进行验证。

### 中间人攻击

攻击中间人攻击英文名叫 Man-in-the-MiddleAttack，简称「MITM 攻击」。指攻击者与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方 直接对话，但事实上整个会话都被攻击者完全控制。

#### 防御

1. 使用加密通信协议。加密通信协议可以保证通信数据的机密性和完整性，从而防止中间人篡改数据。常见的加密通信协议包括 HTTPS、SSH 等。  
2. 使用数字证书验证身份。数字证书可以验证通信双方的身份，从而防止中间人冒充通信双方进行攻击。常见的数字证书包括 SSL 证书、SSH 证书等。  
3. 使用双因素认证。双因素认证可以增加身份验证的安全性，从而防止中间人攻击。常见的双因素认证方式包括短信验证码、动态口令等。  
4. 定期更新软件和补丁。定期更新软件和补丁可以修复已知的漏洞和安全问题，从而防止中间人攻击。

### IP欺骗

IP 欺骗技术就是**伪造**某台主机的 IP 地址的技术。通过 IP 地址的伪装使得某台主机能够**伪装**另外的一台主机，而这台主机往往具有某种特权或者被另外的主机所信任。

假设现在有一个合法用户 **(1.1.1.1)** 已经同服务器建立正常的连接，攻击者构造攻击的 TCP 数据，伪装自己的 IP 为 **1.1.1.1**，并向服务器发送一个带有 RSI 位的 TCP 数据段。服务器接收到这样的数据后，认为从 **1.1.1.1** 发送的连接有错误，就会清空缓冲区中建立好的连接。

这时，如果合法用户 **1.1.1.1** 再发送合法数据，服务器就已经没有这样的连接了，该用户就必须从新开始建立连接。攻击时，伪造大量的 IP 地址，向目标发送 RST 数据，使服务器不对合法用户服务。虽然 IP 地址欺骗攻击有着相当难度，但我们应该清醒地意识到，这种攻击非常广泛，入侵往往从这种攻击开始。

#### 防御

虽然无法预防 IP 欺骗，但可以采取措施来阻止伪造数据包渗透网络。**入口过滤** 是防范欺骗的一种极为常见的防御措施，如 BCP38（通用最佳实践文档）所示。入口过滤是一种数据包过滤形式，通常在网络边缘设备上实施，用于检查传入的 IP 数据包并确定其源标头。如果这些数据包的源标头与其来源不匹配或者看上去很可疑，则拒绝这些数据包。一些网络还实施出口过滤，检查退出网络的 IP 数据包，确保这些数据包具有合法源标头，以防止网络内部用户使用 IP 欺骗技术发起出站恶意攻击。

### SYN泛洪攻击

在 SYN 泛洪攻击中，攻击者可以反复将 SYN 数据包发送到服务器上的每个端口（通常使用虚假 IP 地址或欺骗性 IP 地址），或发送到任意一个端口。由于这些请求看似合法的 TCP 连接，服务器会使用来自所请求的每个开放端口的 SYN-ACK 数据包响应各请求。最终的 ACK 数据包永远不会到达，于是服务器就会维持越来越多的开放端口连接。在所有可用端口均已开放后，服务器无法再正常运行，造成为真实用户管理 TCP 序列号极其困难。

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

#### 防御

- 减少 SYN+ACK 重传次数，当重传超过次数达到上限后，就会断开连接。
- 增大半连接队列
- 防火墙，白名单等，过滤掉非法ip
- 开启 net.ipv4.tcp_syncookies
	-   当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；
	- 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端； 
	- 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。
	- 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

-   入侵检测系统 (IDS)，如果攻击使用非欺骗性源 IP，这类系统能检测并阻止来自 SYN 泛洪攻击和其他 DDoS 攻击的恶意流量
-   速率限制技术，用于限制任何时候可以向服务器发送的每秒 SYN 请求数或每秒 SYN 数据包数
-   配置更大的待处理任务队列，增加允许的“半开放”连接数量
-   部署解决方案以实现更高的网络监测能力，让安全团队能够查看和分析来自网络不同部分的流量
-   SYN Cookie，使用 ACK 数据包中的加密哈希在分配内存资源之前验证连接，也称为反欺骗方法
-   回收最早的半开放连接，为新连接腾出空间，并确保系统在泛洪攻击期间保持可访问状态
-   防火墙，可以过滤掉非法的 SYN 数据包（但这样做会降低性能）
-   云 DDoS 抵御

### UDP Flood(洪水)

**UDP Flood** 也是一种拒绝服务攻击，将大量的用户数据报协议（**UDP**）数据包发送到目标服务器，目的是压倒该设备的处理和响应能力。防火墙保护目标服务器也可能因 **UDP** 泛滥而耗尽，从而导致对合法流量的拒绝服务。

**UDP Flood** 主要通过利用服务器响应发送到其中一个端口的 **UDP** 数据包所采取的步骤。在正常情况下，当服务器在特定端口接收到 **UDP** 数据包时，会经过两个步骤：

-   服务器首先检查是否正在运行正在侦听指定端口的请求的程序。
-   如果没有程序在该端口接收数据包，则服务器使用 **ICMP**（ping）数据包进行响应，以通知发送方目的地不可达。

举个例子。假设今天要联系酒店的小蓝，酒店客服接到电话后先查看房间的列表来确保小蓝在客房内，随后转接给小蓝。

首先，接待员接收到呼叫者要求连接到特定房间的电话。接待员然后需要查看所有房间的清单，以确保客人在房间中可用，并愿意接听电话。碰巧的是，此时如果突然间所有的电话线同时亮起来，那么他们就会很快就变得不堪重负了。

当服务器接收到每个新的 **UDP** 数据包时，它将通过步骤来处理请求，并利用该过程中的服务器资源。发送 **UDP** 报文时，每个报文将包含源设备的 **IP** 地址。在这种类型的 **DDoS** 攻击期间，攻击者通常不会使用自己的真实 **IP** 地址，而是会欺骗 **UDP** 数据包的源 **IP** 地址，从而阻止攻击者的真实位置被暴露并潜在地饱和来自目标的响应数据包服务器。

由于目标服务器利用资源检查并响应每个接收到的 **UDP** 数据包的结果，当接收到大量 **UDP** 数据包时，目标的资源可能会迅速耗尽，导致对正常流量的拒绝服务。

#### 防御

大多数操作系统部分限制了 **ICMP** 报文的响应速率，以中断需要 ICMP 响应的 **DDoS** 攻击。这种缓解的一个缺点是在攻击过程中，合法的数据包也可能被过滤。如果 **UDP Flood** 的容量足够高以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何缓解都将不足以应对目标设备上游的瓶颈。

### HTTP Flood(洪水)

HTTP Flood 是一种大规模的 DDoS（Distributed Denial of Service，分布式拒绝服务）攻击，旨在利用 HTTP 请求使目标服务器不堪重负。目标因请求而达到饱和，且无法响应正常流量后，将出现拒绝服务，拒绝来自实际用户的其他请求。

HTTP 洪水攻击是“第 7 层”DDoS 攻击的一种。第 7 层是 OSI 模型的应用程序层，指的是 HTTP 等互联网协议。HTTP 是基于浏览器的互联网请求的基础，通常用于加载网页或通过互联网发送表单内容。缓解应用程序层攻击特别复杂，因为恶意流量和正常流量很难区分。

为了获得最大效率，恶意行为者通常会利用或创建僵尸网络，以最大程度地扩大攻击的影响。通过利用感染了恶意软件的多台设备，攻击者可以发起大量攻击流量来进行攻击。

HTTP 洪水攻击有两种：

-   **HTTP GET 攻击**：在这种攻击形式下，多台计算机或其他设备相互协调，向目标服务器发送对图像、文件或其他资产的多个请求。当目标被传入的请求和响应所淹没时，来自正常流量源的其他请求将被拒绝服务。
-   **HTTP POST 攻击**：一般而言，在网站上提交表单时，服务器必须处理传入的请求并将数据推送到持久层（通常是数据库）。与发送 POST 请求所需的处理能力和带宽相比，处理表单数据和运行必要数据库命令的过程相对密集。这种攻击利用相对资源消耗的差异，直接向目标服务器发送许多 POST 请求，直到目标服务器的容量饱和并拒绝服务为止。

#### 防御

如前所述，缓解第 7 层攻击非常复杂，而且通常要从多方面进行。一种方法是对发出请求的设备实施质询，以测试它是否是机器人，这与在线创建帐户时常用的 CAPTCHA 测试非常相似。通过提出 JavaScript 计算挑战之类的要求，可以缓解许多攻击。

其他阻止 HTTP 洪水攻击的途径包括使用 Web 应用程序防火墙 (WAF)、管理 IP 信誉数据库以跟踪和有选择地阻止恶意流量，以及由工程师进行动态分析。Cloudflare 具有超过 2000 万个互联网设备的规模优势，能够分析来自各种来源的流量并通过快速更新的 WAF 规则和其他防护策略来缓解潜在的攻击，从而消除应用程序层 DDoS 流量。

### DNS Flood(洪水)

域名系统（DNS）服务器是互联网的“电话簿“；互联网设备通过这些服务器来查找特定 Web 服务器以便访问互联网内容。DNS Flood 攻击是一种分布式拒绝服务（DDoS）攻击，攻击者用大量流量淹没某个域的 DNS 服务器，以尝试中断该域的 DNS 解析。如果用户无法找到电话簿，就无法查找到用于调用特定资源的地址。通过中断 DNS 解析，DNS Flood 攻击将破坏网站、API 或 Web 应用程序响应合法流量的能力。很难将 DNS Flood 攻击与正常的大流量区分开来，因为这些大规模流量往往来自多个唯一地址，查询该域的真实记录，模仿合法流量。

DNS Flood 攻击不同于 [DNS 放大攻击](https://www.cloudflare.com/zh-cn/learning/ddos/dns-amplification-ddos-attack/)。与 DNS Flood 攻击不同，DNS 放大攻击反射并放大不安全 DNS 服务器的流量，以便隐藏攻击的源头并提高攻击的有效性。DNS 放大攻击使用连接带宽较小的设备向不安全的 DNS 服务器发送无数请求。这些设备对非常大的 DNS 记录发出小型请求，但在发出请求时，攻击者伪造返回地址为目标受害者。这种放大效果让攻击者能借助有限的攻击资源来破坏较大的目标。

#### 防御

DNS Flood 对传统上基于放大的攻击方法做出了改变。借助轻易获得的高带宽僵尸网络，攻击者现能针对大型组织发动攻击。除非被破坏的 IoT 设备得以更新或替换，否则抵御这些攻击的唯一方法是使用一个超大型、高度分布式的 DNS 系统，以便实时监测、吸收和阻止攻击流量。

### DDOS

DDos 全名 Distributed Denial of Service，翻译成中文就是**分布式拒绝服务**。指的是处于不同位置的多个攻击者同时向一个或数个目标发动攻击，是一种分布的、协同的大规模攻击方式。单一的 DoS 攻击一般是采用一对一方式的，它利用网络协议和操作系统的一些缺陷，采用**欺骗和伪装**的策略来进行网络攻击，使网站服务器充斥大量要求回复的信息，消耗网络带宽或系统资源，导致网络或系统不胜负荷以至于瘫痪而停止提供正常的网络服务。

#### 防御

1. 使用高防服务器：主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等。
2. 黑名单机制
3. **DDoS 清洗**会对用户请求数据进行实时监控，及时发现DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量。
4. CDN 加速，CDN 服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 **DDoS** 攻击，也可以将流量分散到各个节点中，防止源站崩溃。

## websocket

WebSocket 可以实现双向通信，不需要像 HTTP 一样每次请求都要重新建立连接，同时也可以提高实时性，支持点对点和群聊消息发送和接收。
TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
它适用于**需要服务器和客户端（浏览器）频繁交互**的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。

WebSocket和HTTP一样都是==基于TCP的协议==。**经历了三次TCP握手之后，利用 HTTP 协议升级为 WebSocket 协议**。

- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。
- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
- 正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。

### 为什么用ws不用http

1. ws是真正的全双工，http本质上是半双工的协议，同一时刻信息流向是单向的。
2. http的虽然有keep-alive机制，但是它仍然有一个保持时间，时间一到就会立马关闭，而且在这个机制中每次的请求仍然会发送header。
3. HTTP协议是一个请求－响应协议，请求必须先由浏览器发给服务器，服务器才能响应这个请求，再把数据发送给浏览器。换句话说，浏览器不主动请求，服务器是没法主动发数据给浏览器的。http的通信只能由客户端发起，如果服务器由变化无法主动通知客户端。
4. ws的数据格式轻量，性能开销好，通信高效。

### 握手

1. 客户端向服务器发送Upgrade请求头，请求升级到WebSocket协议。
2. 服务器返回101状态码，表示同意升级到WebSocket协议，并在响应头中携带Upgrade和Connection字段，标识协议已经升级。
3. 握手完成后，客户端和服务器就可以建立持久连接，并进行双向通信。

浏览器在 **TCP 三次握手**建立连接之后，都**统一使用 HTTP 协议**先进行一次通信。
- 如果这时候是**想建立 WebSocket 连接**，就会在 HTTP 请求里带上一些**特殊的header 头**，如下：

```http
Connection: Upgrade
Upgrade: WebSocket
Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n
```

这些 header 头的意思是，浏览器想**升级协议（Connection: Upgrade）**，并且**想升级成 WebSocket 协议（Upgrade: WebSocket）**。同时带上一段**随机生成的 base64 码（Sec-WebSocket-Key）**，发给服务器。

如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个**公开的**算法变成另一段字符串，放在 HTTP 响应的 `Sec-WebSocket-Accept` 头里，同时带上`101状态码`，发回给浏览器。HTTP 的响应如下：

```http
HTTP/1.1 101 Switching Protocols\r\n
Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n
Upgrade: WebSocket\r\n
Connection: Upgrade\r\n
```

浏览器也用同样的**公开算法**将`base64码`转成另一段字符串，如果这段字符串跟服务器传回来的**字符串一致**，那验证通过。就这样经历了一来一回两次 HTTP 握手，WebSocket就建立完成了，后续双方就可以使用 webscoket 的数据格式进行通信了。

### 消息格式

数据包在WebSocket中被叫做**帧**：在 WebSocket 协议中, 帧 (frame) 是通信双方数据传输的基本单元, 与其它网络协议相同, frame 由 Header 和 Payload 两部分构成, frame 有多种类型, frame 的类型由其头部的 Opcode 字段 来指示, WebSocket 的 frame 可以分为两类, 一类是用于传输控制信息的 frame (如通知对方关闭 WebSocket 连接), 一类是用于传输应用数据的 frame, 使用 WebSocket 协议通信的双方都需要首先进行握手, 只有当握手成功之后才开始使用 frame 传输数据

![WS](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202311060955043.png)

**opcode字段**：这个是用来标志这是个**什么类型**的数据帧。
**payload字段**：存放的是我们**真正想要传输的数据的长度**，单位是**字节**。
**payload data字段**：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。

## KCP 

[在网络中狂奔：KCP协议 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/112442341)
[skywind3000/kcp: :zap: KCP - A Fast and Reliable ARQ Protocol (github.com)](https://github.com/skywind3000/kcp)

TCP保证数据准确交付，UDP保证数据快速到达，KCP则是两种协议的一个折中。
KCP的设计目标是为了解决在网络拥堵的情况下TCP传输速度慢的问题。

KCP协议是一个纯粹的ARQ协议，通过重传机制实现UDP数据包的可靠传输。

### 数据段格式

![](https://raw.githubusercontent.com/Swiftie13st/Figurebed/main/img/202310232050430.png)

- **conv**: 连接标识。
- **cmd**: Command。
- **frg**: 分片数量，表示随后还有多少个报文属于同一个包。
- **wnd**: 发送方剩余接收窗口的大小。
- **ts**: 时间戳。
- **sn**: 报文编号。
- **una**: 发送方的接收缓冲区中最小还未收到的报文段的编号。也就是说, 编号比它小的报文段都已全部接收。
- **len**: 数据段长度。
- **data**: 数据段. 只有数据报文会有这个字段

### 特征

- **RTO不翻倍**

RTO(Retransmission-TimeOut)即重传超时时间，TCP是基于ARQ协议实现的可靠性，KCP也是基于ARQ协议实现的可靠性，但TCP的超时计算是RTO*2，而KCP的超时计算是RTO*1.5，也就是说假如连续丢同一个包3次，TCP第3次重传是RTO*8，而KCP则是RTO*3.375，意味着可以更快地重新传输数据。通过4字节ts计算RTT(Round-Trip-Time)即往返时延，再通过RTT计算RTO，ts(timestamp)即当前segment发送时的时间戳。

- **选择性重传**

TCP中实现了连续ARQ协议，再配合累计确认重传数据，只不过UNA下重传时需要将最小序号丢失的以后所有的数据都要重传；而KCP不仅有UNA，还有sn即收到的UNA之后但不连续的序号，这样发送端就可以单独对UNA之后的，不包括sn的数据单独做计数，故而只需要重传真正丢失的数据。

- **快速重传**

与TCP相同，都是通过累计确认实现的，发送端发送了1，2，3，4，5几个包，然后收到远端的ACK：1，3，4，5，当收到ACK = 3时，KCP知道2被跳过1次，收到ACK = 4时，知道2被跳过了2次，此时可以认为2号丢失，不用等超时，直接重传2号，大大改善了丢包时的传输速度。1字节cmd = 81时，sn相当于TCP中的seq，cmd = 82时，sn表示收到的但不连续的序号。cmd相当于WebSocket协议中的openCode，即操作码。

- **非延迟ACK**

TCP在连续ARQ协议中，不会将一连串的每个数据都响应一次，而是延迟发送ACK，即上文所说的UNA模式，目的是为了充分利用带宽，但是这样会计算出较大的RTT时间，延长了丢包时的判断过程，而KCP的ACK是否延迟发送可以调节，当配置了非延迟ACK时，收到数据立即响应（_或得知发送端的wmd = 0时立即响应，比较容易理解，wnd = 0，必然是对方超时没有收到确认猜想网络拥堵从而做出了慢启动补偿，所以此时就需要立即给出响应_）。

- **UNA + ACK**

参考特征2和特征3，cmd = 82 时，una + sn 配合；

- **非退让流控**

在传输及时性要求很高的小数据时，可以通过配置忽略上文所说的窗口协议中的拥塞窗口机制（_退半避让_），而仅仅依赖于滑动窗口。就是说当丢包的情况出现时，网络可能发生了拥堵，本该ssthresh减半，cwnd=1 | = ssthresh，但KCP不做处理，这样对其他做传输的服务是不公平的，如果网络真的拥堵，KCP如此将导致网络里增加更多的未被收到的数据（更多的丢包），牺牲了带宽利用率。

2字节wnd与TCP协议中的16位窗口大小意义相同，值得一提的是，KCP协议的窗口控制还有其它途径，当cmd = 83时，表示询问远端窗口大小，当cmd = 84时，表示告知远端窗口大小。

4字节conv表示会话匹配数字，同TCP中的conv，类似于HTTP协议中的SessionID，表示两端的编号身份。

1字节frg表示拆数据时的编号，4字节len表示整个数据的长度，相当于WebSocket协议中的len。
